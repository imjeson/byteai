---
title: '国产芯片大战更焦灼了丨智涌分析'
date: 2024-07-10
author: ByteAILab

---

7月4日-7日，世界人工智能大会（下称WAIC）在上海世博展馆开启。而算力，作为AI发展的刚需要素，让展馆中的芯片企业成为关注焦点。

---
如果说，去年的WAIC上，行业里GPU只有英伟达一个独苗可以选择，情况在今年有了巨大的变化。2024年的WAIC，分为H1、H2、H3三个馆。据《智能涌现》作者观察，其中，H2馆基本有一半的厂商都是和智算中心、芯片有关的厂商，大玩家也基本聚齐：华为、百度昆仑芯、天数智芯、摩尔线程、算能、中科曙光、燧原等等。不过，由于芯片还是一个相对敏感的话题，冒头的厂商们，展示方式上还是略显收敛。

多位芯片厂商人士告诉《智能涌现》，他们最新的芯片产品并不敢拿出来展示，也不打算正式发布。在展示方式上，大家形成了心照不宣的默契，并不愿意直接呈现芯片本身——而是直接呈现装好芯片的服务器，或者是以合作伙伴的落地案例来展现。

WAIC作为人工智能行业的一个集中观察窗口，从这里我们可以窥见2024年的国产算力发展趋势。随着大模型逐渐往两派分化——一派追逐务实的商业化落地，另外一派是技术理想派，还在持续进发追求高参数量。

有趣的是，同样的趋势也出现在上游的算力端。目前，国内的芯片厂商也呈现了策略上的两极分化，一派继续往万卡、万P进发，另一派则更关注大模型在各行各业的落地诉求，推理芯片进入爆发前夜。

推理芯片的大爆发，是一个市场和竞争综合作用的结果。随着主流大模型逐渐推进开源、以及大模型厂商们今年为了抢夺市场疯狂降价，大模型逐渐在各行各业落地。推理正是一个“用”大模型的过程，需要大量的推理芯片的支撑。和训练场景不一样的是，推理芯片面向的是各行各业，眼前是星辰大海。而更重要的是，这也是英伟达芯片没有渗透到的广泛市场。在此前，行业内一般采用英伟达的4090、L20这些产品来跑大模型推理，不过英伟达这类产品的缺点也相当明显。比如，英伟达的4090其实是消费级显卡，英伟达官方并不允许其运用于大模型推理，目前也面临着禁运的情况。而更关键的是，英伟达这些芯片由于并非针对推理场景制定，存在着功耗过大、内存不够等情况，难以满足诉求。而前述那些“卖爆”的产品，也正是基于英伟达的种种阿喀琉斯之踵而切入。4090、L20，基本是这些国产推理卡的直接对标对象。

一名天数智芯的工作人员称，他们推出的“大模型推理16卡服务器”，16卡服务器的单机显存达到512GB，单卡成本和4090差不多的情况下，功耗只有其1/3，并且，“供应稳定持续有货”，目前已经打入了某大模型厂商供应链。除了传统的芯片厂商之外，《智能涌现》发现，目前也有中兴在内的新玩家进入推理芯片市场，以及出现了全新的商业模式。...

  本文链接：<a data-v-7f057cc4="" href="https://www.aixinzhijie.com/article/6846230">https://www.aixinzhijie.com/article/6846230</a>
转载请注明文章出处

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。