---
title: '你是否80%生气和2%伤心？为什么“情感AI”充满问题'
date: 2024-06-24
author: ByteAILab

---

AI号称可以读懂我们的情绪，这可能会增强用户体验，但对于滥用和偏见的担忧意味着该领域充满潜在危险。

---


在本文中，作者描述了一种试验情景。他在周三晚上坐在厨房桌旁，苦苦思考着自己的笔记本电脑，竭尽全力地把所有的愤怒倾泻进了三个小词：“我爱你。”纽约创业公司Hume开发了一款声音AI，声称已经发展出了“世界上第一个具有情感智能的语音AI”。Hume的首席执行官兼首席科学家Alan Cowen表示：“我们训练了一个可以理解您说话语气的大型语言模型。这使得我们能够预测一个给定语音表达或句子将会引发的情感模式。”简而言之，Hume声称能够识别我们声音中的情感（以及非公开版本中的面部表情），并且能够以共情回应。受Open AI五月发布的更“富有表现力”的GPT4o的推动，所谓的情感AI变得日益庞大。Hume在三月的第二轮融资中筹集了5,000万美元，该行业的价值预计今年将超过500亿美元。但班戈大学情感AI实验室主任Andrew McStay教授表示，这样的预测毫无意义。“情感是人类生活中如此基本的维度，如果你能理解、衡量和以自然的方式回应情感，那将产生远远超过500亿美元的影响。”可能的应用范围从更好的视频游戏和更少令人沮丧的热线电话到像奥威尔小说中那样的监视和大规模情感操纵。但AI真的能够准确读懂我们的情绪吗？如果无论如何都会出现这种技术的某种形式，我们应该如何处理它呢？

{
其他部分内容...
}

---

。注意：Title、Date、Body 三个部分的内容，放入到对应的位置，Title部分内容需要翻译为中文。最后只需要输出为Makedown源文件格式内容。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。