---

title: '欧洲“OpenAI”叒融资6亿刀，成立1年估值60亿刀，他们只做了一件事'
date: 2024-05-14
author: ByteAILab

---

文章来源：[智能涌现](https://mp.weixin.qq.com/s/GtrKZFUnME2x4zS3vbaqhA)

文｜李然 李苗

编辑｜李然

“Open AI 欧洲版”Mistral AI又融到一笔巨款，让本就富裕的家庭锦上添花。

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1715415435251/FiLX_jiYyMZjSeYMCbP8p93d-b3G.png)

华尔街日报报道，法国AI独角兽Mistral AI即将获得新一轮6亿美元的融资，目前估值达60 亿美元，比半年前翻三倍。

---
据知情人士透露，现有股东General Catalyst和Lightspeed Venture Partners预计将成为新一轮融资的最大投资者之一。

![Image](http://www.jesonc.com/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1715414124866/FqqDbn44sJNv1g5uePU4kdG8WzM6.png)

天下武功唯快不破。无论是产品交付还是融资节奏，Mistral的效率都高得惊人。

2023年4月底成立，花1个月写了7页PPT，6月份，Mistral首轮融资1.13亿美元。

半年内，Mistral发布了开源的Mistral 7B和MoE模型Mixtral 8x7B Instruct。年底，这家仅20人规模的公司就筹了约4.15亿美元，估值达20亿美元。

今年2月底，Mistral Large发布，强势对标GPT-4。同日，[微软也正式宣布与Mistral AI达成合作。](http://mp.weixin.qq.com/s?__biz=MzkwMDQ2NDU2Nw==&mid=2247498818&idx=1&sn=5caa43d16c49f19bf1cc1ee9dc3b7366&chksm=c041169af7369f8c214d16317be5d5d85c228252e427f14ef30a8e231af29d5f1545baa971de&scene=21#wechat_redirect)

![Image](http://www.jesonc.com/FrHW8srDS22tEo5JlgYtgQDs-MuW)

Mistral AI的高速发展历程堪比“爽文”，“爽文”的标题可能是：

- “三句话，让投资人心甘情愿为我花六亿美元。”
- “从白手起家到估值60亿刀，我只做对了这件事。”
- “我们欧洲什么时候才能站起来？有自己的OpenAI，我们做到了”。

**1年从0到估值60亿刀，他们只有一个追求——高效**

Mistral AI，成立1年整，融资超过11亿刀，估值达到60亿刀，只做了一件事：

**用最高效的方法做最高效的大模型。**

**技术路线：最高效的开源和闭源大模型**

在公司网站对于自家产品的介绍中，他们最重点介绍的就是自己是世界上最高效的大模型提供商。

![Image](http://www.jesonc.com/FvsmCr8XCFPC8bJdIiugY5Jgbb4n)

他们是大模型性能进入GPT-4时代之后，第一家发布MoE构架开源大模型的公司，现在Mistral 8*22B，依然是开源大模型中标杆级别的存在。

而MoE构架最重要的特点就是能在训练和推理的过程中大大降低算力和能源的消耗，还能提供非常高的推理性能。所以Mistral推出的8*7B开源模型才能做到6倍于Llama2 70B的推理效率。

**融资和交付最为高效的大模型公司**

2023年5月，3位创始人拿着7页PPT开始了他们创业之旅。整整一年之后，让我们看看他们做出了些什么成果：

2023秋天发布Mistral-7B，一个磁力链接，没有花哨的宣传，开源社区为之疯狂。

![Image](http://www.jesonc.com/FjkwpNm0tzuon4k8BpnOX954WidN)

2个多月后，一个磁力链接丢出Mistral 8*7B。

![Image](http://www.jesonc.com/FuI9ejakua5__L49ikseN43sbZD_)

网友感叹，“谷歌强在发布，Mistral强在交付”

![Image](http://www.jesonc.com/FprUesh3tMRKCESGUqhnmrAGyk2r)

又过了差不多3个月，Mistral发布了自己的闭源模型全家桶，Mistral-Large，Mistral-Medium，Mistral-small。模型API服务随之上线。超大杯能力对标GPT-4。

4月10日，还是一个磁力链接，Mistral 8*22B性能接近GPT-4，开源社区从此站起来了。

![Image](http://www.jesonc.com/FlYh-5FVnGYvr86acHsrkVi2l3mp)

至此，Mistral AI用一年不到的时间，从3个人4张PPT，一路高速弯道超车，一己之力完成了开源闭源接近SOTA的模型交付。

一家20人的公司用不到1年时间，把OpenAI（能力比肩GPT-4）+谷歌（大中小杯闭源模型）+Meta（引领开源社区风潮）3家公司从Transformer诞生至今所有和大模型有关的里程碑都走了一遍。

这家法国公司的交付效率，让所有硅谷大厂都为之汗颜，也就难怪投资人上赶着给他们送钱了。

**人效惊人！有多少员工就估值多少亿刀的神话**

Mistral AI如此高的交付效率，如果放在大厂，还能靠堆人头堆出来。

而夸张的是，Mistral AI这一年时间大部分时间，团队人数都保持在20个人左右，大部分交付的成果都是在20人团队规模时完成的。

算上种子轮，Mistral AI一年时间总共经历3次融资：3个人估值4亿刀，20人团队估值20亿刀，60人团队估值60亿刀。

每次融资估值数和团队人数之比都高度一致：平均1人值1亿刀！

可以说，Mistral AI在组织架构效率层面取得的成绩，也是行业最一流的。

可以和OpenAI做个简单的对比就能看出Mistral的组织到底有多高效。

根据彭博社一个月前对于OpenAI COO的采访，现如今OpenAI的雇员数差不多有1200人，最近一次对外融资时的估值差不多是950亿美金。

![Image](http://www.jesonc.com/FhynjbNKEQxoc5OYgf_tA948QJkK)

Mistral AI人员/估值比甚至超过了行业中最火的公司，足以看出他们在人员效率上的优势。

做最高效的大模型，用最高效的方式做大模型，成立最高效的组织做大模型。

**实用主义无神论者，把「高效灵活」刻进创业基因**

Mistral的三位核心创始人曾是校友，在工作后纷纷成为令人羡慕的的硅谷技术精英。

![Image](http://www.jesonc.com/Fof58eIeAN8uxOiLHNTvhRtl-rKi)

创始人Arthur Mensch 曾在谷歌担任高级研究员，而 Timothée Lacroix 和 Guillaume Lample 在Meta的 LLaMa 团队，当前分别在 Mistral AI 任首席技术官和首席科学官。

Mensch 曾对媒体表达过离开谷歌的原因是因为其“不够创新（innovative）”——嫌弃大公司效率低下。而 Lacroix 和 Lample 因为 Meta 公司内部的原因，也离开了。

![Image](http://www.jesonc.com/Fj33Q8EON_JlM8I8EJTeJE7zBkiK)

在人工智能创业领域，Open AI 和谷歌等大模型巨头已经形成马太效应。比起简单直接的商业场景落地，做模型似乎已经成了一件吃力不讨好的事。

但是，不要小看创业者的羁绊。

Mensch 曾在采访中表示，他与 Lample 和 Lacroix 从学生时代起就认识，友谊已经超过了十年。

在 30 出头的年纪，他们决定趁着风口给这个世界一点小小的震撼。三人联手在法国创办了 Mistral AI 并成长迅速，成为 Open AI 有力竞争者之一（起码分走了微软的青睐）。

最初的愿景是搓出一个“更有用的AI”。

![Image](http://www.jesonc.com/Flt6GNBNYdn_4Z-bGjoB9SXgznJo)

Mensch 是个无神论者，他没有“造神”的意愿，只相信“有用”的力量。他曾公开表示自己“区别于别的 AI 创业 CEO”（指马斯克和萨姆·奥尔特曼），并对硅谷中弥漫的“关于通用人工智能的宗教迷恋感到不适”

![Image](http://www.jesonc.com/FgJUfFS339c69YrA4VGBdok-JrPL)

“整个通用人工智能的言论都是关于创造上帝，” 米斯特拉尔在接受采访中说。“我不相信上帝。我是一个坚定的无神论者。所以我不相信通用人工智能。”

![Image](http://www.jesonc.com/FjIu60ZExZGzhxVE0uNx1InEvJpt)

Reddit 网友对此新闻评论：老兄，我只是想简单地活着，不用担心账单而已。

追求实用、灵活和高效的目标刻在 Mensch 的从业基因里。Mensch 在 Google 的 DeepMind 团队主要负责 retrieval 工作。他发表过 21 篇有关语言模型的 ArXiv 论文，是 RETRO、Flamingo 和 Chinchilla 项目的主要贡献者

![Image](http://www.jesonc.com/FuMG0OfxBCPURZJr0KpOli5wPIqq)

这三个项目都与大模型的效率提升有关。擅长机器学习可视化的知名博客作者 Jay Alammar 曾详细分析了 Mensch 参与搭建的的 RETRO（Retrieval-Enhanced TRansfOrmer）模型。该模型与 GPT-3 性能相当，但参数量仅为 GPT-3 的4%。

在算力和数据吃紧的当下，增大模型不是提高性能的唯一选择。RETRO 模型能如此高效的原因在于它将语言信息和世界知识信息区分开了，并加入了检索来增强性能。

![Image](http://www.jesonc.com/FncTIou_uifpivmeeVmamaTRU0PQ)

Flamingo 是一个视觉模型，仅使用少量带注释的示例来构建可以快速适应新任务。

而 Chinchilla 模型则大大简化了下游利用，因为它可以减少推理和微调所用到的算力。

Mensch 创办 Mistral AI 的理念其实和他的工作内容是一脉相承的：多快好省地建设 AI 模型。

在商业化方面，灵活、便携、性价比也被 Mistral AI 所强调。

比起市面上其他公司，Mistral的不同之处在于其便携式解决方案。它可以通过 API 配合云服务作为 SaaS 使用。最重要的是，它也可以作为一个平台进行本地部署。

Mensch 曾在 5 月 2 日接受采访时骄傲地表示：“如果您拥有私有云，并且想要高度定制工作负载，或者您是在本地运行，那么我们基本上是唯一的解决方案之一。这一切都与我们愿意广泛分享技术有关。反过来，这也正是我们开源的原因。”

短短一年时间，在模型能力上做到有开源也有闭源；在商业化应用上，有本地部署，也有外部云服务。

灵活的唯物主义六边形战士 Mistral AI 在欧洲“开卷”，六十亿的新估值是这条鲶鱼应得的。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。