---

title: 'AI生成的内容可以被区分出来么？'
date: 2024-11-08
author: ByteAILab

---

当前，识别AI生成内容的技术手段均未成熟。如何在潜在风险，治理成本、目标成效之间取得合理平衡成为关键所在。

---
建议小步试错，探寻科学的风险管理方案。

## 内容治理逻辑的扩展：人类原创还是AI生成？

对于AI生成内容在未来全部信息内容中所占比例，不同机构的预测口径有所不同，从20%-90%不等。但不容否认的是：**随着生成式AI技术应用的普及，AI生成内容比例正在逐步攀升。**有研究显示，仅仅从2023到2024的一年间，包含AI生成内容的网页数量就激增了2848%。与此同时，内容生产模式的变革也在推动着内容治理逻辑的悄然变化，从过去针对内容性质——是否违法有害，扩展至针对内容来源——是否为AI生成。  

在AI生成内容早期阶段，大模型厂商从提升模型透明度，支持权利保护等目标出发，尝试开展标识工作。特别在版权方面，尽管对AI生成内容的可版权性...

## 如何把AI生成内容区分出来？

**区分AI生成内容首先是一个技术问题.** 目前，识别的技术路径主要包括生成内容检测和来源数据追踪两个方向。前者主要通过寻找数字内容所包含的生成特征来确定内容是否由AI生成或篡改。后者则是通过对数字内容全生命周期的相关信息（是否由AI生成、修改）的独立记录来间接反映数字内容的性质。**然而对于AI内容识别，目前尚缺乏成熟可靠的技术方案。**

1. 内容检测路径

内容检测是最为直观的解决方案。虽然目前在人类的感官层面，AI生成内容与人工创作内容已相差无几，但是在细节层面...

2. 数据跟踪路径

**来源数据跟踪是对“内容性质识别”的间接解决方案.** 来源数据跟踪并不依赖内容本身，而是通过对于内容的变动（生成、修改等）进行记录，从侧面反映内容的真实性、完整性。当前的来源数据跟踪方法主要包括显式标识和隐式标识。

## 产业界对于AI生成内容标识的自发探索

在全球范围内，人工智能企业、大型网络平台基于透明度、可信赖等原则，围绕AI生成内容的标识，已自发展开探索...

## AI生成内容标识：基于动态风险的治理探索 

AI生成内容带来了与以往完全不同的风险，推动着各方尝试明确AI生成与人类创造的边界。然而，针对AI生成内容的标识，目前尚未形成成熟的技术解决方案。总体上，出于“防患于未然”的风险预防思路，标识工作处于一种自发探索的状态...

1. 在不断试错验证的过程中，探寻合理的风险管理方案  

建议采取开放推荐的方式，鼓励相关主体积极探索包括内容检测、数字水印等在内的多种技术方式...

2. 基于场景区分不同主体的治理角色  

对于AI生成内容，AI生成技术的提供者与部署者具有明确的主体角色差异，需适配不同规则. 例如：欧盟《人工智能法》依据主体角色的不同，相应建立了不同的标识规范...

3. 避免大而全，将治理资源聚焦在“真正的风险领域”  

**全面标识听起来“大而美好”，但实质上却可能有碍于标识目的的实现，让真正具有风险的内容融入普遍被标识的信息海洋，易使公众信息过载，控制风险的作用大打折扣，**在此背景下，可考虑限定标识的范围...

4. 培养公众在AI时代的“信息素养”  

多么完美的识别规则，最终也只能起到辅助判断的作用，无法替代公众对信息内容作最后的真伪判断，个人永远是自己“选择相信内容”的最终把关人. 信息爆炸的时代，越需提升对信息真实与否的敏感度...

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。