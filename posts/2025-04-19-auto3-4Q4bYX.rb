title: 'CoreWeave推出NVIDIA GB200 Grace Blackwell系统，实现规模化'
date: 2025-04-20
author: ByteAILab

---

初步客户包括IBM、Mistral AI和Cohere  
CoreWeave, AI Hyperscaler™，今天宣布Cohere、IBM和Mistral AI是首批获得NVIDIA GB200 NVL72机架规模系统和CoreWeave的全栈云服务的客户——这是一种旨在推动AI模型开发和部署的组合。![图片](https://ai-techpark.com/wp-content/uploads/CoreWeave-2.jpg){ width=60% }

---
  

现在，企业和其他组织的AI创新者可以使用NVIDIA Grace Blackwell超级芯片，专门用于推理和智能代理AI的高级网络，突显了CoreWeave在先进AI云解决方案方面始终走在市场前列的记录。  

“CoreWeave的目标是快速发展，我们一再证明了这一点，通过最先进的系统在规模上实现运营的领先地位，”CoreWeave的联合创始人及首席执行官Michael Intrator表示。“今天证明了我们的工程实力和快速响应能力，以及我们对启用下一代AI的持续关注。我们非常高兴看到一些富有远见的公司已经在我们的平台上取得新的突破。通过提供规模化的最先进计算资源，CoreWeave使企业和AI实验室客户能够更快地创新，并部署曾经遥不可及的AI解决方案。”  

“全球的企业和组织正在竞相将推理模型转变为能够改变人们工作和娱乐方式的智能代理AI应用程序，”NVIDIA的高性能计算和超大规模副总裁Ian Buck说。“CoreWeave迅速部署NVIDIA GB200系统，为实现AI工厂提供了基础设施和软件。”  

CoreWeave提供先进的AI云解决方案，同时最大化效率并打破性能记录。公司最近以NVIDIA GB200 Grace Blackwell超级芯片在AI推理方面创下新的行业记录，该记录在最新的MLPerf v5.0结果中报告。MLPerf推理是一个工业标准套件，用于测量机器学习在现实部署场景下的性能。  

去年，该公司成为首批提供NVIDIA H100和NVIDIA H200 GPU的企业，并首次演示了NVIDIA GB200 NVL72系统。  

CoreWeave的云服务产品组合针对NVIDIA GB200 NVL72进行了优化，为客户提供了性能和可靠性，包括CoreWeave Kubernetes服务、在Kubernetes上运行的Slurm（SUNK）、CoreWeave任务控制等。CoreWeave的NVIDIA Blackwell加速实例可扩展至多110,000个Blackwell GPU，配备NVIDIA Quantum-2 InfiniBand网络。  

除了IBM、Mistral AI和Cohere，CoreWeave最近还与ChatGPT的创始公司OpenAI签署了一份多年合同。  

---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。