---

title: '本周日不见不散！ICLR 2025北京论文分享会最后报名了'
date: 2025-04-18
author: ByteAILab

---

从 OpenAI o1 到 DeepSeek R1，推理模型进入到了全新的发展阶段，展现出来的「慢思考、强推理」能力正在加速从语言智能到认知智能的进程，并构筑起未来 AGI 的重要基石。同时，学界对大语言模型范式的探索仍在继续，扩散模型不断向主流的自回归架构发起挑战。

---


当然，在 2025 智能体元年，大语言模型（LLM）驱动的智能体借助手机等移动终端的落地，深刻改变了人机交互范式。多模态大模型的竞争也趋于白热化，提升跨模态理解与生成能力的同时注重低成本和低门槛应用。

为让从业者全面了解 AI 社区涌现的最新创新成果和发展趋势，机器之心计划 4 月 20 日在北京举办「ICLR 2025 论文分享会」，围绕着训练推理、多模态、Agent 等热门主题邀请顶级专家、论文作者与现场参会观众共同交流。

作为机器学习和深度学习领域的顶级会议，ICLR 具有极高的含金量， 每年都会吸引大量研究机构和高校参会。今年，ICLR 2025 共接收 11,565 份投稿，录用率为 32.08%。

作为一场为国内 AI 人才打造的盛会，本次论文分享会设置了 Keynote、论文分享、圆桌对话、Poster 交流等丰富环节。今天，论文分享会的全日程、Keynote 分享嘉宾、演讲主题以及圆桌嘉宾正式公布，**感兴趣的读者可以继续扫描文中二维码报名，截止日期到4月18日24:00**。

![图片](https://image.jiqizhixin.com/uploads/editor/703ff0de-2673-4003-bdfe-a5084f024e8c/640.png)

**Keynote 嘉宾及演讲主题**

**上午 Keynote：陈键飞 基于量化稀疏的高效训练推理：理论及算法**

![图片](https://image.jiqizhixin.com/uploads/editor/75f88a07-8a1c-496d-8868-2c4585da4385/640.png)

**分享人介绍**：陈键飞，清华大学计算机系准聘副教授。2010-2019 年获清华大学学士和博士学位。从事高效机器学习研究，谷歌学术引用 5000 余次。担任 IEEE TPAMI 的编委，担任 ICLR 等会议领域主席。获得 CCF 青年人才发展计划、清华大学学术新人奖等。

**分享摘要**：大模型所需计算成本高昂，而低精度、稀疏等高效训练推理方法均在原有计算基础上引入了近似，可能会引起精度损失。本报告将介绍近似梯度下降理论，该理论可以为高效的近似训练方法的收敛性、收敛速度提供理论保证。基于该理论，将分别介绍通过量化和稀疏两条技术路线设计的前馈神经网络计算加速、注意力计算加速、激活压缩、优化器压缩、通信压缩等高效训练推理算法。将从机器学习的角度出发，介绍高效训练的过程中遇到的训练不稳定等问题及克服方法。

**下午 Keynote：李崇轩 LLaDA：语言模型新范式**

![图片](https://image.jiqizhixin.com/uploads/editor/c146681b-a5c8-4c75-a63f-4fda144eb3e1/640.png)

**分享人介绍**：李崇轩，中国人民大学高瓴人工智能学院准聘副教授、博士生导师，2010-2019 年获清华大学学士和博士学位。主要研究机器学习、深度生成模型，代表性工作部署于 DALL・E 2、Stable Diffusion、Vidu 等生成式大模型。获国际会议 ICLR 杰出论文奖、吴文俊优秀青年奖、吴文俊人工智能自然科学一等奖、中国计算机学会优秀博士论文等，主持国家自然基金重大研究计划培育项目、面上项目等，担任 IEEE TPAMI 编委、软件学报编委和 ICLR、NeurIPS 等国际会议的领域主席。

**分享摘要**：本次报告聚焦一个问题：自回归是否是通向当前乃至更高水平的生成式智能的唯一范式？本次报告首先从统一概率建模的视角总结当前基础生成模型的发展，并从这个视角出发指出大语言模型的性质（如可扩展性、指令追随、情景学习、对话、无损压缩）主要来自于生成式准则，而非自回归建模独有。基于这些洞察，本次报告基于掩码的扩散语言模型的技术路线，包括基础理论和扩展定律。最终，基于前期成果，训练 8B 扩散大语言模型 LLaDA（Large Language Diffusion with mAsking）。在 20 多个语言、代码、数学等评测集上，LLaDA 8B 全面超过 LLaMA 2，对标 LLaMA 3。并且 LLaDA 通过非自回归的方式，展示了令人惊讶的可扩展性和多轮对话能力。这些结果不仅挑战了自回归的地位，更加深了我们对生成式人工智能的理解。

**圆桌讨论嘉宾**

这场分享会中，我们特别设置了一场「LLM 驱动的 Agent：技术瓶颈与融合路径」主题圆桌，邀请了四位专家学者现场探讨。

**主持人：张群英 ICT 产业观察家，茶思屋科技网站总编**

![图片](https://image.jiqizhixin.com/uploads/editor/05357f04-e6de-454f-8a3a-bc9fcaaed818/640.png)

对话嘉宾：
- **李崇轩**，中国人民大学高瓴人工智能学院准聘副教授、博士生导师，2010-2019 年获清华大学学士和博士学位。主要研究机器学习、深度生成模型，代表性工作部署于 DALL・E 2、Stable Diffusion、Vidu 等生成式大模型。

![图片](https://image.jiqizhixin.com/uploads/editor/5c9f856c-51fd-47e3-af32-2939524ed11c/640.png)

- **李庆**，北京通用人工智能研究院机器学习实验室主任，2022年博士毕业于UCLA。他的研究方向包括大模型智能体，多模态理解，具身智能等。

![图片](https://image.jiqizhixin.com/uploads/editor/ef27521d-4f1f-4771-9391-f8826c3d78eb/640.png)

- **吴承霖**，DeepWisdom 创始人兼 CEO。拥有十亿级用户的大规模 AI 落地经验。

![图片](https://image.jiqizhixin.com/uploads/editor/c129fa3d-2102-4999-9e7b-e296ad984778/640.png)

- **杨林易**博士自2017年起在都柏林大学攻读博士学位，在人工智能领域取得了一系列具有国际影响力的学术成果。

**Poster**

在本次论文分享会中，将会有一批论文作者进行论文分享与 Poster 展示，感兴趣的读者可以通过下图了解具体信息：

![图片](https://image.jiqizhixin.com/uploads/editor/9fde730e-1e28-4fcb-a4eb-30b984e86339/640.png)

此次论文分享会也将在机器之心视频号以及黄大年茶思屋科技网站两个平台进行直播，欢迎大家关注、预约。

![图片](https://image.jiqizhixin.com/uploads/editor/619c28c1-02c0-4db3-99e2-862ffbe74cb8/1744863301405.png)

**合作伙伴介绍**

**黄大年茶思屋科技网站**  
黄大年茶思屋科技网站是致力于推动科学与技术交流的开放平台。我们汇聚全球科学家、研究人员和技术专家，共同探讨最前沿的学术话题，分享最新的科研成果，激发创新思维的火花。  
网址：[https://www.chaspark.com](https://www.chaspark.com)

**腾讯青云计划**  
腾讯青云计划聚焦 AI 大模型等十大技术领域，面向全球招募顶尖实习生和毕业生。  
青云官网：[https://join.qq.com/qingyun.html](https://join.qq.com/qingyun.html)

**真格基金**  
真格基金创立于 2011 年，是国内最早的天使投资机构之一。  
网址：[https://www.zhenfund.com/](https://www.zhenfund.com/)

**博世集团**  
博世集团是全球领先的技术和服务供应商，在智能出行、工业技术、能源与建筑技术等领域持续深耕。  
网址：[https://www.bosch.com.cn/careers/](https://www.bosch.com.cn/careers/)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。