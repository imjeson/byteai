---

title: '快手可灵又一次进化了AI视频模型，继续遥遥领先？'
date: 2024-09-08
author: ByteAILab

---

可灵又双叒叕更新了。
目前对可灵的超创们，开放了他们继续进化的视频模型，以及新功能运动笔刷。

---

作为超创，第一时间拿到了资格，但是恰巧那天正在上海出差参加飞书的活动，没啥空玩，这刚回到北京，就先试了试。
主要就是两块：
**1. 图生视频新增「运动笔刷」功能（1.0模型），支持为图片中的人/物体等各种元素，指定特定的运动轨迹.**
**2. 基座模型升级：普通人现在能用的版本，模型应该是1.0版本，而我们现在内测拿到的是1.5版本的模型，质量更高，分辨率也从720P变成1080P.
花了几个小时，跑了些case，给大家看看这一版更新的效果。
但是有一说一，我觉得可灵的动作和更新速度，实在是过于迅猛了。。先说说这个运动笔刷.
为数不多的AI视频增强可控性的共识，Runway老大哥最先上的，然后Pixverse迭代出了自定义轨迹，即梦又搞出了动效画板.
但是总体逻辑都是框选/涂抹一个物体，让他做特定的轨迹与变形运动.
可灵的运动笔刷跟Pixverse的逻辑是一样的，可以自定义运动轨迹.
比如当你拿出旅游的海边照片.
你可以直接涂上你想运动的区域，然后用画笔拖个你想让它咋运动.
给大家放个case.
动的还是很自然的.
唯一难受的点就是运动笔刷只能搭配线上的1.0版本才能用，内测版的1.5模型用不了运动笔刷，适配还没做完。
然后就是最重要的可灵1.5版本的新模型.
测了一堆case，我的感觉就是:**文生视频的审美有了大幅进化，整体一致性更强，人物表演更强，修复了色差的BUG，更加高清.**
一个个说.
**1. 审美**
文生视频是最能看出来，这个模型的审美是啥样的，说实话，之前的可灵的审美就很快手，土土的，跟Runway这种很影视经验沉淀极深的公司比还是有不少差距.
但是这次发布的1.5版本模型，审美上终于是能看了，摆脱了过去那种很土的影子.

这些内容请到原文链接查看。如有需要，请访问 [原文链接](https://www.aixinzhijie.com/article/6846618)。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。