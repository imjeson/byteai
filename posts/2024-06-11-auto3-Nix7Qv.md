---
title: 'Gcore发布AI应用，为终端用户提供无缝性能'
date: 2024-06-12
author: ByteAILab

---

新的AI解决方案实现了全球范围内预训练机器学习模型的快速、安全和经济有效部署，位于边缘
全球边缘AI、云、网络和安全解决方案提供商Gcore今日宣布推出Gcore在边缘推理，这是一项突破性解决方案，为AI应用提供超低延迟体验。![图片](https://ai-techpark.com/wp-content/uploads/2024/06/Gcore-Unveils-960x540.jpg){ width=60% }

---
这一创新解决方案实现了预训练机器学习（ML）模型在边缘推理节点的分布式部署，确保无缝、实时推理。
Gcore在边缘推理赋予各行业的企业（包括汽车、制造、零售和技术）以经济有效、可伸缩和安全的AI模型部署。生成式AI、物体识别、实时行为分析、虚拟助手和生产监控等用例现在可以在全球范围内迅速实现。
Gcore在边缘推理运行在Gcore庞大的全球网络中，拥有180多个边缘节点，所有节点都通过Gcore先进的低延迟智能路由技术相互连接。每个高性能节点位于Gcore网络的边缘，策略性地将服务器放置在终端用户附近。在边缘推理上运行的是NVIDIA L40S GPU，这是专门设计用于AI推理的市场领先芯片。当用户发送请求时，边缘节点确定到最近可用推理区域的路由，并以最低延迟实现典型响应时间低于30毫秒。
这一新解决方案支持各种基本ML和自定义模型。Gcore ML模型中心提供的开源基础模型包括LLaMA Pro 8B、Mistral 7B和Stable-Diffusion XL。模型可以被选择和训练以适应任何用例，然后在全球范围内分发到Gcore在边缘推理节点。这解决了开发团队面临的一个重要挑战，即AI模型通常在训练时运行在相同的服务器上，结果性能较差。
Gcore在边缘推理的优势包括:
- 成本有效的部署: 灵活的定价结构确保客户只支付他们使用的资源。
- 内置DDoS防护: 通过Gcore基础设施，ML端点会自动受到DDoS攻击的保护。
- 出色的数据隐私和安全性: 该解决方案具有内置的符合GDPR、PCI DSS和ISO/IEC 27001标准的规范。
- 模型自动扩展: 可用于处理负载波动，因此模型始终准备好支持高需求和意外激增。
- 无限物体存储: 与不断发展的模型需要相匹配的可扩展S3兼容云存储。

Gcore CEO Andre Reitenbach表示:“Gcore在边缘推理使客户能够专注于让他们的机器学习模型得到训练，而不用担心部署全球AI应用所需的成本、技能和基础设施。在Gcore，我们相信边缘是实现最佳性能和终端用户体验的地方，这就是为什么我们不断创新，以确保每个客户都获得无与伦比的规模和性能。Gcore在边缘推理提供了所有的动力，却没有任何烦恼，为现代、有效、高效的AI推理体验提供了一种方式。”

了解更多信息，请访问https://gcore.com/inference-at-the-edge
在AITechPark探索关于人工智能、物联网、网络安全、人工智能新闻以及行业专家的深入见解！

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。