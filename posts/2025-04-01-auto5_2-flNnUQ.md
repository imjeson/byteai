---

title: '一脑多机！智源的新发布，让不同机器人轻松协作'
date: 2025-04-02
author: ByteAILab

---

3 月 29 日，智源研究院在 2025 中关村论坛 “未来人工智能先锋论坛” 上发布首个跨本体具身大小脑协作框架 RoboOS 与开源具身大脑 RoboBrain，可实现跨场景多任务轻量化快速部署与跨本体协作，**推动单机智能迈向群体智能**，为构建具身智能开源统一生态加速场景应用提供底层技术支持。 

开源链接如下：

具身多模态大脑模型 RoboBrain
- GitHub：https://github.com/FlagOpen/RoboBrain
- Gitee：https://gitee.com/flagopen/robo-brain
- Huggingface：https://huggingface.co/BAAI/RoboBrain

为机器人操作任务设计的高质量异构数据集 ShareRobot
- GitHub：https://github.com/FlagOpen/ShareRobot
- Gitee：https://gitee.com/flagopen/share-robot
- Huggingface：https://huggingface.co/datasets/BAAI/ShareRobot

**增强长程操作任务能力  打造感知 - 认知 - 决策 - 行动闭环**

![图片](https://image.jiqizhixin.com/uploads/editor/bf251582-2315-4aa9-8954-133fa4a2a9b8/640.png)

在具身场景中，长程操作任务是机器人执行复杂任务的核心能力之一。

---
具身大脑 RoboBrain 融合了**机器人任务规划、可操作区域感知、轨迹预测**的三维能力，通过将抽象指令映射为具象动作序列，增强长程操作任务的能力。

RoboBrain 由三个模块组成：用于任务规划的**基座模型**、用于可操作区域感知的**A-LoRA 模块**和用于轨迹预测的 **T-LoRA 模块**。在推理时，模型首先感知视觉输入，并将输入指令分解为一系列可执行的子任务，然后执行可操作区域感知和轨迹预测。RoboBrain 采用多阶段训练策略，使其具备长历史帧记忆和高分辨率图像感知能力，进而提升场景感知和操作规划的能力。

RoboBrain 在任务规划、可操作区域感知和轨迹预测评测任务中均表现出卓越性能。

在**任务规划**方面，RoboBrain 在不牺牲通用能力的前提下，在机器人规划评测集 OpenEQA、ShareRobot（自建）和 RoboVQA 上多个维度优于 GPT-4V、Claude3 等 6 个当时领先的闭源 / 开源 MLLMs。

![图片](https://image.jiqizhixin.com/uploads/editor/6b46a14b-b34f-4758-ac69-124752efd2f5/640.png)

*RoboBrain 在具身规划评测基准上的性能*

在**可操作区域感知**方面，RoboBrain 在 AGD20K 测试集上的平均精度超过了当时最先进的开源模型 Qwen2-VL，验证了其在指令理解和物体属性方面的卓越能力。

![图片](https://image.jiqizhixin.com/uploads/editor/a32ade27-bf87-4a86-99cc-483429254345/640.png)

*RoboBrain 在可操作区域感知基准上的性能*

在轨迹预测方面，RoboBrain 预测的操作轨迹具有与真实轨迹较高的相似度，展现了其在轨迹预测中的高精度和稳定性。RoboBrain 的未来迭代版本会持续提高轨迹预测的能力。

![图片](https://image.jiqizhixin.com/uploads/editor/f3323ebe-05fb-4428-8390-8b8f8025bd23/640.png)

*RoboBrain 在轨迹预测基准上的性能*

目前，RoboBrain 能够**解读**人类指令和视觉图像，以**生成**基于实时图像反馈的行动计划和评估，**预测**每一步的轨迹并**感知**相应的可操作区域。具体而言，RoboBrain 能够有效利用环境信息和交互对象的状态 —— 无论是从第一人称还是第三人称视角捕捉的图像 —— 生成针对不同类型机器人操作任务的任务规划，并基于人类指令和视觉信息，提供合理的可操作区域，并能在不同场景中表现出良好的泛化能力。

![图片](https://image.jiqizhixin.com/uploads/editor/2d95933c-ae9f-464a-8f7c-dc95caf873b4/640.png)

**具身大脑 RoboBrain**、**小脑技能库**以及**跨机器人数据中枢**，是跨本体框架 RoboOS 的核心要素。具身大脑 RoboBrain，负责全局感知与决策，构建动态时空感知、规划指导和反馈纠错机制；小脑技能库，负责低延迟精准执行，实现柔性与精密操作等；跨机器人数据中枢，负责实时共享空间、时间和本体记忆，为决策规划与优化协作操作提供信息支持，从而形成感知 - 认知 - 决策 - 行动的闭环。

**一脑多机实现跨本体协作  从单体智能迈向群体智能**

跨本体具身大小脑协作框架 RoboOS，基于**“大脑-小脑” 分层架构**，通过模块化设计、智能任务管理和跨本体协作，为机器人提供高效、灵活、可扩展的底层支持，实现从单机智能到群体智能的跃迁。 

在 RoboOS 的分层架构下，具身大脑 RoboBrain 的复杂场景感知与决策能力，可与小脑技能库的高效执行能力深度结合，确保协作框架在**长周期、高动态任务**中的稳定运行。实现大脑模型（如 LLM/VLM）与小脑技能（如抓取、导航）的 “即插即用”，目前，可支持松灵双臂、睿尔曼单 / 双臂、智元人形、宇树人形等不同类型的具身本体。 

通过共享记忆系统（空间记忆 / 时间记忆 / 本体记忆），实现**多个机器人之间的状态同步与智能协作，**突破传统 “信息孤岛” 限制，实现跨本体协作控制。

RoboOS 可**动态管理多机器人任务队列**，支持优先级抢占与资源优化分配，确保复杂场景下实时响应，实现高并发任务调度。

此外，RoboOS 可基于执行反馈动态调整策略，结合环境变化，**持续优化任务规划**，提升鲁棒性，做到实时闭环优化。

![图片](https://image.jiqizhixin.com/uploads/editor/3832d1fa-45b3-4b60-b960-037ffcedd44a/1743480163730.png)

*基于 RoboOS 及 RoboBrain 的多机器人跨本体协作递送任务 Demo*

在 “递送苹果和水果刀” 的任务场景中，基于 RoboOS 及 RoboBrain，睿尔曼单臂机器人（转运）、宇树人形 G1（挑拣水果）、松灵双臂机器人（挑拣水果刀）分工协作。

整体任务流程是睿尔曼调用 “导航技能” 移动至餐桌前，宇树 G1 调用 “视觉抓取技能” 完成指定物体的挑拣，睿尔曼调用 “抓取技能” 提起果篮并导航至松灵餐桌前。紧接着，松灵调用 “抓取技能” 获取水果刀，并放置在果篮中心，睿尔曼依据 “空间记忆” 导航至办公桌位置，递送果篮后返回。

**RoboOS 接收** “拿离杯子最近的水果，并递送一把水果刀” **指令**后，**递送 RoboBrain 进行任务拆解**，并将拆解后的子任务分发给 3 台跨本体机器人。RoboBrain 通过 "空间记忆" 感知环境，确定果篮、苹果位置，并拆解任务为 “宇树 G1 挑拣苹果→睿尔曼传递果篮→松灵机器人抓取水果刀→睿尔曼返回”。

各机器人本体执行子任务过程中，**由 RoboOS 提供端云协作能力**，将任务规划为技能粒度，实现云端 RoboBrain 分发规划，端侧执行技能并实时反馈。RoboBrain 识别 “离杯子最近的水果位置”、“果篮抓取位置 affordance”、“水果刀抓取位置 affordance”、“果篮空闲位置 Pointing”，经由** RoboOS 递送指导各机器人本体完成任务。**

**“即插即用” 快速轻量化泛化部署  打造统一生态**

RoboOS 作为面向多机器人系统的跨本体具身大小脑协作框架，专为解决当前具身智能落地过程中的通用性适配与多机调度难题而设计。针对**异构本体难以统一接入、任务调度效率低、缺乏动态错误反馈机制**等痛点，基于 RoboOS 的 “大小脑协同” 的架构范式，云端的具身大脑 RoboBrain 负责**统一的任务理解、规划决策与上下文感知**，本体侧则接入轻量级的小脑执行模块，实现感知 - 认知 - 决策 - 行动的闭环协作。

该机制能够动态感知本体差异、灵活适配操作指令、自动修复异常行为，有效提升系统在复杂任务场景下的鲁棒性与泛化性。RoboOS 原生支持**异构机器人本体的灵活接入**，以 Profile 模板机制快速完成机器人能力建模与适配。

本体的小脑模块可调用包括开源技能库、自研低阶控制器等多种技能接口，形成一个**支持模块复用、即插即用**的运行体系，大幅降低开发门槛与接入成本。

在云端，RoboOS 提供完备的模型适配与 API 接入能力，兼容自研的多模态 VLM，**作为可插拔的大脑决策引擎**，从而在服务机器人、工业自动化、智慧物流、智能制造等领域支撑复杂任务的多机协作需求。

借助 RoboOS 的**端云一体化协同能力与动态调度机制**，整个系统不仅具备高度的扩展性与可迁移性，更为未来具身智能的规模部署与生态构建奠定了通用操作系统级的基础。

![图片](https://image.jiqizhixin.com/uploads/editor/f549dc1d-5e25-47bd-98ea-cb8e5aaac40f/640.png)

RoboOS 基于智源研究院研发的并行训练与推理框架 FlagScale，原生支持多机器人系统的端云协同能力，打造具身智能的统一底座。系统在设计上充分考虑 “多机器人 - 多模态 - 多任务” 场景，具备极高的可扩展性与低时延响应能力。

在端侧部署中，机器人注册即可自动与云端部署的 RoboBrain 大脑建立双向通信链路，通过高效发布 - 订阅机制实现实时任务调度与状态反馈，指令响应延迟低于 10ms，满足复杂动态任务的闭环控制需求。

面向机器人在长期运行中产生的海量感知与行为数据，RoboOS 提供基于内存优化的数据访问引擎，支持 TB 级别历史数据的内存随机访问能力，为任务复现、异常回溯、跨任务知识迁移等场景提供基础能力。结合 RoboBrain 的任务推理与策略优化模块，历史数据还可用于多机之间的协作知识共享，实现更强的智能演化与自主学习能力。

此外，FlagScale 作为底层支撑框架，支持大模型在**多设备间的并行推理与多任务协同调度，可无缝集成视觉语言模型、轨迹生成模块、感知识别等子系统**，全面释放具身大模型的系统潜力。

目前，智源研究院依托多模态大模型技术优势资源，正在联合北大、清华、中科院等高校院所以及银河通用、乐聚、加速进化、宇树等产业链上下游企业，积极建设具身智能创新平台，重点开展数据、模型、场景验证等研究。

此次智源研究院发布的跨本体具身大小脑协作框架 RoboOS 及开源具身大脑 RoboBrain，将有机融合和广泛链接不同构型的具身本体与丰富多元的具身模型，加速具身智能跨本体协作与规模化应用。

**开放、协作、共享，是具身智能生态繁荣的必经之路**，智源研究院愿携手更多产业合作伙伴，共绘具身智能生态蓝图。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。