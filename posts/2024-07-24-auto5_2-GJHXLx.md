---
title: '为大模型提供全新科学复杂问答基准与测评体系，UNSW、阿贡、芝加哥大学等多家机构联合推出SciQAG框架'
date: 2024-07-25
author: ByteAILab

---

编辑 | ScienceAI

问答（QA）数据集在推动自然语言处理（NLP）研究发挥着至关重要的作用。高质量QA数据集不仅可以用于微调模型，也可以有效评估大语言模型（LLM）的能力，尤其是针对科学知识的理解和推理能力。

---


尽管当前已有许多科学QA数据集，涵盖了医学、化学、生物等领域，但这些数据集仍存在一些不足。

其一，数据形式较为单一，大多数为多项选择题（multiple-choice questions），它们易于进行评估，但限制了模型的答案选择范围，无法充分测试模型的科学问题解答能力。相比之下，开放式问答(openQA)可以更加全面地评估模型的能力，但缺乏合适的评估指标。

其二，现有数据集的内容很多来源于大学及以下等级的教科书，难以评估LLM在实际学术研究或生产环境中的高层次知识保持能力。

其三，这些基准数据集的创建依赖人类专家标注。

应对这些挑战对建立更全面的QA数据集至关重要，也有利于对科学LLM的更精准评估。

为此，美国Argonne国家实验室、芝加哥大学Ian Foster 教授（2002年戈登贝尔奖得主）团队、澳大利亚新南威尔士大学Bram Hoex教授UNSW AI4Science团队、AI4Science 公司GreenDynamics 与香港城市大学揭春雨教授团队联合提出了 SciQAG，第一个基于大语言模型（LLM）从大型科学文献语料库中自动生成高质量科学开放性问答对的新型框架。

论文链接：https://arxiv.org/abs/2405.09939
github链接：https://github.com/MasterAI-EAM/SciQAG

基于SciQAG，研究人员构建了一个大规模、高质量、开放式的科学QA数据集 SciQAG-24D ，包含从24个科学领域的22,743篇科学论文中提取的188,042 个QA对，旨在服务LLM的微调和科学问题解答能力评估。

实验证明，在 SciQAG-24D 数据集上对 LLM 进行微调可以显著提高它们在开放式问题解答和科学任务中的性能。

数据集、模型和评估代码已经开源(https://github.com/MasterAI-EAM/SciQAG)，以促进AI for Science社区对开放式科学问答的共同开发。

SciQAG框架与SciQAG-24D基准数据集

SciQAG由QA生成器和QA评估器组成，旨在大规模快速生成基于科学文献的多样化开放式问答对。首先，生成器将科学论文转换为问答对，然后评估器过滤掉不符合质量标准的问答对，从而获得高质量的科学问答数据集。

QA生成器

<!-- 此部分省略 -->

QA评估器

<!-- 此部分省略 -->

SciQAG 框架的运用

<!-- 此部分省略 -->

SciQAG-24D 基准数据集

<!-- 此部分省略 -->

实验结果

<!-- 此部分省略 -->

总结与展望

<!-- 此部分省略 -->

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。