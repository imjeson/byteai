title: 'NTT在ICML 2025上推动AI的准确性、安全性和成本优化'
date: 2025-07-23
author: ByteAILab

---

会议展示了AI和ML基础研究与开发领域的全球最新突破
新闻亮点：

NTT研究和NTT R&D科学家在ICML 2025上发表了12篇论文，这是全球最负盛名的AI和机器学习会议之一。![图片](https://ai-techpark.com/wp-content/uploads/NTT-Advan.jpg){ width=60% }

---

NTT研究的AI物理组共同作者的三篇论文包括新的发现，揭示了旨在提高大型语言模型（LLM）准确性和事实关联的算法如何可能对模型的事实回忆和推理能力产生负面影响。
NTT R&D科学家共同作者的8篇论文提出了全球首个“可移植调优”技术，旨在降低再训练成本并提高生成AI的可持续性。

NTT Research, Inc. 和 NTT R&D，NTT (TYO:9432) 的两个部门的研究人员在2025年7月13日至19日于温哥华举行的第42届国际机器学习会议（ICML 2025）上发表了12篇论文。ICML 2025是一场专注于促进人工智能领域中机器学习发展的全球领先会议，涵盖应用领域包括机器视觉、计算生物学、语音识别和机器人技术等。
NTT研究的AI物理组（PAI）的三篇论文提升了我们对大型语言模型（LLM）准确性、机器学习可解释性以及递归神经网络（RNN）短期记忆的神经机制的理解。
在论文《变换器中的表现粉碎：一种基于知识编辑的综合研究》中，研究人员探讨了为什么知识编辑（KE）算法——一种修改LLM权重以修复不正确、过时或不需要的事实关联的算法——可能会对模型的事实回忆准确性和推理能力产生负面影响。研究人员表明，“表现粉碎”这一现象是导致模型事实回忆和推理性能下降的原因，KE“无意中影响了目标以外的实体的表示，扭曲了模型推断未知知识的相关结构”。
在《原型SAE：用于大型视觉模型的自适应和稳定字典学习》的论文中，研究人员揭示了稀疏自编码器（SAE）作为提高机器学习可解释性的字典学习框架的基本局限性：严重的不稳定性削弱了其可靠性和作为可解释性工具的有效性。研究人员提出了一种解决方案，即原型SAE（及其变体，放松的原型SAE），显著增强了SAE的稳定性。
在论文《RNN中的短期记忆机制的动力学阶段》中，研究人员探讨了短期记忆中神经机制的未知角色。这项工作提供了对这些短期记忆机制的新见解，并提出了可实验测试的预测以进一步推进系统神经科学研究。
NTT研究PAI组负责人田中秀典表示：“作为一家公司，NTT致力于开发能够实现可持续发展的AI技术，尊重人类自主性，确保公平与开放，并保护安全和隐私。实现这些积极成果始于通过科学考察对AI ML进行基础层面的探索。我为NTT研究PAI组和我们在NTT R&D的同事所做的工作感到骄傲，并且能够在ICML 2025上与AI学术界分享我们的研究成果是一种莫大的荣幸。”
除了PAI组的录用论文外，NTT R&D实验室在日本的科学家还共同发表了8篇论文。
其中一篇论文，《可移植奖励调优：面向不同预训练模型的可重用微调》，提出了全球首个“可移植调优”技术，该技术消除了在更新基础模型时重新训练专门AI模型的需求，从而显著降低再训练成本并提高定制生成AI的可持续性。
另一篇论文，《基于隐式贝叶斯推理的差分隐私上下文学习准确性改进的合理令牌放大》，提出了合理令牌放大（PTA），首次理论性地揭示了基于差分隐私（减轻数据泄露的一种方法）添加“噪声”如何降低LLM的准确性。这项技术预计将促进LLM在处理与个人用户相关的数据的领域，如医疗、政府和金融中的应用。
在《K2IE：用于非均匀泊松过程的基于核方法的核强度估计器》中，研究人员展示了对大型数据集泊松过程计算效率的重大改进，这一过程用于分析和预测事件模式，从社交媒体平台的帖子到疾病暴发等。
其他五篇由NTT R&D科学家撰写或共同撰写的论文包括：

《协变量偏移下的正无标AUC最大化》
《通过零阶优化对神经网络的黑箱训练的自然扰动》
《学习生成投影以减少异构线性规划问题的维度》
《针对决策依赖分布的随机非凸问题的引导零阶方法》
《深度里奇变换与深浅联合群等变机器的统一通用性定理》

此外，NTT R&D研究人员还展示了关于模型合并的海报《多个模型之间的线性模式连接模除置换对称性》。以往研究提出了通过利用神经网络固有的置换对称性合并两个预训练模型的方法。该研究对此方法进行了扩展，实现了三种或更多模型的同时合并，并展示了合并模型的性能随着合并模型数量的增加而提升。
NTT致力于结合信任、诚信和创新，赋能企业和社区，以尖端的AI解决方案推动全球的效率、安全和进步。NTT研究PAI组成立于2025年4月，致力于研究AI的本质，旨在“解决生物智能与人工智能之间的相似性，进一步揭示AI机制的复杂性，并建立信任，从而实现人类与AI的更和谐融合”。
欲了解NTT如何创新AI以创造更美好的未来，请访问：https://www.global.ntt/innovation/artificial-intelligence
有关NTT研究PAI组的更多信息，请访问：https://ntt-research.com/pai-group

索引

Nishi, K., Ramesh, R., Okawa, M., Khona, M., Tanaka, H., & Lubana, E. S. (2024). Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing. ArXiv. https://arxiv.org/abs/2410.17194  
Fel, T., Lubana, E. S., Prince, J. S., Kowal, M., Boutin, V., Papadimitriou, I., Wang, B., Wattenberg, M., Ba, D., & Konkle, T. (2025). Archetypal SAE: Adaptive and Stable Dictionary Learning for Concept Extraction in Large Vision Models. ArXiv. https://arxiv.org/abs/2502.12892  
Kurtkaya, B., Dinc, F., Yuksekgonul, M., Cirakman, E., Schnitzer, M., Yemez, Y., Tanaka, H., Yuan, P., & Miolane, N. (2025). Dynamical phases of short-term memory mechanisms in RNNs. ArXiv. https://arxiv.org/abs/2502.17433  
Chijiwa, D., Hasegawa, T., Nishida, K., Saito, K., & Takeuchi, S. (2025). Portable Reward Tuning: Towards Reusable Fine-Tuning across Different Pretrained Models. ArXiv. https://arxiv.org/abs/2502.12776  
Yamasaki, Y., Niwa, K., Chijiwa, D., Fukami, T., Miura, T. (2025). Plausible Token Amplification for Improving Accuracy of Differentially Private In-Context Learning Based on Implicit Bayesian Inference. OpenReview. https://openreview.net/forum?id=skAjaAEuA2  
Kin, H., Iwata, T., Fujino, A. (2025). K2IE: Kernel Method-based Kernel Intensity Estimators for Inhomogeneous Poisson Processes. OpenReview. https://openreview.net/forum?id=XKuTFM93mG  
Kumagai, A., Iwata, T., Takahashi, H., Nishiyama, T., Adachi, K., Fujiwara, Y. (2025). Positive-Unlabeled AUC Maximization Under Covariate Shift. OpenReview. https://openreview.net/forum?id=HQEPgICjBS  
Sawada, H., Aoyama, K., Hikima, Y. (2025). Natural Perturbations for Black-Box Training of Neural Networks by Zeroth-Order Optimization. OpenReview. https://openreview.net/forum?id=ULAQ9GmJlo  
Iwata, T., Sakaue, S. (2025). Learning to Generate Projections for Reducing Dimensionality of Heterogeneous Linear Programming Problems. OpenReview. https://openreview.net/forum?id=LnoTEuVhud  
Hikima, Y., Sawada, H., Fujino, A. (2025). Guided Zeroth-Order Methods for Stochastic Non-Convex Problems with Decision-Dependent Distributions. OpenReview. https://openreview.net/forum?id=cRmuEY7jhb  
Sonoda, S., Hashimoto, Y., Ishikawa, I., Ikeda, M. (2025). Deep Ridgelet Transform and Unified Universality Theorem for Deep and Shallow Joint-Group-Equivariant Machines. OpenReview. https://openreview.net/forum?id=JKsxKPXXUd  
Ito, A., Yamada, M., Kumagai, A. (2025). Linear Mode Connectivity between Multiple Models modulo Permutation Symmetries. OpenReview. https://openreview.net/forum?id=qaJuLzY6iL  

Business WireBusiness Wire是一个值得信赖的新闻来源，为新闻组织、记者、投资专业人士和监管机构直接提供新闻，通过其多项专利的NX网络将新闻引入编辑系统和领先的在线新闻源。Business Wire在全球拥有18个新闻室，以满足传播专业人士和新闻媒体的需求。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。