---

title: 'Inworld Runtime：首个针对消费者应用的AI运行时'
date: 2025-08-17
author: ByteAILab

---

今天，Inworld AI发布了Inworld Runtime——首个专为扩展消费者应用设计的AI运行时。![图片](https://ai-techpark.com/wp-content/uploads/Inworld-Runtime.jpg){ width=60% }

---
它允许开发人员更快地从原型过渡到生产，并支持用户从10人增长到1000万人，几乎无需修改代码。通过自动化AI操作，Inworld Runtime释放了工程资源用于新产品开发，并提供工具来设计和部署无代码实验。Inworld目前的合作伙伴，包括主要媒体公司、AAA游戏制作公司和AI原生初创企业，已经利用Runtime作为其AI堆栈的基础，创造出面向下一代实时、数百万用户的AI功能和体验。

旨在加速Inworld内部开发，现在可让所有消费者建设者使用
Inworld团队的初衷在于确保AI的好处触及每一个人，通过实现下一代消费者应用。创始团队来自Google和DeepMind，他们认识到AI在商业自动化和专业应用中的势头，而消费者界面却滞后于此。公司最初与Xbox、Disney、NVIDIA、Niantic和NBCUniversal等游戏和媒体合作伙伴合作，开发AI代理，这些应用需要大语言模型（LLM）在对话AI方面的卓越表现。

为了加速与这些客户的合作，Inworld建立了Runtime作为内部基础设施，以应对消费者AI的独特需求：在数百万并发用户的规模下保持实时性能，以及用户特定的专注于参与度的质量期望，成本控制在每用户每天不到一美分。当来自健康/健身、学习和社交应用的公司开始接触Inworld时，团队发现这些公司面临的挑战与Runtime内部解决的问题完全相同，因此决定将其公开发布。

“我们构建Runtime是因为我们自己需要它。现有工具无法提供我们的合作伙伴所需的速度和规模，”Inworld AI首席执行官Kylan Gibbs表示。“当我们意识到每个消费者AI公司都面临这些障碍时，我们知道必须开放我们所构建的。我们看到行业达到了一个拐点，成千上万的建设者都在遇到我们曾经遇到的扩展障碍，因此我们在过去一年里努力增加超出我们内部需求的功能，以创建加速整个消费者AI生态系统的通用后端。”

消费者AI的领导者需要的三个关键因素
经过四年的消费者AI应用部署，Inworld发现了决定成功或失败的三个关键因素。在这三方面的卓越表现都是必须的，任何一方面的弱点都将阻止消费者AI功能或应用达到市场领导地位：

1. 从原型到生产的时间
虽然创建AI演示只需几个小时，但达到生产就绪状态通常需要6个月以上的基础设施和质量改进工作。团队必须处理供应商的故障、实施备份、管理速率限制、配置和加速计算能力、优化成本并确保一致的质量。Inworld与品类领导者的合作显示，大多数消费者AI项目要么实现飞跃，要么在原型和可扩展现实之间停滞和死亡。

2. 新产品开发的资源分配
发布后，大多数工程团队将超过60%的时间用于维护任务：调试供应商更改、管理模型更新、处理规模问题和优化成本。这样会导致可用于新功能开发的资源极为有限，造成产品停滞不前，而竞争对手则在不断前进。Inworld对此有直接的体验，甚至创新团队也会陷入维护周期而无法构建用户下一个想要的功能。

3. 实验速度
消费者的偏好不断演变，但传统的部署周期为2-4周，无法与此速度相匹配。团队需要测试数十种变体，衡量真实用户的影响，并扩大成功的变体，所有这些都必须没有代码部署和应用商店审批的摩擦。与行业各方合作的经历显示，学习速度最快的团队将赢，但现有基础设施使得快速迭代几乎不可能。

“我们在19天内从原型扩展到100万用户，并且成本降低超过20倍。”——Fai, Status首席执行官

Inworld Runtime的技术设计
Inworld Runtime通过多项创新提供这些能力，包括：
1. 自适应图
基于C++的图执行系统，解决了大多数AI框架面临的跨平台扩展局限性，支持Node.js、Python等SDK。开发人员使用经过预优化的节点作为构建块（并包含来自顶级提供商的LLM、TTS、STT、知识、记忆等API），这些节点处理低级集成工作，并自动优化组件间的数据流。相同的图可无缝扩展，从10个测试用户到1000万并发用户，几乎无需修改代码和管理端点。配有用户友好的界面，直接支持从原型到生产的快速跃迁，仅需几天时间，无需几个月。

2. 自动化MLOps
除了基本操作外，Runtime还提供自包含的基础设施自动化，集成了捕获每次交互的日志、跟踪和指标的遥测。可操作的洞见，如识别错误、用户模式和优化机会，通过Inworld的可观察性和实验管理平台Portal被呈现。Runtime在提供商之间执行自动故障转移，智能管理模型间的容量，并智能处理速率限制。它还支持定制的本地部署，为企业优化模型托管。随着应用扩展，Inworld提供访问所有必要的云基础设施，以训练、调整和托管打破默认模型成本质量边界的自定义模型。

3. 实时实验
一键部署或扩展实验。配置与代码分离，使得可以即时进行A/B测试，无需部署摩擦。Runtime可以通过SDK定义变体同时自动运行数百个实验，并通过Portal管理测试，测试不同的模型、提示、图形配置和逻辑流程。变化在几秒钟内部署，并自动测量对用户指标的影响。

Inworld Runtime早期采用者的成功案例
Runtime的部署展示了稳定的技术成就：

Inworld的最大合作伙伴（主要知识产权持有者、媒体公司和AAA工作室）已经利用Runtime作为其AI堆栈的基础
Wishroll在19天内从原型扩展到100万用户，同时成本降低超过95%
Little Umbrella能够发布新的AI游戏，同时使用Inworld减少对现有标题的更新和维护工作
Streamlabs构建了一款多模态实时流媒体助手，包含六个月前无法实现的功能
Bible Chat升级和扩展了他们的语音功能，同时将语音成本降低了85%
Nanobit为数百万用户提供个性化的AI叙事，达到了可持续的单位经济学

可用性和定价
开发者可以立即通过下载Runtime SDK开始，地址为inworld.ai/runtime，提供全面的文档和迁移指南。Runtime与Cursor、Claude Code、Google CLI、Windsurf和Zencoder等代码助手原生兼容。开发者可以从自己的项目开始，或使用Inworld的模板和演示应用作为灵感。Runtime灵活部署，可在客户端应用、任何云提供商的服务器上，或通过Inworld管理的模型托管进行定制本地安装。一旦投入生产，Portal可以用于可观察性和快速实验。

Runtime的定价完全基于使用量，无需前期成本。开发者可以体验所有模型和功能，只需为成功扩展的部分付费，确保与消费者应用经济学相一致，成本必须随着使用量的增长保持可持续。有访问Anthropic、Google、Mistral和OpenAI的最先进模型的权限，开发人员可以轻松测试并选择最适合其用例的模型。Runtime还通过快速的提供商Groq、Tenstorrent和Fireworks AI提供访问顶级开源模型Deepseek、Llama和Qwen。与Microsoft或Google的已有合作关系的开发者可以通过Azure Marketplace和Google Cloud Marketplace访问Runtime。

GlobeNewswire是全球最大的新闻稿分发网络之一，专门向媒体、投资社区、个人投资者和公众传递企业新闻、财务披露和多媒体内容。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。