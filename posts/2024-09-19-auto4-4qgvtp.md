---
title: '阿里史上最大规模开源发布，超GPT-4o 、Llama-3.1！'
date: 2024-09-20
author: ByteAILab

---

今天凌晨，阿里巴巴官宣了史上最大规模的开源发布，推出了基础模型Qwen2.5、专用于编码Qwen2.5-Coder和数学的Qwen2.5-Math。

这三大类模型一共有10多个版本，包括0.5B、1.5B、3B、7B、14B、32B和72B，适用于个人、企业以及移动端、PC等不同人群不同业务场景的模型。

---


如果不想进行繁琐的部署，阿里还开放了旗舰模型Qwen-Plus 和 Qwen-Turbo的API，帮助你快速开发或集成生成式AI功能。

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/8FD7B96F5E34993C64020C0DB54F4C00/1726713554125/ljNPP0FE3YsdnBrtrUqN6eP-MNTs.png)

开源地址：[https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e)

Github：[https://github.com/QwenLM/Qwen2.5?tab=readme-ov-file](https://github.com/QwenLM/Qwen2.5?tab=readme-ov-file)

在线demo：[https://huggingface.co/spaces/Qwen/Qwen2.5](https://huggingface.co/spaces/Qwen/Qwen2.5)

API地址：[https://help.aliyun.com/zh/model-studio/developer-reference/what-is-qwen-llm](https://help.aliyun.com/zh/model-studio/developer-reference/what-is-qwen-llm)

下面「AIGC开放社区」详细为大家介绍这些模型的性能特点以及测试结果。

**Qwen2.5系列性能测试**

本次阿里开源的最大版本指令微调模型Qwen2.5-72B在MMLU-Pro

MMLU-redux、GPQA、MATH、GSM8K、HumanEval、MBPP等全球知名基准测试平台的测试结果显示。

*虽然Qwen2.5只有720亿参数，但在多个基准测试中击败了Meta拥有4050亿参数的最新开源Llama-3.1指令微调模型*；全面超过了Mistral最新开源的Large-V2指令微调模型，成为目前最强大参数的开源模型之一.

![图片1](http://www.jesonc.com/FqP0ei8aBdZe5JYDM40bNiy8nvHj)

即便是没有进行指令微调的基础模型，其性能同样超过Llama-3-405B.

![图片2](http://www.jesonc.com/Ftv6CvpRaaX9_59RLKQihNVsTjc4)

阿里开放API的旗舰模型Qwen-Plus，其性能可以媲美闭源模型GPT4-o 和Claude-3.5-Sonnet.

![图片3](http://www.jesonc.com/FhJBTYmKx6susVC4GNjEQctS6xMN)

此外，Qwen2.5系列首次引入了140 亿和320亿两种新参数模型，Qwen2.5-14B 和 Qwen2.5-32B.

指令微调模型的性能则超过了谷歌的Gemma2-27B、微软的Phi-3.5-MoE-Instruct，*与闭源模型GPT-4o mini相比，只有三项测试略低其他基准测试全部超过*.

![图片4](http://www.jesonc.com/FuDJzTk56u2IEJDl-sf5E2ZIhctN)

自阿里发布CodeQwen1.5 以来，吸引了大量用户通过该模型完成各种编程任务，包括调试、回答编程相关的问题以及提供代码建议.

本次发布的Qwen2.5-Coder-7B指令微调版本，在众多测试基准中，击败了那些知名且有较大参数的模型.

![图片5](http://www.jesonc.com/FnNkIdUy3KzxEoBPlSdzOyGsIJL1)

前不久阿里首次发布了数学模型Qwen2-Math，本次发布的Qwen2.5-Math 在更大规模的高质量数学数据上进行了预训练，包括由 Qwen2-Math 生成的合成数据。同时增加了对中文的支持，并通过CoT、PoT和 TIR的能力来加强其推理能力.

其中，Qwen2.5-Math-72B的整体性能超越了Qwen2-Math-72B指令微调和著名闭源模型GPT4-o.

![图片6](http://www.jesonc.com/FqBxm0CswT7ftOaAimMhwFwNmzjM)

其实从上面这些测试数据不难看出，即便是参数很小的模型，在质量数据和架构的帮助下，同样可以击败高参数模型，这在能耗和环境部署方面拥有相当大的优势。而阿里本次发布的Qwen2.5系列将小参数模型的性能发挥到了极致.

**Qwen2.5系列简单介绍**

Qwen2.5系列支持中文、英文、法文、西班牙文、葡萄牙文、德文、意大利文、俄文、日文等超过29种主流语言。与 Qwen2类似，Qwen2.5语言模型支持高达 128K tokens，并能生成最多 8K tokens的内容.

与Qwen-2相比，*Qwen2.5系列的预训练数据大幅度增长达到了惊人的18万亿tokens，超过了Meta最新开源Llama-3.1的15万亿*，成为目前训练数据最多的开源模型.

知识能力显著增强，Qwen2.5在 MMLU 基准测试中，与 Qwen2-7/72B 相比从70.3提高到74.2，从84.2提高到86.1. Qwen2.5 在 GPQA/MMLU-Pro/MMLU-redux/ARC-c 基准测试上也有显着改进.

![图片7](http://www.jesonc.com/Fn1hy4vwRd9OVu2KHS-mQGL9MKWD)

Qwen2.5能够生成更符合人类偏好的响应，与Qwen2-72B-Instruct相比，Qwen2.5-72B-Instruct的Arena-Hard分数从48.1显着提高到81.2 ，MT-Bench分数从9.12提高到9.35.

数学能力获得增强，在融合了Qwen2-math的技术后，Qwen2.5的数学能力也得到了快速提升。在MATH基准上，Qwen2.5-7B/72B-Instruct的得分从Qwen2-7B/72B-Instruct的52.9/69.0提高到75.5/83.1.

此外，Qwen2.5在指令跟踪、生成长文本（从1k增加到超过8K标记）、理解结构化数据（例如表格）以及生成结构化输出（尤其是JSON）方面实现了显着改进。同时对系统提示的多样性更具弹性，增强了聊天机器人的角色扮演实施和条件设置.
---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。