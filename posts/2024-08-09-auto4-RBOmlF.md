---

title: '曾毅：从科学和社会的视角对当代人工智能的反思'
date: 2024-08-10
author: ByteAILab

---

来源：[见地沙龙](https://mp.weixin.qq.com/s/V22xDtCP9TiWOrgclxtoAw)

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1723183929651/FpN38QjKVwb2lL_GTCjBcCWvkg2L.jpg)

曾  毅 人工智能科学家，中国科学院自动化研究所研究员

本文为曾毅先生在2023见地年会的发言，原主题为《从科学和社会的视角对当代人工智能的反思》。

我讲几个关键词。

---


第一个关键词是“自大”。

现在对于人工智能对世界的描述是用什么来描述的？是用X来描述的，就是参数。现在的人工智能研究，参数是百亿的、千亿的、万亿的，但有统计学家说，统计学就是用200个参数来描述人工智能学家用几百亿的参数才能做的事情。

这给我们很大的反思：当人工智能研究有万亿的参数来描述一个世界的时候，这个万亿的参数实际上就是万亿的X，代表万亿种变化，也代表着万亿的不确定性。既然它有万亿个不确定性，也有万亿个可能性。这个时候，它实际上带给我们的是万亿个未知，而这种未知是无限的想象还是无限的风险，我觉得是非常危险的地方。所以，人工智能研究者，实际上将这种不确定性、风险描述成了机遇，这是非常危险的。虽然这种参数的扩充使得我们对于世界的描述更为精确，更多变，但是如果人工智能不是真正基于智能的，那么它带来的意外也是无限放大的，这在我看来是一种无知的自大。

第二个关键词是“说谎”。

人工智能是如何开始的？在一个屋子里，有一个机器，有一个人，当你无法区分你的对话对象是人还是机器的时候，说明这个机器达到了人类水平的智能，这是图灵提出的图灵测试。所以人工智能起源于“欺骗”，它通过欺骗达到衡量智能的水平。但图灵从来没有说过，当人工智能达到足以欺骗人类的时候，你应当用这种服务去欺骗人类。但这却是现在的人工智能天天在做的事情，就是用看似智能的事情来欺骗人类。

比如说到ChatGPT有什么样的能力，有人说它已经达到了人类水平。但是搞人工智能的人很少讲，当它的正确率远远超过人类的时候，比如做一件事，人的正确率只有90%，它可以做到99.9%，但当你看剩余00.1%的时候发现，那些错误不是人类会犯的错误，人工智能会犯。人工智能的研究者，特别是产业的推动者，绝不希望你看到这一面。

...

(以下内容省略)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。