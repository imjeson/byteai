---
title: '看透物体的3D表示和生成模型：NUS团队提出X-Ray'
date: 2024-05-07
author: ByteAILab
---

AIxiv专栏是机器之心发布学术、技术内容的栏目。过去数年，机器之心AIxiv专栏接收报道了2000多篇内容，覆盖全球各大高校与企业的顶级实验室，有效促进了学术交流与传播。

---
如果您有优秀的工作想要分享，欢迎投稿或者联系报道。投稿邮箱：liyazhou@jiqizhixin.com；zhaoyunfeng@jiqizhixin.com

项目主页：[https://tau-yihouxiang.github.io/projects/X-Ray/X-Ray.html](https://tau-yihouxiang.github.io/projects/X-Ray/X-Ray.html)
论文地址：[https://arxiv.org/abs/2404.14329](https://arxiv.org/abs/2404.14329)
代码地址：[https://github.com/tau-yihouxiang/X-Ray](https://github.com/tau-yihouxiang/X-Ray)
数据集：[https://huggingface.co/datasets/yihouxiang/X-Ray](https://huggingface.co/datasets/yihouxiang/X-Ray)

如今的生成式AI在人工智能领域迅猛发展，在计算机视觉中，图像和视频生成技术已日渐成熟，如Midjourney、Stable Video Diffusion [1]等模型广泛应用。然而，三维视觉领域的生成模型仍面临挑战。

目前的3D模型生成技术通常基于多角度视频生成和重建，如SV3D模型[2]，通过生成多角度视频并结合神经辐射场(NeRF)或者3D高斯渲染模型（3D Gaussian Splatting）技术逐步构建3D物体。这种方法主要限制在只能生成简单的、无自遮挡的三维物体，且无法呈现物体内部结构，使得整个生成过程复杂而且不完美，显示出该技术的复杂性和局限性。

究其原因，在于目前缺乏灵活高效且容易泛化的3D Representation (3D表示)。

X射线能够穿透并记录关键物体内外表面信息，受到这个启发，新加坡国立大学(NUS)胡涛博士带领研究团队发布了一种全新的3D表示—X-Ray，它能够序列化地表示从相机摄像角度看过去的物体的逐层次的物体表面形状和纹理，可以充分利用视频生成模型的优势来生成3D物体，可以同时生成物体的内外3D结构。

本文将详细展示X-Ray技术的原理、优势及其广泛的应用前景。

技术革新：物体内外表面的3D表示方法

X-Ray表示：从相机中心开始朝向物体方向的H×W个矩阵点发射射线。在每条射线方向上，逐个记录与物体的表面相交点的L个包含深度、法向量和颜色等的三维属性数据，然后将这些数据组织成L×H×W的形式，实现任意3D模型的张量表示，这就是该团队提出的X-Ray表示方法。

给定一个3D模型，通常是三维网格，首先设置一个相机观测该模型，然后通过光线投影算法(Ray Casting Algorithm)来记录每个相机射线与物体相交的所有表面的属性，包括该表面的深度，法向量，颜色等，为了指示方便，用表示该位置是否存在表面。

然后，获取所有相机射线等相交表面点，即可得到一个完整的X-Ray 3D表达。

给定一个X-Ray，也可以通过解码过程转化回3D模型，这样只需要通过生成X-Ray即可生成3D模型。

基于X-Ray表示的3D模型生成

为了生成高分辨率的多样3D X-Ray模型，该团队使用了与视频格式相似的视频扩散模型架构。这个架构可以处理...

未来展望：新表示带来无限可能

随着机器学习和图像处理技术的不断进步，X-Ray的应用前景无限广阔。

未来，这种技术可能会与增强现实（AR）和虚拟现实(VR)技术结合，为用户创造出完全沉浸式的3D体验。教育和训练领域也可以从中受益，例如通过3D重建提供更为直观的学习材料和模拟实验。

此外，X-Ray技术在医疗影像和生物技术领域的应用，可能改变人们对复杂生物结构的理解和研究方法。期待它如何改变与三维世界的互动方式。

参考文献：

[1] Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, Varun Jampani, and Robin Rombach. Stable video diffusion: Scaling latent video diffusion models to large datasets. CoRR, 2023.

[2] Vikram Voleti, Chun-Han Yao, Mark Boss, Adam Letts, David Pankratz, Dmitry Tochilkin, Christian Laforte, Robin Rombach, Varun Jampani. SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion. arXiv preprint arXiv:2403.12008, 2024.

[3] Aaron van den Oord, Oriol Vinyals, Koray Kavukcuoglu. Neural Discrete Representation Learning. NeurIPS-2017.

[4] Tao Hu, Wenhang Ge, Yuyang Zhao, Gim Hee Lee. X-Ray: A Sequential 3D Representation for Generation. arXiv preprint arXiv: 2404.14329v1, 2024.

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。