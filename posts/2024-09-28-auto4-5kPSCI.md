---

title: 'Llama-4使用10万块GPU训练、更好开源，扎克伯格亲口确认！'
date: 2024-09-29
author: ByteAILab

---

全球最大社交平台Meta（Facebook、Instagram、WhatsApp等母公司）联合创始人兼CEO扎克伯格接受了，前Vox著名记者Cleo Abram的专访。

主要谈到了Meta最新发布的变革性产品全息AR眼镜，开源大模型、生成式AI的发展以及全球开发者非常关心的Llama-4。

---


扎克伯格亲口确认了Llama-4使用了超过10万个GPU进行训练。目前Meta公开的算力是60万块GPU，也就是说Llama-4已经成为Meta的主力拳头产品，使用更多的GPU训练有助于突破AI极限。

扎克伯格认为AI大模型的极限非常高，远没有达到尽头。例如，Llama 3使用了2万块GPU进行训练；Llama 4使用了超10万块GPU，Llama 5则会使用更多。这就是说在如此多的GPU训练下，模型的性能和商业潜力会进一步被人类挖掘。

...

Meta又开源了首个多模态大模型Llama-3.2，这是Llama-3系列的一次重大升级，一共有4个版本。

1B和3B参数专为边缘和移动设备设计，而较大的11B和90B参数模型为 Llama 生态系统带来了新的视觉能力。

1B 和 3B支持 12K 令牌的上下文长度，擅长总结、指令遵循和文本重写等任务，并且能在移动设备上本地运行。更重要的是，这些轻量级模型发布时便对高通和联发科的硬件进行了适配，并针对 Arm 处理器进行了优化，广泛的兼容性将加速其在各种移动和物联网设备中的应用。

...

Meta 提供了多种编程语言的客户端代码，包括 Python、Node.js、Kotlin和 Swift，以实现与不同应用和平台的集成。

Llama Stack 具有部署灵活性，为 Distribution Server 和 Agents API Provider 提供预制 Docker 容器以减少配置错误，并针对不同运营规模提供从单机单节点分布到与 AWS、Databricks、Fireworks 和 Together AI 合作的可扩展云部署等解决方案。在 iOS上通过 PyTorch ExecuTorch 提供设备端分布，方便开发直接在移动设备上运行的AI 应用。

由于安全、合规或性能考虑需要内部AI能力的公司可以利用Dell Technologies支持的本地分发。可通过将多个API提供商打包到一个单一端点，并与合作伙伴合作以适应Llama Stack API，Meta为这些多样化环境中的开发者创造了一致且简化的体验。

这种方法显著降低了构建Llama模型的复杂性，加速了AI在广泛的应用程序和用例中的创新。

开源地址：[https://www.llama.com/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama32](https://www.llama.com/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama32)
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。