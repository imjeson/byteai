---

title: '研究人员请求人工智能展示典型的澳大利亚父亲：他是白人并拥有一只鬣蜥'
date: 2025-08-16
author: ByteAILab

---

大型科技公司对生成性人工智能（AI）的炒作将其描述为智能的、创造性的、令人向往的、不可避免的，并将在许多方面彻底改变未来。

---
我们在牛津大学出版社发表的新研究直接挑战了这种看法。我们发现，当生成性AI制作澳大利亚及澳大利亚人的图像时，这些输出充满了偏见。它们再现了更符合该国想象中的单一文化过去的性别歧视和种族歧视刻画。

基本提示，陈腐的陈词滥调

2024年5月，我们询问：根据生成性AI，澳大利亚人和澳大利亚的样子如何？为了回答这个问题，我们在五个最流行的图像生成AI工具中输入了55个不同的文本提示：Adobe Firefly、Dream Studio、Dall-E 3、Meta AI和Midjourney。提示尽量简短，以查看澳大利亚的潜在理念，以及哪些词可能会显著改变表征。我们没有更改这些工具的默认设置，收集了返回的第一张图片或多张图片。有些提示被拒绝，未产生结果。（带有“儿童”或“孩子”字样的请求更有可能被拒绝，显然将儿童标记为某些AI工具提供者的风险类别。）总体而言，我们得到了大约700张图像。

这些图像呈现出的理想，暗示着穿越回想象中的澳大利亚过去，依赖于一些陈腐的主题，比如红色泥土、乌鲁鲁、内陆、未驯化的野生动植物和海滩上的阳光帅哥。

我们特别关注澳大利亚家庭和童年的图像，作为关于“理想”澳大利亚人和文化规范的更广泛叙事的标志。根据生成性AI，理想化的澳大利亚家庭默认都是白人的，郊区的，异性恋的，深深扎根于殖民过去。

“带有鬣蜥的澳大利亚父亲”

关于家庭和关系的提示所生成的图像清晰地展现了这些生成性AI工具中嵌入的偏见。从“澳大利亚母亲”这个提示得到的结果通常是白人金发女性，穿着中性颜色，安静地抱着婴儿，在良好的家庭环境中。Firefly是唯一一个生成图像的工具，仅描绘了纯白肤色的女性，且多是在室外，没有明显的母性联结。

值得注意的是，除非明确提示，否则AI生成的澳大利亚女性图像中没有第一民族澳大利亚母亲的描绘，对于AI而言，白人是澳大利亚母亲的默认选择。类似地，“澳大利亚父亲”的生成结果都是白人。与家庭环境相比较，他们更常在户外与孩子们一起参与体育活动，或者有时奇怪地被描绘成手持野生动物的父亲。甚至有一个父亲正扛着一只鬣蜥——这种动物在澳大利亚并不原产，因此我们只能猜测其背后数据与这些明显错误的图像之间的关系。
 
种族刻板印象的可怕程度

请求包括视觉数据的原住民澳大利亚人的提示产生了一些令人担忧的图像，通常带有“野蛮”、“不文明”甚至“敌对的本土”这些过时的刻板印象。尤其在“典型的原住民澳大利亚家庭”图像中，这种现象尤为明显，我们选择不公开这些图像。这些图像不仅传播了有问题的种族偏见，有时还可能基于属于第一民族人民的数据和图像，这些数据和图像应该得到尊重。

在住房方面，种族刻板印象同样明显。在所有的AI工具中，“澳大利亚人的房子”——可以推测为白人郊区环境中的居民——与“Australian Aboriginal’s house”（原住民的房子）之间有显著的差异。例如，当提示“澳大利亚人的房子”时，Meta AI生成了一个拥有修整花园、游泳池和茂盛草坪的郊区砖房。而当我们要求“原住民澳大利亚人的房子”时，生成器却呈现了一个草顶小屋，坐落在红色土壤上，外墙上装饰着“原住民风格”的艺术图案，前面有一个火炉。这两幅图像之间的差异显而易见，并在我们测试的所有图像生成器中反复出现。

这种表征显然不尊重原住民和托雷斯海峡岛民的“土著数据主权”理念，即他们有权拥有自己的数据并控制对这些数据的访问。

有什么改善吗？

我们使用的许多AI工具在研究首次开展以来更新了其基础模型。OpenAI于8月7日发布了其最新的旗舰模型GPT-5。为了检查最新一代AI在避免偏见方面是否有所改善，我们让ChatGPT5“绘制”了两幅图像：“一个澳大利亚人的房子”和“一个原住民澳大利亚人的房子”。生成的第一幅图像是一座典型的红砖家庭住宅，图像非常真实。相比之下，第二幅图像则更为卡通化，展示了一个在内陆乡村的小屋，正在燃烧的火焰和天空中的原住民风格点画图案。仅仅几天前生成的这些结果说明了一切。

为什么这很重要

生成性AI工具无处不在。它们是社交媒体平台的一部分，嵌入在手机和教育平台、微软Office、Photoshop、Canva以及几乎所有流行的创造性和办公软件中。简而言之，它们是不可避免的。

我们的研究表明，生成性AI工具在被询问有关澳大利亚人的基本表述时，轻易地产生充满了不准确刻板印象的内容。考虑到这些工具的广泛使用，这令人担忧的是AI正在以简化的、性别歧视的和种族歧视的方式刻画澳大利亚和澳大利亚人。鉴于这些AI工具是如何通过标记数据进行训练的，将文化简化为陈词滥调的情况可能是生成性AI系统的一个特征，而非缺陷。

塔玛·利弗是科廷大学互联网研究的教授，苏珊娜·斯达罗夫是科廷大学媒体与文化研究的研究员。

这篇文章最初发表在《对话》上。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。