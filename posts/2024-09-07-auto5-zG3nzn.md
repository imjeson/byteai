---
title: '高通公司万卫星出席全球AI芯片峰会：以终端侧AI创新开启智能计算全新体验'
date: 2024-09-08
author: ByteAILab

---

9月6日，2024全球AI芯片峰会在北京召开。全球AI芯片峰会至今已成功举办六届，现已成为国内规模最大、规格最高、影响力最强的产业峰会之一。

---
本届峰会以“智算纪元 共筑芯路”为主题，共50多位来自AI芯片、Chiplet、RISC-V、智算集群与AI Infra系统软件等领域的嘉宾参与进行了报告、演讲、高端对话和圆桌Panel，对AI芯片筑基智算新纪元进行了全方位解构。

高通AI产品技术中国区负责人万卫星受邀参加大会开幕式，并发表了以“终端侧AI创新开启智能计算全新体验”为主题的演讲。他在演讲中提出，高通公司持续深耕AI领域，面对当前生成式AI的飞速发展，高通的领先SoC解决方案提供了异构计算系统和具备高性能低功耗的强大NPU，能够满足当前丰富生成式AI用例的不同需求和算力要求，并对实现最佳性能和能效至关重要。利用高通公司推出的领先第三代骁龙8移动平台和骁龙X Elite计算平台，终端侧生成式AI现已应用于旗舰终端和用例，终端侧生成式AI的时代已经到来。

![演讲照片](https://image.jiqizhixin.com/uploads/editor/947b14b3-cf5d-4d9f-b8d5-7cb4adb5d300/1725617360485.jpeg)

演讲全文如下：

大家上午好！非常感谢主办方的邀请，让我能够代表高通公司再次参加本次活动，跟大家分享AI芯片在生成式AI这个当前最火热的赛道上，高通公司做的一些工作。今天我给大家带来的演讲主题是“终端侧AI创新开启智能计算全新体验”。

作为一家芯片公司，高通为AI应用的加速专门打造了高算力、低功耗的NPU。首先，我会给大家简单介绍一下这款高算力、低功耗NPU的演进路径。可以说，这是一个非常典型的由上层AI用例驱动底层硬件设计的演进过程。可以回想一下，在2015年左右，大家所了解的AI用例主要是比较简单的语音识别、语音唤醒、图片分类、图片识别等。这些用例背后的底层模型，都是一些比较浅层的、规模比较小的CNN网络。那个时候，我们就给这颗NPU搭配了标量和矢量的硬件加速单元，满足对于性能的需求。

在2016年之后，计算摄影的概念在市场上得到普及，我们也将研究方向从传统的语音识别、图像分类扩展到了对图片和视频的处理。随着基于像素级别的处理对算力的要求越来越高，支撑这些应用的模型除了更大规模、更多层数的CNN网络之外，还有其他新型的网络，比如LSTM、RNN，甚至大家现在非常熟悉的Transformer。这些网络对算力和功耗的要求非常敏感，所以我们在标量和矢量加速单元的基础之上，进一步配备了一颗张量加速器，以提供更加充沛的算力，满足应用对像素级、对Transformer时序网络、对算力的要求。

2023年开始，大模型，尤其是大语言模型开始真正火爆起来。其实70%以上的大语音模型都是基于Transformer。因此，我们给这颗NPU专门配备了Transformer支持。同时，我们在保持标量、矢量、张量等硬件加速的基础之上，增加更多的硬件加速单元，包括集成独特的微切片推理技术，进一步针对对算力要求和Transformer并行化要求较高的模型推理进行加速。

未来我们会持续地加大对NPU的投入。生成式AI的未来一定是多模态的趋势，所以今年我们也在致力于实现将一些真正的多模态大模型完整地运行在端侧。在今年2月份的MWC巴塞罗那2024上，高通公司基于第三代骁龙8移动平台展示了一个demo，就是让超过70亿参数的多模态语言模型（LMM）完整地跑在端侧。

从模型规模来讲，高通未来会支持更大规模的大语言模型，今年我们将有希望看到超过100亿参数以上的大语言模型完整运行在端侧。当然，终端侧需要跑多大的模...
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。