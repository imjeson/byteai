---

title: '担心X平台的AI事实检查员可能会增加阴谋论的传播'
date: 2025-07-03
author: ByteAILab

---

埃隆·马斯克的X社交媒体平台决定聘请人工智能聊天机器人撰写事实检查，这一举动可能会增加“谎言和阴谋论”的传播，前英国技术部长达米安·柯林斯警告道。

---
柯林斯指责马斯克的公司“把新闻编辑的工作交给了机器人”，这是在X于周二宣布将允许大型语言模型撰写社区注释以澄清或纠正有争议的帖子后发表的评论，用户在此之前需对此进行审批。这些注释之前由人类撰写。X表示，利用AI撰写事实检查注释——这些注释出现在某些X帖子下方——“提升了改进互联网信息质量的先进方法”。X的产品副总裁基思·科尔曼表示，人类会审查AI生成的注释，且仅当拥有多元观点的人认为有用时，这些注释才会显示出来。“我们设计这个试点项目是为了让AI帮助人类，人类来做决定，”他说。“我们相信这可以提供高质量和高信任度。此外，我们在推出试点时发布了一篇论文，由麻省理工学院、华盛顿大学、哈佛大学和斯坦福大学的教授和研究人员共同撰写，阐述了为何这种AI与人类的结合是如此有前景的方向。”但是，柯林斯表示，该系统已经容易受到滥用，AI代理在社区注释中工作的可能性可能导致“人们看到和决定信任的信息的工业操控”，该平台拥有约6亿用户。这是美国科技公司对人类事实检查员的最新反击。上个月，谷歌表示，用户创建的事实检查，包括专业事实检查机构的检查，将在其搜索结果中被降权。它表示，这些检查“对用户并未提供显著的附加价值”。今年1月，Meta宣布它将取消在美国的人类事实检查员，将在Instagram、Facebook和Threads上采用自己的社区注释系统。X的一篇研究论文批评了专业事实检查员，称其通常速度缓慢且规模有限，并且“缺乏大部分公众的信任”。AI创建的社区注释“有潜力更快生成，且生成所需的精力较少，质量也高”，它说。人类和AI撰写的注释将被提交到同一池中，X用户将投票选择哪些注释最有用，并应显示在平台上。该研究论文称，AI将起草“中立性方面得到良好证据支持的总结”。社区注释的信任“不是来自谁撰写注释，而是来自评估他们的人”，它说。但是，英国事实检查组织Full Fact的AI负责人安迪·达德菲尔德表示：“这些计划可能会增加人类审查员需要检查的草稿注释的负担，打开了一种令人担忧且合理的情况，即注释可能会完全由人工智能草拟、审核并发布，而没有人类输入所提供的仔细考虑。”阿兰·图灵研究所新兴技术与安全中心的研究助理塞缪尔·斯托克威尔表示：“人工智能可以帮助事实检查员处理每天通过社交媒体流通的大量声明，但这很大程度上取决于X对这些AI‘注释撰写者’的质量控制所采取的保护措施，以防它们在输出中错觉并放大错误信息。AI聊天机器人通常难以理解细微之处和上下文，但擅长自信地提供听起来令人信服的答案，即使这些答案不真实。如果不加以有效应对，这可能是一种危险的组合。”研究人员发现，公众对人类撰写的社区注释的信任度明显高于简单的错误信息提示。对去年的总统选举期间几百个误导性帖子进行的分析发现，在三分之二的案例中，准确的社区注释没有被展示，这表明它们没有被用户上票。这些误导性帖子，包括声称民主党人正在进口非法选民以及2020年总统选举被盗的说法，获得了超过20亿次的浏览量，据反对数字仇恨中心的数据。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。