---
title: 'Alluxio Enterprise 3.6 提升 AI 模型交付与训练效率'
date: 2025-05-22
author: ByteAILab

---

Alluxio，AI 和数据加速平台，今天宣布推出 Alluxio Enterprise AI 3.6，提供了惊人的模型分发、模型训练检查点写入优化和增强的多租户支持。![图片](https://ai-techpark.com/wp-content/uploads/Alluxio-Enterprise.jpg){ width=60% }

---
这一最新版本使组织能够显著加快 AI 模型的部署周期，减少训练时间，并确保在云环境中实现无缝的数据访问。
  
随着模型规模的增长和推理基础设施跨多个区域，AI 驱动的组织面临着日益增长的挑战。从训练到生产环境分发大型模型会引入显著的延迟问题和不断上升的云成本，而漫长的检查点写入过程则严重拖慢了模型训练周期。
  
“我们很高兴地宣布，我们已经将 AI 加速平台的能力扩展到了模型训练之外，以加速和简化将 AI 模型分发到生产推理服务器环境的过程，”Alluxio 的创始人兼首席执行官 Haoyuan (HY) Li 说。“通过与在 AI 前沿的客户合作，我们不断推动人们一年前想象的可能性的边界。”
  
Alluxio Enterprise AI 版本 3.6 包括以下关键功能：

高性能模型分发 – Alluxio Enterprise AI 3.6 利用 Alluxio 分布式缓存来加速模型分发工作负载。通过在每个区域放置缓存，模型文件只需从模型库复制到每个区域的 Alluxio 分布式缓存一次，而不是每台服务器各复制一次。推理服务器可以直接从缓存中检索模型，进一步的优化包括在推理服务器上的本地缓存和内存池利用。基准测试表明，Alluxio AI 加速平台的吞吐量达到了 32 GiB/s，超出了 11.6 GiB/s 的网络容量 20 GiB/s。

快速模型训练检查点写入 – 在早前推出的 CACHE_ONLY 写入模式基础上，版本 3.6 新增了 ASYNC 写入模式，在 100 Gbps 网络环境下提供高达 9GB/s 的写入吞吐量。这一增强显著减少了模型训练检查点所需的时间，通过将写入操作转移到 Alluxio 缓存而不是直接写入底层文件系统，避免了网络和存储瓶颈。使用 ASYNC 写入模式，检查点文件异步写入到底层文件系统，以优化训练性能。

新的管理控制台 – Alluxio 3.6 引入了全面的基于 Web 的管理控制台，旨在增强可观察性并简化管理。该控制台显示了关键集群信息，包括缓存使用情况、协调器和工作节点状态，以及读取/写入吞吐量和缓存命中率等关键指标。管理员还可以直接通过界面管理挂载表、配置配额、设置优先级和 TTL 策略、提交缓存作业，并收集诊断信息，而无需使用命令行工具。

此版本还为 Alluxio 管理员引入了几个增强功能：

多租户支持 – 本次发布通过与 Open Policy Agent (OPA) 的无缝集成，带来了强大的多租户能力。管理员现在可以为多个团队定义细粒度的基于角色的访问控制，使用单个、安全的 Alluxio 缓存。

多可用区故障转移支持 – Alluxio Enterprise AI 3.6 添加了在多可用区架构中数据访问故障转移的支持，确保高可用性和更强的数据访问弹性。

FUSE 中的虚拟路径支持 – 新增的虚拟路径支持允许用户为数据资源定义自定义访问路径，创建一个抽象层，用以掩盖底层存储系统中的物理数据位置。

可用性
Alluxio Enterprise AI 版本 3.6 可在此处下载：https://www.alluxio.io/demo

GlobeNewswire 是全球最大的新闻发布网络之一，专门向媒体、投资界、个人投资者和公众交付企业新闻稿、财务披露和多媒体内容。
  
---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。