---
title: 'AI pioneers turn whistleblowers and demand safeguards'
date: 2024-06-08
author: ByteAILab

---

OpenAI正面临内部纷争和外部批评，涉及其实践以及其技术可能带来的潜在风险。![图片](https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/06/ai-whistleblowers-artificial-intelligence-ethics-society-letter.jpg){ width=50% }

---


五月，包括前OpenAI“超级对齐”工作的负责人Jan Leike在内的几位知名员工离开了这家公司。Leike的离职发生在OpenAI推出其新旗舰GPT-4o模型后不久，该模型在其春季更新活动上被誉为“神奇”。

据报道，Leike的离开是由于对安全措施、监控实践以及攀附华而不实的产品发布而非安全考虑的持续分歧。

Leike的离职为该AI公司敞开了潘多拉魔盒。前OpenAI董事会成员提出了针对CEO Sam Altman和公司领导层的心理虐待指控。

OpenAI日益增长的内部动荡与外界对像公司自己的语言模型这样的生成式AI技术可能带来的潜在风险的关切相吻合。批评者警告说，先进的AI超越人类能力的即将到来的存在威胁，以及更直接的风险，如工作替代以及将AI武器化用于信息误导和操纵活动。

作为回应，一群来自OpenAI、Anthropic、DeepMind和其他领先AI公司的现任和前任员工共同起草了一封致这些风险的公开信。

“我们是先进AI公司的现任和前员工，我们相信AI技术潜力可以为人类带来前所未有的好处。我们也了解到这些技术所带来的严重风险，”信中写道。

“这些风险范围从进一步巩固现有的不平等，到操纵和误导，到失去对自主AI系统的控制，可能导致人类灭绝。AI公司本身已经承认了这些风险，各国政府以及其他AI专家也承认了这些风险。”

这封信已经有13位员工签署，并获得了AI先驱Yoshua Bengio和Geoffrey Hinton的认可，其中提到四个核心要求，旨在保护告发者，促进在AI开发方面更大的透明度和问责：

- 公司不会强制执行不恭维条款，或因员工提出与风险相关的问题而采取报复行动。
- 公司将支持一种可验证匿名的员工与董事会、监管机构和独立专家沟通提出关注的过程。
- 公司将支持一个批评开放的文化，并允许员工公开分享与风险相关的担忧，同时适当保护商业秘密。
- 公司不会对在其他流程失败后分享机密与风险相关信息的员工采取报复行动。

“他们等其他人赞成‘快速行动，打破陈规’的做法，但这与这种强大且理解不足的技术所需的相反，”曾因对公司价值观和缺乏责任感的担忧离开OpenAI的前员工Daniel Kokotajlo说。

这些要求出现在OpenAI迫使即将离职的员工签署保密协议，以防他们批评公司或失去其已投资权益的报告中。OpenAI首席执行官Sam Altman承认对这种情况感到“尴尬”，但声称公司实际上从未收回过任何人的已投资权益。

随着AI革命不断发展，OpenAI的内部纷争和告密者的要求突显了这项技术周围的成长阵痛和未解决的伦理困境。

另请参阅：OpenAI瓦解了五个秘密影响行动

想要从行业领袖那里了解更多关于AI和大数据的知识吗？查看在阿姆斯特丹、加利福尼亚和伦敦举行的AI&Big Data Expo。这一全面的活动与其他领先活动同时在这里举行，包括智能自动化大会、BlockX、数字转型周和网络安全与云计算博览会。

探索由TechForge提供的其他即将举行的企业技术活动和网络研讨会。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。