---

title: '应当对推动人工智能的大型语言模型进行公有制'
date: 2025-05-27
author: ByteAILab

---

大型语言模型（LLMs）迅速进入了历史研究的领域。

---
它们处理、注释和生成文本的能力正在转变学术工作流程。然而，历史学家处于一个独特的位置，可以提出一个更深层次的问题——谁拥有塑造我们对过去理解的工具？如今，最强大的大型语言模型由私人公司开发。尽管它们的投资巨大，但其目标——专注于利润、平台增长或知识产权控制——与历史学术的价值观（例如透明性、可重复性、可及性和文化多样性）往往并不一致。这引发了严重的担忧：a）不透明性：我们通常缺乏对训练数据和内嵌偏见的洞察；b）不稳定性：访问条款和能力可能会在没有通知的情况下改变；c）不平等性：许多研究人员，尤其是在资源较少的情况下，被排除在外。 

现在是时候为人文学科构建公共的、开放获取的大型语言模型——这些模型应基于来自我们图书馆、博物馆和档案馆的经过策划的、多语言的、扎根于历史的语料库进行训练。这些模型必须透明，对学术共同体负责，并获得公共资金的支持。构建这样的基础设施是具有挑战性的，但至关重要。就像我们不会将国家档案或学校课程外包给私人公司一样，我们也不应将我们最强大的解释性技术托付给他们。 

人文学科有责任并有机会创造文化意识、学术基础扎实的人工智能。让我们不仅要负责任地使用大型语言模型，还要负责任地拥有它们。学术诚信和公共知识的未来可能依赖于此。 

Prof Dr Matteo Valleriani  
Max Planck Institute for the History of Science, Berlin, Germany  
Have an opinion on anything you’ve read in the Guardian today? Please email us your letter and it will be considered for publication in our letters section.  
Explore more on these topics  
Artificial intelligence (AI)  
Academics  
Humanities  
Ethics  
Libraries  
Museums  
History  
letters  
Share  
Reuse this content  

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。