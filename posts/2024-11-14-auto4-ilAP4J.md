---
title: '大佬喊话，AI寒冬已来？'
date: 2024-11-15
author: ByteAILab

---

OpenAI的原联合创始人-Ilya Sutskever指出，使用大量未标记数据来理解语言模式和结构的训练阶段已经接近尾声。他提到，扩展训练的结果已经趋于平稳，意味着通过增加数据和算力来提升AI模型性能的方法（即Scaling Law）已经遇到瓶颈。

---


![图片来源：由无界AI生成](https://appserversrc.8btc.cn/upload/8FD7B96F5E34993C64020C0DB54F4C00/1731563668081/Ft9T_Gxr0ptXSltvqSSlUKINKmCL.png)

### 像ChatGPT这样的大型语言模型（LLMs）
当前扩展策略已达到极限

根据Ilya Sutskever的说法，简单地通过增加更多数据和计算资源来扩大规模已不足以实现有意义的进步。 Ilya表示，虽然增加计算能力仍然是提升AI性能的一个方式，但已经无法像以前那样通过不断堆砌算力和数据量来实现模型的大幅提升。 大模型企业需要采用更智能的训练技术，更加重视模型训练的方式和内容，而不仅仅是关注规模大小。

这种方法的转变代表了人工智能发展的关键转折点，超越了“越大越好”的理念。

预训练阶段，大模型被输入大量未分类数据以识别模式和结构的过程，一直是开发强大LLMs的基石。 这个阶段，模型通过消化各种文本——从书籍、文章到网站和社交媒体帖子——来学习语言表示，使其能够识别语法、语法和含义。 从过往发展上看，这种方法效果很好，通过简单地增加数据量，LLMs提高性能。 然而，Ilya Sutskever认为这种方法现在已经趋于平稳。增加更多数据所带来的性能提升正在减少，更重要的是，人们越来越意识到模型的有效性不仅取决于它处理的数据量，还取决于它接触到的数据的质量和结构。 意味着大模型企业必须重新思考他们的策略，以在LLMs的发展上取得进一步的进展，**换句话说，大模型进一步发展的大山跨不过去，也许就是一道“生死分割线”。**

### 向“更智能”训练的转变
应该更关注模型的细腻度

Ilya Sutskever提及研究人员现在需要考虑更先进的方法来完善学习过程，而不仅仅是增加数据集的大小。 包括改进训练期间使用的算法，优化数据管理，并引入更先进的技术，如强化学习或多模态训练，其中模型不仅接触到文本，还接触到图像、视频或其他形式的数据。 Ilya Sutskever关于未来的LLMs将需要“稍微思考更长时间”的评论强调了进步的另一个关键方面。 大模型需要在更长时间内进行更复杂推理的能力，对于需要深度理解、多步骤推理或长期记忆的任务越来越必要。 随着复杂性增长，大模型必须能够在更长的对话中保持上下文，执行更复杂的任务，并响应数据中更微妙的线索。

例如，像ChatGPT当前的LLMs可以在单次对话中生成令人印象深刻的连贯且与上下文相关的回应。 但是很明显，在长期交流中的上下文或处理复杂逻辑推理任务的时候，还存在很多困难。 **为了克服这一限制，未来的模型将需要实现更好的记忆机制和更复杂的处理能力，以便“思考”更长时间。** 随着计算能力的持续增长，**走在前列的大模型企业关注的重点**逐渐从简单地扩展模型转向更高效和更具上下文智能发展。涉及神经网络、机器学习算法以及人工智能系统处理和保留信息的方式的技术进步的结合。

未来有了更智能、思考更长时间的模型，人工智能可以变得更适应性，允许与用户进行更个性化、更准确、更有洞察力的互动。 当然如果技术有进一步落地，人工智能应用也将会实现在从医疗保健到金融到客户服务等多个行业的突破。 总之，**Ilya Sutskever强调了人工智能研究中一个关键时刻：随着LLMs的预训练阶段达到其极限，未来的进展取决于开发更智能的训练技术和提高模型在更长时间内保持上下文的能力。** **在当下，对于大模型企业来说，正确选择扩展的方向比以往任何时候都更为重要。** 大模型企业必须重新思考处理模型扩展的方法，少关注简单地增加更多数据和计算资源，更多地关注完善训练过程和开发能够更深入、更连贯地推理的模型。

### llya惊起千层浪，他的SSI什么来头？

SSI（Safe Superintelligence）由Ilya Sutskever、Daniel Levy和Daniel Gross三人创立，旨在开发远超人类能力的安全人工智能系统。 Ilya Sutskever曾强调，他们的首要产品将是关于超级智能的安全。 SSI在没有发布任何产品的情况下，三个多月就已经筹集了10亿美元现金，公司估值达到50亿美元。

**Ilya Sutskever 是 OpenAI 的联合创始人之一，在2024年5月离开。** 他是人工智能领域最具影响力的技术专家之一，曾师从被称为“人工智能教父”的 Geoffrey Hinton，也是扩展假设的早期倡导者。

![图：Sam Altman与Ilya Sutskever](https://appserversrc.8btc.cn/FlmvMXTyCWXkskKNUGi4nnE4mhBu)

Daniel Gross曾担任苹果公司AI技术负责人，也曾是前Y Combinator合伙人，而 Daniel Levy则是 OpenAI 的前员工。 SSI以常规的营利性结构运营，现在约10名员工，分布在加利福尼亚州的帕洛阿托以及以色列特拉维。 SSI的投资者包括顶级风险投资公司 Andreessen Horowitz、Sequoia Capital、DST Global 和 SV Angel，以及由 Nat Friedman 和 SSI 首席执行官 Daniel Gross 运营的投资合伙企业 NFDG。

### SSI是否能掀起大模型界的“研究山峰”

当然在这次众人关注的对话中，**Ilya也提到，SSI已经发现了一个新的研究领域，有可能改变我们对人工智能的理解。** 他将这一研究领域比作一座山，表示一旦攻克这座山，AI的“范式”将发生根本性的改变。 让大家对SSI未来的技术突破赋予期待，他们有可能带来一场AI领域的“革命”。 然而，具体的研究方向和细节仍未公开。

另一方面，也基于Ilya过往的工作经历，他多次表明他和SSI的目标不仅仅是推动AI技术的边界，更重要的是通过确保超级智能的安全，避免可能带来的伦理和社会风险。 尽管Scaling Law可能已遇到瓶颈，但SSI的探索表明，AI领域的进展依然充满潜力，且正在朝着更加复杂和安全的方向发展。 **从目前来看，AI的进步不再是单纯的技术竞争，更多的是如何平衡技术发展、安全、商业化之间的关系，无疑是一个具有挑战性的长期课题。** **随着新方法和新领域的突破，未来的人工智能可能会以一种全新的方式与我们相遇。**

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。