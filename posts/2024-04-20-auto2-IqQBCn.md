---
title: 'Meta通过开源Llama 3 LLM提高了水平'
date: 2024-04-21
author: Jeson

---

Meta推出了Llama 3，这是其最新一代的先进开源大型语言模型（LLM）。![图片](https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/04/IMG_0091-scaled.jpeg){ width=50% }

---
这家科技巨头声称，Llama 3在真实场景中建立了新的性能基准，超越了先前领先行业的模型如GPT-3.5。

“通过Llama 3，我们着手构建与当今最优秀专有模型相媲美的最佳开源模型”，Meta在一篇宣布发布的博文中表示。

最初推出的Llama 3模型是80亿和700亿参数版本。Meta表示，其团队仍在训练更大的4000亿+参数模型，这些模型将在未来几个月内发布，同时还将发布详细介绍工作的研究论文。

Llama 3历经两年多的研发，投入了大量资源用于收集高质量训练数据、扩大分布式训练、优化模型架构以及创新的指导微调方法。

Meta的700亿参数的指导微调模型在12个关键使用场景（如编码、推理和创意写作）的人类评估中胜过了GPT-3.5、Claude等规模可比的LLMs。该公司的80亿参数预训练模型也在热门LLM评估任务中设立了新的基准：

“我们相信这些是目前同类别最优秀的开源模型”，Meta表示。

这家科技巨头通过“默认开源”方法发布这些模型，以进一步推动AI开发周围的开放生态系统。Llama 3将在所有主要云提供商、模型托管者、硬件制造商和AI平台上都可用。

Iris.ai的CTO兼联合创始人维克多·博特夫表示：“随着全球向AI监管的转变，Meta的Llama 3模型的推出是显著的。通过开源透明度，Meta与对负责任AI实践和伦理发展日益强调的发展方向保持一致。

此外，这为更广泛的社区教育提供了机会，因为开源模型有助于洞察发展并审查各种方法，这种透明度反馈到起草和执行监管中。”

随着Meta最新模型的推出，还推出了更新的一套AI安全工具，包括用于分类风险的第二代Llama Guard和用于评估潜在滥用的CyberSec Eval。还引入了一个名为Code Shield的新组件，用于在推理时过滤不安全的代码建议。

“然而，保持透视是重要的——一个模型仅仅是开源并不自动等同于道德的AI”，博特夫继续说道。“解决AI的挑战需要全面应对，解决数据隐私、算法偏见和社会影响等问题——这是全球新兴AI法规的重点。

虽然像Llama 3这样的开放倡议促进了审查和合作，但它们的真正影响取决于全面应对AI治理合规性，并将伦理纳入AI系统生命周期的承诺。Meta与Llama模型的持续努力是正确方向上的一步，但伦理AI需要所有利益相关者持续的承诺。”

Meta表示，公司已采取“系统级方法”来开发和部署负责任AI，Llama 3。虽然这些模型经过了广泛的安全测试，但公司强调开发人员应根据其应用程序的要求实现自己的输入/输出过滤。

该公司的集成了Llama 3的最终用户产品是Meta AI，Meta声称由于新模型的推出，Meta AI现在是全球领先的人工智能助手。用户可以通过Facebook、Instagram、WhatsApp、Messenger和网络访问Meta AI，用于生产力、学习、创造力和一般查询。

整合视觉功能的Meta AI的多模态版本即将推出，早期预览将在Meta的Ray-Ban智能眼镜上发布。

尽管Llama 3取得了可观的成就，但AI领域的一些人对Meta的动机采取“为社会福祉”开放方法表示怀疑。

但是，就在Mistral AI创立了Mixtral 8x22B开源模型的全新基准的一天之后，Meta的发布再次提高了可公开获得的LLMs的标准。
---
