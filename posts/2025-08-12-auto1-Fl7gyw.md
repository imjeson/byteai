---
title: '男子因ChatGPT查询停止食盐摄入后发展成罕见病症'
date: 2025-08-13
author: ByteAILab

---

一篇美国医学期刊警告称，使用ChatGPT获取健康信息可能存在风险，因为一名男子在咨询聊天机器人有关停止食盐摄入后，发展成了罕见的病症——溴中毒。

---
发表于《内科年鉴》的文章报道了一起病例，60岁男子因咨询ChatGPT而发展出溴中毒。文章将溴中毒描述为20世纪初就已“广为人知”的综合症，彼时被认为是近十分之一精神病入院的原因之一。患者告诉医生，在阅读有关氯化钠（即食盐）负面影响后，他咨询了ChatGPT，关于从饮食中消除氯化物的建议，之后持续三个月服用溴化钠。尽管他阅读到“氯化物可以被溴化物替代，但可能是出于其他目的，如清洁”。溴化钠在20世纪初被用作镇静剂。

这篇文章的作者来自华盛顿大学西雅图分校，他们表示，这一病例凸显了“人工智能的使用可能导致可避免的不良健康后果”。他们补充说，由于无法访问患者的ChatGPT对话记录，因此无法确定该男子获得的具体建议。然而，当作者自己使用ChatGPT查询氯化物可以替代的物质时，该响应也包括了溴化物，并且没有提供具体的健康警告，也没有询问作者为何寻求此类信息——“我们推测，医疗专业人士会这样做”，他们写道。作者警告称，ChatGPT及其他AI应用可能“生成科学不准确的信息，缺乏批判性讨论结果的能力，并最终助长误信息的传播”。

该公司上周宣布了聊天机器人的升级，声称其最大的优势之一在于健康方面。它表示，使用GPT-5模型的新版本ChatGPT将在回答健康相关问题时表现得更好，同时也更积极地“标记潜在的问题”，例如严重的身体或精神疾病。然而，它强调该聊天机器人并不能替代专业帮助。聊天机器人的指南也指出，它“不适合用于诊断或治疗任何健康状况”。

这篇发布于GPT-5推出前一周的期刊文章指出，该患者似乎使用的是ChatGPT的早期版本。尽管承认AI可以成为科学家与公众之间的桥梁，文章表示，该技术也有促进“脱离上下文的信息”的风险，而医疗专业人士不太可能在患者询问替代食盐时建议使用溴化钠。因此，作者表示，医生在检查患者获取信息的来源时，需要考虑AI的使用。

作者称，这名溴中毒患者在医院就诊时声称自己的邻居可能在毒害他。他还表示自己有多个饮食限制。尽管口渴，但他对于医院提供的水也表现出疑虑。在入院后24小时内，他试图逃离医院，并在被精神隔离后接受了精神病治疗。当患者稳定后，他报告出现了其他多种症状，这些症状提示溴中毒，包括面部痤疮、极度口渴和失眠。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。