```
---

title: '论文荣登计算机体系结构顶会ISCA，芯片架构成为边缘AI最佳并行计算选择'
date: 2024-08-14
author: ByteAILab

---

AI 大模型的爆发带动了 GPU 的强劲需求，从云端到边缘渗透的 AI 应用也将带动边缘 AI 服务器及加速处理器的需求。通过对比 GPGPU、FPGA、NPU 和 ASIC，可重构计算架构 CGRA 成为最适合边缘 AI 的并行计算架构。

---
由芯动力提出的可重构并行处理器（RPP）是比传统 CGRA 更适合大规模并行处理的计算架构，这不但通过试验评测得到证实，而且也通过 ISCA 会议得到国际学术权威的认可。基于 RPP 架构的 R8 芯片及后续更高性能的迭代芯片将是边缘 AI 服务器和 AI PC 的理想 AI 加速处理器选择。

目录

一、什么是边缘 AI？
二、边缘 AI 服务器市场趋势
三、适合边缘 AI 的理想计算架构
四、RPP 架构详解
五、RPP 处理器 R8 能效对比
六、RPP 处理器到国际学术权威认可
七、结语

一、什么是边缘 AI？
边缘 AI（AI Edge）是人工智能 (AI) 与边缘计算交叉的先进技术，这一概念源于 AI 从云端向边缘下沉的分布式计算范式转变。边缘 AI 的核心是将 AI 算法直接嵌入到产生大量数据的本地环境中，例如智能手机、物联网设备或本地服务器，通过位于网络 “边缘”（即更靠近数据源）的设备和系统进行实时数据处理和分析。

相对于传统的数据中心或云计算平台的 AI 训练或推理，边缘 AI 的主要优势在于 “就地处理”，大大减少了数据传输和处理的延迟，这在智能监控、自动驾驶、实时医疗诊断或工业自动化控制等应用场景中尤其重要。

实现边缘 AI 计算的设备和系统主要包括：

智能终端：主要用于产生或收集数据的设备，如智能传感器、智能手机、AI PC 或物联网设备等；
边缘 AI 服务器：直接对所收集数据进行处理和分析的边缘设备及软硬件系统，比如专用的大语言模型（LLM）AI 推理服务器、智能驾驶区域计算中心服务器等；
通信网络设备：尽管边缘 AI 应用对通信网络的带宽和速率要求没有云端那么高，但也必须提供可靠的高速连接才能达到边缘 AI 所需的低延迟和实时性要求。

本文主要讨论边缘 AI 服务器及其市场发展趋势、对 AI 加速处理器的要求，以及适合边缘 AI 应用的并行计算架构和处理器实现。

二、边缘 AI 服务器市场趋势
AI 服务器是指专为人工智能应用而设计的高性能计算机设备，能够支持大规模数据处理、模型训练、推理计算等复杂任务。AI 服务器通常配备高性能的处理器、高速内存、大容量高速存储系统，以满足 AI 算法对计算资源的极高需求。按不同的分类标准，AI 服务器可以大致分为训练服务器、推理服务器、GPU 服务器、FPGA 服务器、CPU 服务器、云端 AI 服务器，以及边缘 AI 服务器等。

...

[剩余内容略]

---

```
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。