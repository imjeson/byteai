---

title: '警告：英国政府在公众身上使用的AI工具“带有种族主义和偏见”'
date: 2024-08-26
author: ByteAILab

---

人工智能和算法工具在英国中央政府使用后，一直饱受“根深蒂固”的种族主义和偏见的指责，现在将被公开登记。

---
官员们在本周末确认，一些被活动人士挑战的工具因涉嫌保密和存在偏见风险将很快被公布。这些技术已被用于多种用途，从试图检测假结婚到查找福利申请中的欺诈和错误。

这一举措是对那些一直在挑战中央政府中使用人工智能的活动人士的胜利，这些人认为该技术在公共部门可能会快速推广前存在一定程度的保密性和偏见风险。公共法律项目（Public Law Project，PLP）的高级研究员卡罗琳·塞尔曼表示，这些系统的存在、细节和部署缺乏透明度。她说：“我们需要确保公共机构发布有关这些工具的信息，这些工具正在被迅速推广。对于被采纳的技术合法、公正且无歧视对每个人都是有利的。”

2020年8月，内政部同意停止使用计算机算法来帮助整理签证申请，此前有人声称该算法“带有根深蒂固的种族主义和偏见”。在移民福利联合委员会和数字权利组织Foxglove提出法律挑战后，官员们暂停了该算法的使用。

Foxglove称，有些国籍被自动给予“红色”交通灯风险评分，这些人更有可能被拒绝签证。其称这一过程构成了种族歧视。该部门去年还因一个用于发现旨在逃避移民管控的假结婚的算法工具而受到挑战。PLP表示，这个工具似乎可能对某些国家的人进行歧视，公平性评估透露给该慈善机构表明，保加利亚、希腊、罗马尼亚和阿尔巴尼亚人更有可能被调查。

政府的数据伦理与创新中心，现为负责技术采纳的机构，于2020年11月在一份报告中警告称，存在大量新技术“根深蒂固或放大了历史偏见，甚至产生了新的偏见或不公正现象”。该中心协助制定了一个用于部署AI和算法工具的透明度记录标准。它建议那些与公众互动或对决策产生重要影响的模型被发布在一个登记或“资料库”上，并提供使用方式和原因的详细信息。

截至目前，三年内只有九条记录被发布在该资料库上。这些模型都不是由内政部或工作和养老金部门（DWP）运营的，而这些部门运营了一些最具争议的系统。

在今年二月有关AI监管的咨询回应中，上一届政府表示各部门将被强制遵守报告标准。科学、创新和技术部（DSIT）本周末证实，各部门现在将按照该标准报告使用技术的情况。

DSIT发言人表示：“技术有巨大潜力来改善公共服务，但我们知道重要的是要保持正确的防范措施，包括必要时人为监督和其他形式的治理。”“算法透明度记录标准现在对所有部门都是强制性的，一些记录将很快被发布。我们继续探讨如何能够在整个公共部门扩展这一标准。我们鼓励所有组织在使用AI和数据时要建立公众信任，通过工具、指导和标准。”

各部门很可能会面临进一步要求披露其AI系统运行方式及减少偏见风险措施的呼吁。工作和养老金部门正在利用AI来检测普遍信用预付款的潜在欺诈行为，并且正在开发更多用于检测其他领域欺诈行为的工具。

在其最新的年度报告中，该部门表示，已对其在普遍信用预付款方面使用AI进行了“公平性”分析，并未“立即引发任何歧视担忧”。该部门未提供任何关于其评估的细节，因为担心公开可能“允许欺诈者了解模型的运作方式”。

PLP正在支持对工作和养老金部门使用该技术的可能法律诉讼。该项目正向该部门施压，要求提供其使用方式和减少危害措施的细节。该项目已编制了政府自动化决策工具的自己的登记，目前已追踪了55个工具。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。