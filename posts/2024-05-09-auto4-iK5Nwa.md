---

title: '万卡时代不打群架，中国智算正过三关'
date: 2024-05-10
author: ByteAILab

---

我前两天看到了一个挺震撼的视频，科学家们在NASA戈达德空间飞行中心的天体物理学家指导下，使用Discover超级计算机模拟了跳入黑洞的过程。

画面视觉效果摄人心魄，而一组数据同样让我感到震撼：该视频生成10TB的数据，只用了5天，耗费了0.3%总算力。

---
如果我们想用自己的笔记本电脑模拟这个场景，需要花费的时间是10年。

“时间就是金钱，效率就是生命”，这句改开时代的口号，在大模型驱动的智算时代，仍旧不过时。

算力作为生产力，所节约的不只是金钱，更重要的是时间。

目前算力集群已经从千卡，迈入了万卡、五万卡集群。甚至有媒体预测，GPT6未来部署的时候，需要70万-80万张卡才能支撑。

那问题来了，万卡集群在执行大规模训练任务时负载重，发生软硬件错误的概率，当然也就更高。万卡时代，一张卡、一台机器或一个链路的故障，都可能导致中断，拖慢进程。那么十万卡、百万卡等更大数量级的提升，未来如何应对？

最近几个月，我们团队跟不少ICT厂商做了交流，简单总结一下行业动向，那就是：迈入万卡时代，必须“过三关”。

万卡时代，做AI=“中彩票”？

有必要首先说明一下，为什么智能计算仍在“堆卡”？从千卡、万卡到十万卡、百万卡，这个趋势是可持续的吗？

伴随着模型规模与数据参数愈发庞大，在可以预见的未来，基础设施层面的“堆卡”竞赛仍将继续。

目前，国际科技巨头如谷歌、微软、苹果等，在算力集群建设上持续投入，其中AI算力占总算力支出的比例持续增长，预计到2025年将达到25%。放眼国内，万卡及以上的组网也成为下一代智算中心的建设重点。

然而，算力集群卡的数量非线性增加，会带来更大的不稳定性和协作难度。正如新华三在前不久的媒体与分析师大会上所说，单卡单打独斗我们（与N卡）有差距，多卡集群服务不能打群架。

我们知道，分布式并行训练能够加速训练过程，是大模型常用的训练方式，相当于将任务分配给多个AI硬件，组成协作节点和集群，主打一个“人多力量大”。但是，人多还得心齐啊，让多卡用高效一致的步伐进行协作，却是一件难事，容易出现“打群架”的情况。

多卡“打架”，集群就会因故障而中断。

一位清华大学计算机教授曾分享过一个数据，其团队写一次容错检查点checkpoint需要三小时，这还是世界先进水平（未经优化前）。

工作三小时就得被迫停下，活（训练过程）又一点不能少，只能加班加点。普通打工人听了都得“抓狂”，更别说要跟技术创新抢速度、作业生产要效率的产学界了。

多卡集群“不打群架”，将算力最大化地有效使用起来，发挥每一张GPU的价值，提升训练效率，对开发人员来说，堪比中“彩票”，价值很大，但概率却不定。

显然，千行百业智能化，当然不能靠“中彩”和运气。

当算力集群即将从万卡，迈入五万、十万乃至百万卡的清晰未来，我们不能只以单一的规模和FLOPS浮点运算次数，来衡量智算中心的综合水平。其他因素也同样重要，比如集群扩展性、兼容性、算效比、能耗比等。

如何提供一个稳定可靠高性能的智算基础设施，万卡时代要“过三关”。

第一关：闯过资源墙

超大规模集群的不稳定性，一方面要对抗硬件数量非线性增长带来的“增熵”。

随着集群增大，AI芯片也会出现算力衰减的情况。支撑稳定高效的训练，就需要优化分布式计算系统的并行加速比。

更高的加速比，可以让集群在执行同一任务时，获得更高的速度和效率。也就是说，算力集群能够最大限度地一直运转，那么有效训练时间的比例更高，是开发人员衡量集群性能的一个关键。

比如国产大模型文心4.0，就通过百度智能云的万卡集群进行训练，支持模型的稳定高效迭代进化。目前，百度智能云上万卡训练集群的加速比和有效训练时间，达到 95% 以上。

另一方面，中国智算还有一个特殊的要求，那就是闯过多元异构算力的“资源墙（resource wall)"。

不少智算中心，使用不一样的AI芯片服务器组成异构集群合池训练，共同完成一个大模型训练。尤其是此前GPU紧缺的情况下，一些数据中心、智算中心在不同时期，购买了不同的GPU，形成了不同类型、不同版本的异构集群。

多元异构的国产算力，既能以用促建，促进国产AI芯片的发展，减少对海外单一供应链的依赖，也能发挥不同类型芯片的特性，提高计算资源的利用率和训练效率。

但要将多元异构算力进行合池训练，会带来精度误差、同步问题，以及更复杂的资源管理和调度策略，更高的开发运维难度等。

未来，每个行业、每家公司都可能训练自己的大模型，带来充沛、高效、稳定的AI算力需求。让十万百万级集群、多元异构的算卡，以高效一致的步伐进行协作，将成为中国智算行业的关键挑战。

第二关：踏宽通信路

如果网络通信的联接能力不畅，大量算力资源折损在传输过程中，给智算中心与AI模型开发者带来的损失都是难以估量的。

如何将大量算卡有效地连接起来，形成一个高效稳定的计算网络，是支撑超大规模集群的关键。

需要说明的是，网络作为算力运输的道路，并不能无止境地拓宽。集群网络，尤其是万卡、十万卡集群网络的拓展，会受到几方面的制约。

首先是成本上，万卡乃至五万卡集群，所需要的网络设备数、端口数、光模块数量，可能会达到百万级别。而一个普通的400G光模块功耗就在10瓦到12瓦，当一个网络需要一万多个光模块，仅仅是电费成本都非常庞大。

此外，有业内人士向我们表示，万卡集群还容易搭建起来，未来如果要有百万卡集群来训练的大模型，可能整个...

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。