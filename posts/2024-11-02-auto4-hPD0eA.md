---
title: '当AI取代真相，大模型如何一步步诱骗了人类的文明？'
date: 2024-11-03
author: ByteAILab

---

如今，人们选择餐厅，多半会打开app搜索一番，再看看排名。然而美国奥斯汀的一家餐厅Ethos的存在证实这种选择机制多么不可靠。

---
Ethos在社交媒体instagram宣称是当地排名第一的餐厅，拥有7万余粉丝。
实际上，这家看起来很靠谱的餐厅根本不存在，食物和场地的照片都由人工智能生成。可它家发布在社媒上的帖子却得到了数千名不知情者的点赞和评论。大模型通过视觉形式误导公众认知，引发了人们对其潜在影响的深刻思考。

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/8FD7B96F5E34993C64020C0DB54F4C00/1730426781892/Fv7s-fZCEso4Hn0rqWiwTr9Jj2f_.png)

**AI生成的虚假信息影响深远**

类似开篇提到的虚假餐厅的例子，现实生活中发生了不止一次。2023年11月，搜索引擎Bing曾因为爬取了错误信息，而针对“澳大利亚是否存在”的问题，给出了荒谬的回复。（事后官方很快对该问题进行了修复。）

![Bing截图；图源：Bing](http://www.jesonc.com/FlB4irAzphvhDRNl9ZopcYv14bVF)

上面的例子，还可视为程序的bug，而普林斯顿的一项研究则系统性说明了AI生成数据的影响不止如此。该研究发现，截止24年8月，至少5%的英文维基百科页面是由AI生成的，相对而言德语、法语和意大利语文章的占比较低。
维基百科（Wikipedia）是人工智能训练数据的重要来源，且被普遍视为权威的信息来源。尽管AI生成的内容并不一定都是虚假信息，但该研究指出，被标记为AI生成的维基百科文章通常质量较低，并具有较明显的目的性，往往是自我推广或对有争议话题持特定观点。

**AI生成的虚假信息**
**如何利用了判断真假的启发式弱点**

虽然虚假信息被发现后很快会被纠正，但如同小时候听过的“狼来了”的故事，一次次的接触虚假信息，会让磨损我们彼此间的信任。
我们判断一件事情是否为真时，有两种不同的思考方式，一是启发式，另一种则是费力的思考。启发式思维所需的认知资源更少，依赖直觉，属于丹尼尔·卡尼曼所说的系统一。对个体来说，判断是否是虚假信息，启发式的判断标准包括是否声明清晰，是否吞吐犹豫，是否有熟悉感；而费力的思考则多基于逻辑：“不应该只相信互联网来源，我是否在学校或是书本中见过类似的？”
![大模型会如何利用人类事实监控机制的弱点，图源：参考文献1](http://www.jesonc.com/FuDJ5GbU3Ij7Gmvoa-sutkz1XT5P)

在在日常生活中，我们常用到两种启发式方法判断信息真实与否：一种是观察发言是否流畅自信，另一种是言论是否熟悉。然而事实证明，这两种判断基准在人工智能面前都会败下阵来。
然而，大模型生成的文章，往...

[阅读全文](https://www.aixinzhijie.com/article/6847118)
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。