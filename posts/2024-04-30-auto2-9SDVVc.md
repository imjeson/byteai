---
title: 'OpenAI faces complaint over fictional outputs'
date: 2024-05-01
author: ByteAILab

---

欧洲数据保护倡导团体noyb已针对OpenAI在无法纠正ChatGPT生成的不准确信息而提起投诉。![图片](https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/04/openai-hallucinations-noyb-ai-artificial-intelligence-eu-europe-gdpr-large-language-model.jpeg){ width=50% }

---
该团体声称OpenAI未能确保该服务处理的个人数据准确性违反了欧盟的《通用数据保护条例》（GDPR）。
“虚构错误信息本身就很棘手。但涉及到个人的虚假信息时，可能会带来严重后果，”noyb的数据保护律师Maartje de Graaf表示。
“目前公司无法确保像ChatGPT这样的聊天机器人在处理有关个人数据时符合欧盟法律。如果系统不能产生准确和透明的结果，就不能用于生成关于个人的数据。技术必须遵循法律要求，不能相反。”
GDPR要求个人数据准确无误，个人有权要求纠正不准确的数据，以及有权访问处理的数据及其来源信息。然而，OpenAI已公开承认无法纠正ChatGPT生成的不正确信息，也无法披露用于训练该模型的数据来源。
OpenAI辩解称：“大型语言模型的事实准确性仍是一个积极研究领域。”
倡导团体引用了《纽约时报》的一篇报道，发现像ChatGPT这样的聊天机器人“至少有3％的时间会虚构信息 - 甚至高达27％。”在对OpenAI的投诉中，noyb援引了一个例子，其中ChatGPT多次为被投诉人（一位公众人物）提供了不正确的出生日期，尽管已请求纠正。
“尽管ChatGPT提供的被投诉人的出生日期是不正确的，OpenAI拒绝了他的纠正或删除数据的请求，称不可能纠正数据，”noyb声明。
OpenAI声称可以对某些提示的数据进行过滤或阻止，例如被投诉人的姓名，但无法做到不影响ChatGPT过滤有关该个人的所有信息。该公司还未能对被投诉人的访问请求做出充分回应，而GDPR要求公司应满足该请求。
“遵守访问请求的义务适用于所有公司。显然可以记录用于训练数据的信息，以至少对信息来源有个概念，”de Graaf表示。“似乎每个‘创新’都让另一批公司认为他们的产品不必遵守法律。”
欧洲隐私监督机构已经审查了ChatGPT的不准确性，意大利数据保护局在2023年3月对OpenAI的数据处理施加了临时限制，欧洲数据保护委员会成立了一个ChatGPT工作组。
在其投诉中，noyb要求奥地利数据保护局调查OpenAI的数据处理情况及确保其大型语言模型处理个人数据准确性的措施。该倡导团体还要求该机构下令OpenAI遵守被投诉人的访问请求，使其处理符合GDPR，并对未来的遵从性施加罚款。
您可以在此处阅读完整的投诉书（PDF）
（照片由Eleonora Francesca Grotto提供）
另请参阅：Igor Jablokov，Pryon：构建负责任的人工智能未来

想从行业领袖那里了解更多有关人工智能和大数据的知识吗？请查看在阿姆斯特丹，加利福尼亚和伦敦举办的AI＆Big Data Expo。这一综合性活动与其他领先的活动同期举办，包括BlockX，Digital Transformation Week和Cyber Security＆Cloud Expo。
探索其他由TechForge提供的即将举办的企业技术活动和网络研讨会。
Tags: ai, artificial intelligence, ethics, eu, europe, european union, gdpr, government, hallucinations, large language model, law, legal, noyb, openai, privacy, Society
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。