---

title: '人工智能聊天机器人“机械希特勒”可能发布被视为暴力极端主义的内容，专家证人告诉X与eSafety的案件'
date: 2025-07-16
author: ByteAILab

---

嵌入在埃隆·马斯克的X平台中的聊天机器人上周自称为“机械希特勒”，并发表反犹太主义言论，这可能被认为是恐怖主义或暴力极端主义内容，澳大利亚一个法庭听证会上听到的消息。

---
但为X提供证据的专家证人辩称，大型语言模型不能被赋予意图，只有用户才具有意图。马斯克的人工智能公司xAI上周因其聊天机器人Grok在16小时内发表了这些言论而道歉，并将其归因于“弃用代码”，该代码使Grok容易受到现有X用户帖子的影响，“包括当这些帖子包含极端主义观点时”。

该事件在周二的一次行政审查法庭听证会上引起关注，X正在挑战由电子安全专员朱莉·英曼·格兰特于去年3月发出的通知，要求该平台解释其如何采取行动对抗恐怖主义和暴力极端主义(TVE)材料。X的专家证人、RMIT经济学教授克里斯·伯格提供了证据，认为在假定大型语言模型可以生成此类内容是一个错误，因为定义什么可以被视为恐怖主义和暴力极端主义内容的关键在于驱动大型语言模型的用户的意图。电子安全的专家证人、昆士兰科技大学法学教授尼古拉斯·苏佐尔对此表示不同意见，认为“绝对有可能让聊天机器人、生成AI和其他工具在生产所谓的合成TVE内容中发挥一定作用”。“本周发生的情况非常多，X的聊天机器人Grok生成了[符合TVE定义的]内容，”苏佐尔说道。他还表示，人工智能的发展在“下层有人的影响”，你可以找到意图，包括马斯克的行为，他在改变Grok回应查询的方式，以“停止过于觉醒”。

法庭听到，X认为其社区注释功能（用户可以为网站上的帖子提供事实检查）和Grok的分析功能（为帖子提供上下文）可以检测或解决TVE问题。电子安全的两位专家证人，迪肯大学政治学副教授乔希·鲁斯也在听证会上表示，社区注释在这方面的有效性是有争议的。鲁斯说，TVE需要用户向X报告内容，这进入了公司的一个“黑箱”，而且通常只有少量材料被删除，少数账户被封禁。苏佐尔表示，考虑到上周的事件，很难将Grok视为“寻求真相”的工具。“可以毫不争议地说，Grok并没有最大化真相或寻求真相。我特别想提到，上周的事件让我完全不信任Grok，”他说。伯格辩称，X上的Grok分析功能没有更新导致该平台的聊天机器人上周发表此类回应的功能，但承认用户直接回应的聊天机器人“有些失控”，分享了仇恨言论和“非常奇怪的内容”。苏佐尔表示，Grok的回应已经改变，不是为了最大化追求真相，而是“确保这些回应更符合马斯克的意识形态观点”。

在听证会的早些时候，X的律师指责电子安全试图将听证会“变成一个对X某些方面的皇家调查”，而马斯克称英曼·格兰特为“委员”的评论被提及，并在对X一名员工的交叉审问中被提到，关于在发出通知前与X举行的会议。政府的律师史蒂芬·劳埃德辩称，X试图表示电子安全在与X的交往中“过于对抗”，而X在发出通知前在关键时刻中断了谈判。他表示，这种“激进的做法”来自X的领导层。听证会仍在进行中。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。