---

title: 'JHU提出最强ToM方法，AutoToM横扫五大基准'
date: 2025-04-17
author: ByteAILab

---

本文有三位共同第一作者，分别为 Zhining Zhang（张芷宁）、Chuanyang Jin（金川杨）、Mung Yao Jia。他们在约翰霍普金斯大学 Social Cognitive AI Lab 共同完成这篇论文。

---
本文的指导老师为 Tianmin Shu（舒天民），是 JHU Social Cognitive AI Lab 的主任。该实验室致力于构建能够在现实世界中理解、推理和与人类互动的社会智能系统，从而推进以人为中心的 AI。

如何让 AI 像人一样思考？如何拥有像人一样的认知能力和社会能力？

心智能力（Theory of Mind, ToM）是指通过观察他人的行为来理解他们内心想法的能力，这一能力对开发具备社会智能的智能体至关重要。

近日，来自JHU 的研究团队提出了 AutoToM，一种全自动、开放式的心智推理方法。作为首个面向开放场景的 model-based ToM 方法，以类似人类的思维模式，AutoToM 在 5 个基准测试中都取得了最好成绩，并展现出良好的可扩展性、鲁棒性以及可解释性。

![图片](https://image.jiqizhixin.com/uploads/editor/75e9fa11-1f03-47b2-8dd8-5510c5155c7e/640.png)

论文标题：AutoToM: Automated Bayesian Inverse Planning and Model Discovery for Open-ended Theory of Mind

论文地址: [https://arxiv.org/abs/2502.15676](https://arxiv.org/abs/2502.15676)

项目主页: [https://chuanyangjin.com/AutoToM/](https://chuanyangjin.com/AutoToM/)

代码地址: [https://github.com/SCAI-JHU/AutoToM](https://github.com/SCAI-JHU/AutoToM)

**基于模型的心智推理**

当前在实现心智能力的推理方面主要有两种方法：

1. 使用大型语言模型（LLM）来推理他人的心理状态。然而，即使使用了换位思考、变化追踪和时空推理等提示策略，LLM 在复杂情境中仍然会出现系统性的错误。
2. 采用基于模型的推理方法。特别是贝叶斯逆向规划（Bayesian Inverse Planning, BIP）。BIP 假设 agent 会根据一个贝叶斯心智模型（Bayesian Theory of Mind, BToM）做出理性行为。这个模型使用 MDP、POMDP、I-POMDP 等给定框架描述 observation、belief、action、goal 等心理变量之间的依赖关系，来模拟 agent 做出行为的过程。BIP 通过逆推这个生成过程，来判断哪些潜在心理状态可能导致我们观察到的行为。

JHU 该团队之前的论文（ACL 2024 杰出论文奖）将 BIP 和 LLM 结合，以实现既具可扩展性又稳健的模型化心智推理。这类方法更加稳健，在特定领域中相较于直接使用 LLM 有明显优势，但它们依赖的是固定、人工设计的模型，没有办法泛化到不同的领域。

![图片](https://image.jiqizhixin.com/uploads/editor/57ac4a70-0637-4b6e-ac0b-ac6b92475c63/640.png)

不同基准测试中的示例问题及其所需的 BToM 模型。

**AutoToM 第一个适应开放场景的 model-based ToM 方法**

AutoToM 引入了一种全新范式。它是一种完全自动化、开放式的基于模型的 ToM 推理方法。AutoToM 实现了对贝叶斯逆向规划的全流程自动化，包括模型结构的提出与调整、关键时间点的识别、假设的生成以及贝叶斯推理的执行。

它无需任何领域知识，可在任意情境中运行，能够推断任何心理状态，推理涉及任意数量的智能体，并支持任意层级的递归推理。这体现了团队对一种开放、通用且稳健的机器心理理论的愿景。

![图片](https://image.jiqizhixin.com/uploads/editor/e99c4afe-1076-44f0-8c2e-c55642e2a9e1/640.png)

AutoToM 的流程图。X 是已知的可观测变量，V 是潜在的心理变量，q 表示问题中查询的变量。ts:t 表示用于推理的信息来自 ts 到 t 的时间段。变量 s、o、b、a、g 分别表示 state、observation、belief、action、goal，图中的实线箭头表示模型中它们的依赖关系。

**全自动的贝叶斯逆向规划**

给定一个贝叶斯心智理论模型（BToM）中，我们引入大语言模型（LLM）作为计算后端，用于实现贝叶斯逆向规划（BIP）的各个关键环节。

**假设采样（Hypothesis Sampling）**

传统的 BIP 方法通常依赖人为设定的假设空间，以及为每个潜在心理变量指定具体的假设表示方式。而我们的假设采样模块则利用 LLM，根据上下文中可观测变量及其取值，生成一小集合的高质量假设。随后，我们还会通过假设筛选机制，去除不太可能的假设，从而压缩假设空间。

**贝叶斯推理（Bayesian Inference）**

我们使用 LLM 来估计 BToM 模型中每个局部条件概率。接着，通过对非目标潜在变量进行边缘化，我们得到目标变量的后验概率。与以往方法相比，我们的方法具有更强的通用性：支持任意结构的 BToM 模型，能够同时考虑多个潜在变量，并支持任意层级的高阶的心智推理。

![图片](https://image.jiqizhixin.com/uploads/editor/bed982e0-472f-4d9e-9c1f-1e27e2d53010/640.png)

在给定的 BToM 模型下，AutoToM 进行全自动的贝叶斯逆向规划。

**全自动的模型发现与改进**

之前的方法依赖于人工设计的 BToM 模型，这限制了它们在特定领域外的适用性。相比之下，AutoToM 能够自动提出模型，并动态调整模型结构，从而在推理过程中兼顾有效性（即准确地推断出智能体的心理状态）和高效性（即尽可能简化模型和计算复杂度）。

**信息提取**

信息提取模块会处理给定的信息，识别可观测变量的取值，包括状态、动作和言语等信息，并按时间顺序组织。

**提出初始模型**

我们使用 LLM 根据已有的信息和任务提出一个初始的 BToM 模型。基于该模型，我们执行自动化的 BIP。如果该模型的效用超过某个阈值，我们便接受该模型的推理结果，否则将进行后续的模型调整。

**模型调整**

我们通过两种方式迭代式地优化初始模型：**变量调整**和**时间节点调整**。

1. **变量调整**：在某个具体时间点上，我们会引入新的、相关的潜变量来扩展模型结构，从而缓解推理过程中的不确定性。每引入一个变量，我们都会重新计算模型效用，并选择提升效用最大的修改方案进行保留。
2. **时间节点调整**：以往的研究通常假设所有历史都是相关的，而 AutoToM 能够在上下文中发现相关的历史信息，这种能力对于 AutoToM 在长上下文环境中成功进行心理理论推理并降低计算成本至关重要。从最小的时间范围开始，如果在当前的时间范围内，变量调整仍无法显著提升模型效用，我们会考虑加入新的时间节点以引入更多上下文信息。在考虑新的时间节点后，会在此基础上继续执行变量调整。

![图片](https://image.jiqizhixin.com/uploads/editor/39636f2c-22b5-4f82-8486-5b0d14ab4d1c/640.png)

AutoToM 通过在变量调整和时间节点调整之间交替进行，自动优化 BToM 模型。

**自动适应情境，横扫五大基准测试**

该团队在 ToMi、BigToM、MMToM-QA、MuMA-ToM 和 Hi-ToM 五个测试基准上进行了测试。这些基准覆盖了不同的心理变量、环境、agent 数量、有无语言表达、措辞风格以及模态类型。

与 AutoToM 不同，许多近年来的 ToM 方法只能应用于特定的基准测试。而在通用的方法中，AutoToM 在所有基准测试中都取得了最优的表现。

![图片](https://image.jiqizhixin.com/uploads/editor/3ca88e30-4120-4bb7-8a92-78dbabeb887f/640.png)

AutoToM 和 baselines 在所有基准测试上的表现。

本文的消融研究突出了 AutoToM 在变量调整、时间步调整和假设减少方面的优势。AutoToM 能够构建一个合适的模型，该模型不仅支持丰富的 ToM 推理，还能减少计算量，在准确性和成本之间取得平衡。

![图片](https://image.jiqizhixin.com/uploads/editor/0c472b2c-9a8b-40b7-a4d0-e43dda69c791/640.png)

AutoToM 及其消融方法在所有基准测试中的平均正确率与计算量。

**总结和展望**

总的来说，AutoToM 是一个 ToM 推理任务的新颖框架。面对任何 ToM 推理问题，AutoToM 都可以自动构建一个合适的 BToM 模型，并借助 LLM 执行自动的贝叶斯逆向规划。

AutoToM 在所有测试上取得了最好的结果，这是因为 BIP 在面对复杂环境和较长上下文时可以稳健地推理。此外，AutoToM 具有可解释性，能够通过其发现的概率模型来解释模型的判断过程。

该论文为实现更具人类思维特征的推理方式，以及构建具有人类认知基础、具备可扩展性、稳健性和开放性的心理能力模型，指明了一个有前景的方向。该论文也引发了关于 inference-time compute，以及可扩展的 model-based inference 的广泛讨论。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。