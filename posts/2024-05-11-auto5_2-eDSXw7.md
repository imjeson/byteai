---
title: '在ICLR 2024这场演讲中，智谱AI首次公开神秘项目「GLM-zero」'
date: 2024-05-12
author: ByteAILab
---

在机器学习社区中，ICLR （国际学习表征会议）是较为「年轻」的学术会议，它由深度学习巨头、图灵奖获得者 Yoshua Bengio 和 Yann LeCun 在 2013 年牵头举办。但 ICLR 很快就获得了研究者的广泛认可，并且在 AI 圈拥有了深度学习会议「无冕之王」的称号。

---


目前，ICLR 与 ICML、NeurIPS  并称为机器学习领域难度最大，水平最高的会议。从影响力上看，ICLR 长期处于 Google Scholar 全球所有学科中期刊、顶会的前十名。

今年，ICLR 已经来到了第十二届。5 月 7 日，ICLR 2024 在奥地利维也纳会展中心开幕。

或许是受到大模型技术浪潮的推动，无论是参会人数、论文提交量还是现场参会规模，ICLR 2024 的热度相比往年均有极大的提升。

从深度学习的兴起，到生成式 AI 带来的新一波浪潮，ICLR 算是见证了人工智能领域十多年来的发展史。在这个过程中，ICLR 也从第一届只有二十几篇接收论文的小型会议成长为投稿量超过七千的顶会。

大会首日的开幕式公布了 ICLR 2024 的一些数据和奖项：比如，在走过第一个十年后，ICLR 迎来了自己的首届时间检验奖，获奖研究《Auto-Encoding Variational Bayes》（VAE）对于今天深度学习和生成模型领域影响深远。

值得关注的是，本次大会上共有七场受邀演讲，Meta、谷歌等科技巨头悉数在列。

其中一场特邀演讲来自中国的 GLM 大模型团队，主题为《The ChatGLM's Road to AGI》。这也是国内鲜有的，大模型相关 Keynote 登上全球学术顶会的讲台。

大模型时代，AGI 会加速到来吗？

在演讲中，GLM 大模型团队回顾了近年来语言模型领域的技术演进与方向碰撞。

大模型技术显著提升了 AI 在各种任务上的表现，例如自然语言理解和文本生成、图像处理、多模态建模，催生了大众对 AGI 的真切期待。从技术上说，这些神奇能力与模型的「智能涌现」分不开，而「涌现」的底层逻辑是「Scaling Law」。

Open AI 的 Jason Wei 2022 年在谷歌工作期间，与 Jeff Dean 等人共同撰写了关于大模型涌现能力的论文，揭示了重要结论：当模型较小时，性能是随机的，一旦模型规模到达一定阈值，性能就会显著超越随机。一般来说，模型越大，能力越强。

对于这种由量变引起的质变现象，人们称之为「涌现（emergence）」。如果「涌现」是真实存在的，那么 AGI 的实现可以依靠模型体量的增加而逼近。

但斯坦福团队的一项研究却提出了相反的观点：大模型能力是否涌现与任务的评价指标强相关，并非模型行为在特定任务和规模下的基本变化，换一些更连续、平滑的指标后，涌现现象就不那么明显了，而是更接近线性。

「它有连续性，但没有能力涌现。」这项具有警示性的研究还获得了 NeurIPS 2023 最佳论文奖。

论文链接：https://arxiv.org/pdf/2304.15004.pdf

目前，学术界对上述命题仍然存在争论。不过，GLM 大模型团队今年 3 月的一篇论文从预训练损失的角度重新讨论了模型涌现能力 —— 只有当预训练损失低于某个阈值时，模型才具有该能力。这为此后的研究提供了新的视角：Loss 才是涌现的关键，而非模型参数。

论文地址：https://arxiv.org/pdf/2403.15796.pdf

在近来的大模型浪潮中，GLM 大模型团队备受关注。去年 6 月，在科技媒体 The Information 的盘点中，GLM 大模型团队所属的智谱 AI，被视为最有可能成为「中国 OpenAI」的 5 家企业之一。

从 GLM 大模型团队的下一阶段目标中可以看出，除了「涌现」命题，GLM 大模型团队对于通往 AGI 的路径还有很多思考。

GLM 大模型团队表示，文本仍然是最关键的基础，而下一步应该把文本、图像、视频、音频等多种模态混合在一起训练，变成一个真正原生的多模态模型，然后还可以开发面向现实任务的虚拟助理，甚至是以大模型为中心的通用计算系统。

在这一设想中，通用计算系统可基于已有的 All-Tools 能力，再加上内存记忆 memory 和自我反馈 self-reflection 能力，模仿人类的 PDCA 机制，即 Plan-Do-Check-Act 循环，最终实现自我提升。

与此同时，如何大模型拥有人类的「无意识」学习机制，也是 GLM 大模型团队在探索的方向。

「最有希望成为中国 OpenAI」的团队，如何瞄准 AGI？

自 2019 年成立以来，GLM 大模型团队便开始了大语言模型的探索，并选择走开闭源并存的发展路线。

在整体布局上，GLM 大模型团队已经完成了全面对标 OpenAI，从基座模型到对话、文生图、代码、检索增强和视觉模型，包括 GLM、ChatGLM、CogView、CodeGeeX、WebGLM 以及 GLM-4V。这些模型的预训练过程中少不了针对中文语料的大量优化，这也是国产大模型发挥本土化优势的关键。

GLM 大模型团队在 2020 年后开始显现成果。从研发 GLM 预训练架构、到训练完成百亿参数的 GLM-10B、再到 2022 年千亿参数超大规模预训练模型 GLM-130B 的诞生，他们开始围绕这一强大的基座模型持续深拓。

2023 年 3 月，与 GPT-4 同一时间，GLM 大模型团队推出了基于千亿基座模型的对话模型 ChatGLM，理解用户、遵循指令、回答问题的效果显著提升。同时选择开源中英双语对话模型 ChatGLM-6B，实现单张消费级显卡上的本地部署。随后的 6 月和 10 月，GLM 大模型团队又迎来第二代和第三代 ChatGLM，保持三到四个月一次的模型迭代频率。

随着今年初新一代基座大模型 GLM-4 的到来，GLM 系列模型实现了性能比肩 GPT-4，自然语言、多模态、Agent 能力全方位提升的同时推理速度更快、成本更低。

目前，GLM 系列大模型的研究成果已经涵盖了数学、文生图、图像理解、视觉 UI 理解、Agent 等领域。以 ChatGLM-Math 为例，该模型通过独特的「Self-Critique」迭代训练方法和自我反馈机制，实现了 LLM 的数学能力的进一步强化。

论文地址：https://arxiv.org/pdf/2404.02893

与此同时，CogView 文生图模型、CodeGeeX 代码模型、CogVLM 多模态理解模型、GLM-4V 多模态大模型和 All-Tools 功能以及 AI 助手智谱清言也在持续进步，比如基于 CogVLM 开发的具有视觉 Agent 能力的模型 CogAgent、更快更精细的文生图模型 CogView3、让多模态模型具有操作链的通用视觉语言模型 CogCoM。

快速迭代的大模型能力，让研究者们更加期待 GLM 大模型团队未来的进一步动作。在演讲中，GLM 大模型团队深入解读了 GLM 系列大模型下一阶段面向 AGI 的三个探索方向。

第一，GLM-4 的后续升级版本，即 GLM-4.5 及其升级模型，它们将基于超级认知 SuperIntelligence 和超级对齐 SuperAlignment 技术打造。

在持续提升文本能力的基础上，GLM 大模型团队计划将文本、图像、视频、音频等多种模态混合在一起训练，构建真正原生的多模态模型，同时超级对齐 SuperAlignment 技术协助将提升大模型的安全性。

第二，提出 GLM-OS 概念，即以大模型为中心的通用计算系统，旨在解决更加复杂的问题。

在 ICLR 现场，GLM 大模型团队详细阐述了 GLM-OS 的实现方式：基于已有 All-Tools 能力加上内存记忆 memory 和自我反馈 self-reflection 机制，GLM-OS 有望实现模仿人类的 Plan-Do-Check-Act 循环。首先做出计划，然后初步尝试形成反馈，基于反馈结果调整规划，然后再行动以期达到更好的效果。大模型依靠 PDCA 循环机制形成自我反馈和自我提升 —— 恰如人类自己所做的一样。

第三，GLM 大模型团队在现场首次公开了名为「GLM-zero」的技术项目。

这一项目是在 2019 年开展的，旨在研究人类的「无意识」学习机制。该机制是人类认知能力的重要组成部分，包括自我学习 self-instruct、自我反思 self-reflection 和自我批评 self-critics。

「当人在睡觉的时候，大脑依然在无意识地学习。」GLM 大模型团队表示，人脑中存在着反馈 feedback 和决策 decision-making 两个系统，分别对应着大模型和内存记忆两大部分，GLM-zero 的相关研究将进一步拓展人类对意识、知识、学习行为的理解。

GLM 大模型团队认为，尽管还处于非常早期的研究阶段，但 GLM-zero 可以视为通向 AGI 的必经之路。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。