---
title: '大模型边推理边纠错，有可能做到吗？这是ICML爆火的演讲'
date: 2024-09-10
author: ByteAILab

---

即便是最强大的语言模型（LLM），仍会偶尔出现推理错误。除了通过提示词让模型进行不太可靠的多轮自我纠错外，有没有更系统的方法解决这一问题呢？

来自 Meta FAIR、CMU 和 MBZUAI 的叶添、徐子诚、李远志、朱泽园团队在最新的 arXiv 论文《语言模型物理学 Part 2.2：如何从错误中学习》中，通过可控实验，探索了让模型 **「边推理边纠错」** 的可能性。

---


他们在预训练中加入大量「错误的推理」和「错误的纠正」，展示了这类数据可以提高语言模型的推理准确性（无需提示词，无需多轮对话）。文章还深入探讨了许多细节，例如（1）这种方法与 beam search 的区别，（2）如何准备此类数据，（3）是否需要对错误进行掩码，（4）所需的错误数量，（5）此类数据是否可用于微调等。

作者首先展示了一个 GPT-4o 通过提示词和多轮对话进行纠错的示例（图 2），可以看到成功率不高，而且需要很长的对话才能完成纠错。那么，如果模型最终能纠错，为什么不在第一次犯错时「立即收回并改正」呢？

为此，作者使用探针（probing）方法研究模型的内部工作机制。通过 Part 2.1 建立的 iGSM 数据集，作者发现当模型犯错后，内部参数常常表现出「很后悔」的状态，也就是说，模型可能已经知道自己犯了错，但「覆水难收」。

那么， **能否简单地让模型「后悔即重试（retry upon regret）」** ？即，通过额外训练（如微调）得到一个检测错误的模型，只要该模型判定当前步骤有错，就立即退格回到上一步骤的末尾，再重新生成呢？

如图 3 所示，作者进行了横向对比。即便错误识别率超过 99%，这种重试方法在 iGSM 数据集上也只能将推理正确率提高 2%（虽然比 beam search 好）。作者总结了此方法的三个不足。

首先，对正确率提高有限，毕竟退格后，模型依然是随机生成，并没有用高级的方法改错。其次，对错误识别率的要求很高（同等条件下，需要 100% 错误识别率才能将推理正确率提高 8%，但这太不现实）。最重要的是，这并不能降低模型生成文本的时间复杂度，因为依然需要一次次地重新生成。

作者更换方法，在预训练数据中 **加入大量的错误和纠正，例如「A=&gt;B，哦我说错了，应该是 A=&gt;C」**。那么，这能否提升模型的推理正确率呢？乍一看，这似乎不合理，因为增加错误的同时，模型岂不是被迫学习说错误的话（即 A=&gt;B）？是否需要将错误部分（譬如「A=&gt;B，哦我说错了，应该是」这几个字）通过掩码（label masking）从训练标签中删除？

答案是不需要。依然通过 iGSM 数据集，作者用控制变量法，横向对比了诸多参数后得出若干结论...

---

Image links kept for reference:
- 图 1: [Link](https://image.jiqizhixin.com/uploads/editor/d60bec5d-5bac-4d58-bba6-86d04fd4e498/640.png)
- 图 2: [Link](https://image.jiqizhixin.com/uploads/editor/82c5ef58-9f25-40e3-813e-0b5249b4f6bc/640.png)
- 图 3: [Link](https://image.jiqizhixin.com/uploads/editor/21b069a0-88e7-4b80-9b2e-42a585efeb9b/640.png)
- 图 4: [Link](https://image.jiqizhixin.com/uploads/editor/3d4c6bf8-1707-480d-8a46-92b7bbfcc20a/640.png)
- 图 5: [Link](https://image.jiqizhixin.com/uploads/editor/3ff3b08a-52ca-4495-808f-3102c99e1e21/640.png)
- 图 6: [Link](https://image.jiqizhixin.com/uploads/editor/a1c8fac1-bac2-4f23-83b6-e54def61876b/640.png)

---

Reference: [Original Article](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9OnnzCX2HjxlUqj24Vnns9NNNzu0PPwaOst5iciaSdlMlBvia0nHGUtk9XQhXRqPP6P8KXz8wUyXicmg/640?wx_fmt=other&from=appmsg&wxfrom=5&wx_lazy=1&wx_co=1&tp=webp)
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。