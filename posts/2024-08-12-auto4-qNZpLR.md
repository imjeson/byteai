---
title: '曾毅：从科学和社会的视角对当代人工智能的反思'
date: 2024-08-13
author: ByteAILab

---

文章来源：[见地沙龙](https://mp.weixin.qq.com/s/V22xDtCP9TiWOrgclxtoAw)

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1723183929651/FpN38QjKVwb2lL_GTCjBcCWvkg2L.jpg)

曾 毅 人工智能科学家，中国科学院自动化研究所研究员

本文为曾毅先生在2023见地年会的发言，原主题为《从科学和社会的视角对当代人工智能的反思》。

我讲几个关键词。

---


第一个关键词是“自大”。

现在对于人工智能对世界的描述是用什么来描述的？是用X来描述的，就是参数。现在的人工智能研究，参数是百亿的、千亿的、万亿的，但有统计学家说，统计学就是用200个参数来描述人工智能学家用几百亿的参数才能做的事情。

这给我们很大的反思：当人工智能研究有万亿的参数来描述一个世界的时候，这个万亿的参数实际上就是万亿的X，代表万亿种变化，也代表着万亿的不确定性。既然它有万亿个不确定性，也有万亿个可能性。这个时候，它实际上带给我们的是万亿个未知，而这种未知是无限的想象还是无限的风险，我觉得是非常危险的地方。所以，人工智能研究者，实际上将这种不确定性、风险描述成了机遇，这是非常危险的。

第二个关键词是“说谎”。

人工智能是如何开始的？在一个屋子里，有一个机器，有一个人，当你无法区分你的对话对象是人还是机器的时候，说明这个机器达到了人类水平的智能，这是图灵提出的图灵测试。所以人工智能起源于“欺骗”，它通过欺骗达到衡量智能的水平。

...

人工智能具有自我感知，在这个基础之上区分自我和他人，取得认知和情感的共情，演化出道德直觉，并进行复杂的道德决策，这是开发对人类相对安全的人工智能应该走的一条道路。现在就把人类的规范灌输给它，应该这样做，不应该那样做，这是完全无效的。因为你可以跟它说做A，别人就可以跟它说做B，这都不是基于理解的。对于人工智能来讲，这只是一个分类问题。除非人工智能道德体跟我们人类一样，认为自己的道德直觉对自己来说是很必要的，因为它是随着演化产生的，这时候，道德直觉就像在地球上很难违反物理定律一样存在...

交流

黄裕生：曾毅老师，我有一个问题，现在处理做人工智能专业的人以外，包括一些做哲学的人，一直在担心一个问题，就是人工智能最后会超越我们人类自身甚至会取代我们人类，把我们当作低等物种给消灭了。其实，我一直是对此是持怀疑态度的，那么今天听你说完，好像也印证了我的这个想法，你甚至认为，现在所谓的人工智能是一种欺骗，是吧？那按目前人工智能的路径，有没有可能真正实现人工智能？

曾毅：人工智能是不是有可能替代人类或灭绝人类，按现在人工智能的道路发展，它有可能，但方式有两种：一个是，在它不理解人类社会的时候，它以人类不可预期的方式毁灭了人类，但是它都不知道它毁灭的是什么。这是人工智能最有可能给人类造成灾难性后果的原因，比如现在的大模型，你跟它说“我失业了”“我女朋友把我甩了”“我的家人都对我不好”，大模型就建议“那你最好去死”。因为现在在统计意义上，互联网上具有这样特征的人，绝大多数都去死了，所以它建议你去死。但是，它不明白什么叫生，什么叫死，什么叫情感。所以，当它给人类造成毁灭性影响的时候，它甚至不明白什么叫毁灭性的影响，这是人工智能目前风险最大的地方，也就是说，它根本不理解什么是风险，而人最怕的就是人工智能给人类社会造成灾难性的风险。

所以，我们并不需要超级智能的到来，使人工智能毁灭人类，人工智能如果被恶用，比如人工智能通过大规模的数据统计分析，它发现，给人类制造敌对情绪，给人类制造不信任，有机会使得人类社会把所有的计算资源给人工智能用，那么它就会做这样的事情。因为你给它设计了一个奖赏函数，让它获得最大规模的数据和资源，来完成一个目标。如果完成这样的目标——毁灭人类，是一个手段的话，那么它就可以这样去做，因为它不觉得这是代价。所以我说现在的人工智能的路径，没有任何理解可言，它的风险是巨大的。

但是在我看来，未来的超级智能是不是一定是悲观的，我并不这么看。因为在我看来，如果人工智能是超级智能的，那它也应该具有超级共情，也应该是超级利他的。赵老师讲情感的部分是不能丢掉的，如果它是超级利他的，可能它没有人类那么自私。所以...

...

本文链接：[https://www.aixinzhijie.com/article/6846388](https://www.aixinzhijie.com/article/6846388)
转载请注明文章出处
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。