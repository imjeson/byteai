---
title: '曾毅：从科学和社会的视角对当代人工智能的反思'
date: 2024-08-11
author: ByteAILab

---

曾 毅 人工智能科学家，中国科学院自动化研究所研究员。本文为曾毅先生在2023见地年会的发言，原主题为《从科学和社会的视角对当代人工智能的反思》。

---
我讲几个关键词。

第一个关键词是“自大”。

现在对于人工智能对世界的描述是用什么来描述的？是用X来描述的，就是参数。现在的人工智能研究，参数是百亿的、千亿的、万亿的，但有统计学家说，统计学就是用200个参数来描述人工智能学家用几百亿的参数才能做的事情。这给我们很大的反思：当人工智能研究有万亿的参数来描述一个世界的时候，这个万亿的参数实际上就是万亿的X，代表万亿种变化，也代表着万亿的不确定性。既然它有万亿个不确定性，也有万亿个可能性。这个时候，它实际上带给我们的是万亿个未知，而这种未知是无限的想象还是无限的风险，我觉得是非常危险的地方。所以，人工智能研究者，实际上将这种不确定性、风险描述成了机遇，这是非常危险的。虽然这种参数的扩充使得我们对于世界的描述更为精确，更多变，但是如果人工智能不是真正基于智能的，那么它带来的意外也是无限放大的，这在我看来是一种无知的自大。

第二个关键词是“说谎”。

人工智能是如何开始的？在一个屋子里，有一个机器，有一个人，当你无法区分你的对话对象是人还是机器的时候，说明这个机器达到了人类水平的智能，这是图灵提出的图灵测试。所以人工智能起源于“欺骗”，它通过欺骗达到衡量智能的水平。但图灵从来没有说过，当人工智能达到足以欺骗人类的时候，你应当用这种服务去欺骗人类。但这却是现在的人工智能天天在做的事情，就是用看似智能的事情来欺骗人类。

比如说到ChatGPT有什么样的能力，有人说它已经达到了人类水平。但是搞人工智能的人很少讲，当它的正确率远远超过人类的时候，比如做一件事，人的正确率只有90%，...

人类在做决策的时候，要负责任。

第三个关键词叫“放弃”。

人工智能的现阶段，人类放弃了人类应该坚守的东西。一个非常简单的例子：一篇英文文章产生，以前做公众号、做翻译的人快速翻译出来，供大家享用；现在，大家贴在ChatGPT里，翻译完了以后，马上贴在公众号上。原来通过人类的翻译，可以解决绝大多数问题，甚至是所有的问题。但是现在，人类放弃了人类的职责，人类在一个看似智能信息处理工具还完全不可靠的时候，使用它的输出去代替人类在社会中的价值，这是非常糟糕的。...详细请查看原文。

交流

黄裕生：曾毅老师，我有一个问题，现在处理做人工智能专业的人以外，包括一些做哲学的人，一直在担心一个问题，就是人工智能最后会超越我们人类自身甚至会取代我们人类，把我们当作低等物种给消灭了。其实，我一直是对此是持怀疑态度的，那么今天听你说完，好像也印证了我的这个想法，你甚至认为，现在所谓的人工智能是一种欺骗，是吧？那按目前人工智能的路径，有没有可能真正实现人工智能？

---

文章源链接：[https://www.aixinzhijie.com/article/6846388](https://www.aixinzhijie.com/article/6846388)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。