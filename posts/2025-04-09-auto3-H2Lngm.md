---
title: 'Vectara推出开源框架以评估RAG'
date: 2025-04-10
author: ByteAILab
---

与享誉全球的滑铁卢大学研究团队合作构建的Open RAG Eval框架为复杂的RAG部署带来了前所未有的可见性和优化。![图片](https://ai-techpark.com/wp-content/uploads/Vectara.jpg){ width=60% }

---


Vectara，企业检索增强生成（RAG）和AI驱动代理与助手的可信RAG平台，今天宣布了一项重大进展，推出Open RAG Eval，这是其新的开源RAG评估框架。该框架是与享誉全球的滑铁卢大学研究人员共同开发的，允许企业用户评估其RAG系统中每个组件和配置的响应质量，从而快速且一致地优化其AI代理和其他工具的准确性和可靠性。

Vectara的创始人兼首席执行官Amr Awadallah表示：“AI实现，尤其是针对代理RAG系统的实现，正变得愈发复杂。复杂的工作流程、日益增加的安全和可观测性关注，以及即将到来的法规，迫使组织以越来越临时的方式快速部署量身定制的RAG系统。为了避免将整个AI战略置于风险之中，这些组织需要一种一致而严谨的方式来评估性能和质量。通过与滑铁卢大学的Jimmy Lin教授及其卓越团队合作，Vectara正在主动应对这一挑战，推出我们的Open RAG Eval框架。”

Jimmy Lin教授是滑铁卢大学计算机科学系的David R. Cheriton讲席教授。他和他团队的杰出成员是创建世界一流信息检索评估基准和数据集的先驱。

Lin教授表示：“AI代理和其他系统在今天企业运营中变得越来越重要，并且是在未来增长规划中的中心。为了抓住这些技术所提供的潜力，组织需要结合科学严谨性和实用性的强大评估方法来不断评估和优化他们的RAG系统。我的团队和我非常高兴能与Vectara合作，将我们的研究成果带入企业，以推动全球AI系统的准确性和可靠性。”

Open RAG Eval旨在根据企业RAG堆栈的组件和配置来确定用户提示响应的准确性和有用性。该框架根据两个主要指标类别评估响应质量：检索指标和生成指标。

Open RAG Eval的用户可以利用平台的这一初始版本来帮助开发人员了解RAG管道在所选指标下的表现。通过检查这些指标类别，评估者可以在单独或综合得分上比较否则为“黑箱”的系统。

例如，一个低的相关性得分可能表明用户应升级或重新配置系统的检索管道，或者数据集中没有相关的信息。相对较低的生成得分则可能意味着系统应使用更强大的大型语言模型（LLM）——例如，在生成的响应包含幻觉的情况下——或者用户应更新其RAG提示。

该新框架旨在无缝评估任何RAG管道，包括Vectara自己的GenAI平台或任何其他自定义RAG解决方案。

Open RAG Eval帮助AI团队解决实际部署和配置挑战，例如：

- 是使用固定的令牌分块还是语义分块；
- 是否使用混合搜索或向量搜索，以及在混合搜索部署中使用什么值的λ；
- 使用哪个LLM以及如何优化RAG提示；
- 使用哪个阈值进行幻觉检测和修正，等等。

Vectara决定将Open RAG Eval作为一个开源的Apache 2.0许可工具发布，反映了公司在建立其他行业标准（如其开源的Hughes幻觉评估模型HHEM，已在Hugging Face上下载超过350万次）方面的成功记录。

随着AI系统的复杂性快速增长——尤其是代理的崛起——以及RAG技术的不断演变，组织将需要开放和可扩展的AI评估框架，以帮助他们做出正确的选择。这将使组织能够利用自己的数据，添加自己的指标，并将现有系统与新兴替代选项进行比较。Vectara的开源和可扩展方法将帮助Open RAG Eval跟上这些动态，促进来自AI社区的持续贡献，同时确保每个建议和贡献评估指标的实施得以充分理解并接受审查和改进。

---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。