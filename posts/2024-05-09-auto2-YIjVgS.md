---
title: 'OpenAI takes steps to boost AI-generated content transparency'
date: 2024-05-10
author: ByteAILab

---

OpenAI加入了Coalition for Content Provenance and Authenticity (C2PA) steering committee，并将整合开放标准的元数据到其生成式AI模型中，以增加所生成内容的透明度。![图片](https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/05/openai-generative-ai-artificial-intelligence-genai-c2pa.jpeg){ width=50% }

---

C2PA标准允许数字内容通过元数据进行认证，证明其来源，无论是完全由AI创建，使用AI工具进行编辑，还是传统方式捕获。OpenAI已经开始在其最新的DALL-E 3模型输出中的图像中添加C2PA元数据，该模型集成于ChatGPT和OpenAI API中。在OpenAI的即将推出的视频生成模型Sora中广泛推出时，元数据将被整合进去。
OpenAI解释道：“即使没有这些信息（或者可能删除它），人们仍然可以创建欺骗性内容，但他们无法轻易伪造或修改这些信息，这使其成为建立信任的重要资源。”
此举是针对日益增长的担忧，即AI生成的内容可能在美国、英国和其他国家今年的重大选举前误导选民。认证AI创建的媒体有助于应对旨在传播虚假信息的deepfakes和其他篡改内容的问题宣传活动。
尽管技术措施有所帮助，但OpenAI承认，在实践中实现内容的真实性需要平台、创作者和内容处理方的集体行动来保留终端消费者的元数据。
除了整合C2PA，OpenAI还正在开发新的出处方法，如耐篡改水印技术用于音频和图像检测分类器，以识别AI生成的视觉。OpenAI已经向研究人员开放了DALL-E 3图像检测分类器的访问申请，通过其研究人员访问计划。该工具预测了图像来自OpenAI模型的可能性。“我们的目标是启动独立研究，评估分类器的有效性，分析其实际应用，提出相关考虑因素以及探索AI生成内容的特性，”该公司表示。内部测试显示，在区分非AI图像和DALL-E 3视觉方面具有较高准确性，大约有98%的DALL-E图像被正确识别，少于0.5%的非AI图像被错误标记。然而，分类器在区分由DALL-E和其他生成式AI模型产生的图像方面更为困难。OpenAI还将水印技术融入其Voice Engine定制语音模型，目前处于有限预览阶段。该公司相信，增加出处标准的采用将使元数据随内容通过其完整生命周期，填补“数字内容真实性实践中关键差距。”
OpenAI与微软合作成立了一项200万美元的社会抗干扰基金，以支持AI教育和理解，包括通过AARP、国际民主促进协会和人工智能合作伙伴关系。OpenAI声称：“尽管上述技术解决方案为我们提供了积极的防御工具，但实际上实现内容的真实性将需要集体行动。”
“我们的出处工作仅是更广泛行业努力的一部分，我们的许多同行研究实验室和生成式AI公司也正在推进这一领域的研究。我们赞赏这些努力-行业必须合作并分享见解，以增强我们的了解，并继续在线上推进透明度。”
[图片来源：Marc Sendra Martorell]
参见：Chuck Ros, SoftServe: 以负责任的方式提供变革性人工智能解决方案

想要从业界领袖那里了解更多关于人工智能和大数据的知识？查看将在阿姆斯特丹、加利福尼亚和伦敦举办的AI & 大数据博览会。这个全面的活动与其他领先的活动同期举行，包括智能自动化会议、BlockX、数字转型周和网络安全与云博览会。
探索由TechForge提供的其他即将举行的企业技术活动和网络研讨会。

---

注意：Title、Date、Body 三个部分的内容，放入到对应的位置。最后只需要输出为Makedown源文件格式内容。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。