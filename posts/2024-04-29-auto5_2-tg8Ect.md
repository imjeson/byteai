---

title: 'Sora爆红视频幕后：被骗了，用了成吨的后期才有这效果'
date: 2024-04-30
author: ByteAILab

---

「不怕 AI 消灭人类，就怕用 AI 的人太聪明。」

今年 2 月份，OpenAI 发布了人工智能文生视频大模型 Sora，并放出了第一批视频片段，掀起了 AI 生成视频浪潮。

---
目前，Sora 仍未进行公测，只有一些视觉艺术家、设计师、电影制作人等获得了 Sora 的访问权限。他们发布了一些 Sora 生成的视频短片，其连贯、逼真的生成效果令人惊艳。

最近，被誉为「朋克摇滚皮克斯」的加拿大多媒体制作公司 Shy Kids 发布了一段借助 Sora 制作的视频短片《Air Head》，在社交媒体上迅速引起广泛关注。

据悉，这部制作精美的短片主要由 3 个人完成，花费不到 2 周的时间。其中，Sidney Leeder 担任制片人，Walter Woodman 担任编剧和导演，而 Patrick Cederberg 负责后期制作。

本周，知名视觉特效总监 Mike Seymour 采访了 Patrick Cederberg，就《Air Head》制作过程、技术难点等信息展开了提问，并在 fxguide 上发布一篇文章介绍了 Sora 在视频实际制作过程中发挥的作用和存在的问题。

其中，Patrick 表示：「Sora 是一款非常强大的工具，我们已经在思考如何把它融入现有电影制作流程中，但目前 Sora 仍处于测试阶段，在影片制作过程中也会『翻车』。例如，气球的颜色在每次生成中都会改变、镜头中会出现一些瑕疵等等，要想获得最佳表现效果，仍需大量后期制作。」

AI 生成视频并非仅仅是图像生成器的进阶版。更准确地说，它们可能是我们向通用人工智能（AGI) 迈出的重要一步。但正如 Sora 开发团队本周接受采访时所说的，当前的 AI 视频模型仍处于早期阶段。

OpenAI 研究科学家，Sora 项目领导者 Tim Brooks 表示：我觉得现在 Sora 位置，就像是视觉模型新范式的 GPT-1 阶段。

《Air Head》是如何完成的？机器之心对 Mike Seymour 的文章进行了不改变原意的编译、整理，以下是该文章原文：

**用户界面（UI）**

Sora 的用户界面允许用户输入一段文本 prompt，然后 ChatGPT 将其转换为一个更长的字符串，再触发视频片段的生成。目前，没有其他输入方式 —— 还没有实现多模态输入。这一点很重要，因为尽管 Sora 因其生成结果中的对象一致性而受到称赞，但目前还没有任何方法来帮助匹配两个镜头（即两次生成）的内容。即使第二次运行相同的 prompt，生成结果也会不同。

Patrick 介绍说：「我们尽可能做到的是在我们的 prompt 中给出超级详细的描述，例如解释角色的服装、气球的类型。这是我们获得一致性的方法。从一个镜头到另一个镜头 / 一次生成到下一次生成，还没有完全控制一致性的方法。」

单个视频片段的确可以展现 Sora 令人惊叹的技术，但使用这些片段取决于你对隐式或显式镜头生成的理解。

假设你要求 Sora 在厨房里进行一个长镜头跟踪拍摄，桌子上有一个香蕉。在这种情况下，它将依赖其对「香蕉属性」的隐式理解来生成一个展示香蕉的视频。通过训练，Sora 已经学习了一些香蕉属性：比如「黄色」、「弯曲」、「有深色的末端」等等。没有香蕉的实际记录图像。没有「香蕉数据库」，而是有一个更小的、压缩的、隐藏的「潜在空间」，描述了香蕉是什么，每次运行都会展示对潜在空间的一种新解释。你的 prompt 依赖于对香蕉属性的隐式理解。

**制作角色**

为了制作《Air Head》，团队根据大致的剧本生成了多个视频片段，但是没有明确的方式来确保黄色气球头在每个镜头中都保持相同。有时，当 prompt 要一个黄色气球时，生成结果甚至可能不是黄色的。有时，气球上可能嵌入了一张脸，或者似乎在气球的正面画了一张脸。由于现实生活中许多气球都有绳子，因此生成结果中称为 Sonny 的气球人经常会在衣服前襟处有一根绳子。这是因为 Sora 隐式地将绳子与气球联系起来，因此在后期制作中这些需要被移除。

**分辨率**

《Air Head》只使用了 Sora 生成的镜头，但其中很多镜头都经过了调色、处理和稳定化，所有镜头都被提高了分辨率。团队处理的这些片段最初是以较低分辨率生成的，然后使用 Sora 或 OpenAI 之外的 AI 工具进行超分。

「你可以采用 720p 的分辨率，我相信已经有 1080p 了，但它需要一段时间来渲染。为了速度，《Air Head》的所有镜头都是以 480p 制作的，然后使用 Topaz 来提高分辨率」，Patrick 介绍道。

在关键帧方面，Patrick 解释道：「在实际生成中，不同动作的发生有一点时间控制，但并不精确，甚至有点像是碰运气 —— 目前还不确定 Sora 是否真的能完成这一点。」不过，Shy Kids 使用的是最早版本的模型，Sora 仍在不断开发中。

除了选择分辨率，Sora 还允许用户选择长宽比，比如肖像模式或风景模式（或正方形）。这在从 Sonny 的牛仔裤向上摇摄到他的气球头的镜头中非常有用。遗憾的是，Sora 无法原生渲染这样的移动，总是希望镜头的主要焦点 —— 气球头出现在镜头中。因此，团队以肖像模式渲染了这个镜头，然后通过后期的裁剪手动创建了向上摇摄的效果。

**摄像机方向**

对于许多生成式 AI 工具来说，训练数据附带的元数据是宝贵的信息来源，比如摄像机元数据。在电影镜头中，「跟踪」、「平摇」、「竖摇」、「推进」等概念都不是元数据所能捕捉的术语或概念。

描述镜头对影片制作来说非常重要，Patrick 指出：「最初 Sora 中并没有这个功能。不同的人描述电影镜头的方法也不同。OpenAI 的研究人员在艺术家使用这个工具之前，并没有真正像电影制作人那样思考。」

Shy Kids 知道他们使用的是 Sora 早期版本，但「初始版本的 Sora 在摄像机角度方面有点随机。」Sora 是否真的能理解 prompt 还不得而知，OpenAI 的研究人员只是专注于视觉生成，或许不考虑故事讲述者将如何使用它。

「Sora 正在改进，生成控制还没有完全到位。输入一个『摄像机摇摄』，我认为十次中有六次会得到想要的结果」，Patrick 说道。

这不是一个个例问题，几乎所有 AI 视频生成公司都面临着同样的问题，Runway AI 可能是在提供描述摄像机运动方面最先进的，但 Runway 渲染片段的质量和长度都不如 Sora。

**渲染时间**

视频片段可以以不同长度的时间段进行渲染，如 3 秒、5 秒、10 秒、20 秒，最长可达一分钟。渲染时间取决于一天中的时间段以及云服务的需求量。

Patrick 介绍：「一般来说，每次渲染大约需要 10 到 20 分钟。根据我的经验，我选择的渲染时长对渲染时间的影响很小。如果渲染时长是 3 到 20 秒，渲染时间往往不会在 10 到 20 分钟的范围内变化太大。」

虽然所有画面都是 Sora 生成的，但《Air Head》仍然需要大量后期工作。例如，有时会有一张脸在气球人 Sonny 上，就好像是用记号笔画上去的，这些瑕疵将在后期工作中被移除。

**原始素材 vs 最终成品 ——300:1**

Shy Kids 的方法是像制作纪录片一样进行后期制作和编辑，即有很多镜头，需要从这些素材中编织出一个故事，而不是严格按照剧本拍摄。对于最终出现在影片中的 90 秒镜头，Patrick 估计他们生成了「数百个 10 到 20 秒的片段」。他补充说：「我猜原始素材和最终成品的比例大概是 300:1。」

**奇怪的「慢动作」**

《Air Head》的许多片段生成时就好像是以慢动作拍摄的，尽管这并没有在 prompt 中被要求。这种情况发生的原因尚不清楚，但许多片段因此需要重新调整时间，以使其看起来像是实时拍摄的。这似乎与训练数据有关。

值得一提的是，Shy Kids 在他们的 prompt 中使用了「35 mm film（35 毫米胶片）」这个关键词，并发现这在一定程度上给了他们所追求的一致性。

**版权问题**

OpenAI 试图尊重版权，不允许生成可能侵犯版权或肖像权的内容。例如，如果用户的 prompt 类似于「35 毫米胶片，在一个未来主义的太空船中，一个男人拿着光剑向前走」，Sora 将不允许生成该片段，因为它太接近《星球大战》了。

Patrick 回忆说，当他们最初只是想测试 Sora 时：「我不假思索地输入了『阿罗诺夫斯基类型的镜头』，然后就被告知不能这样做。」Sora 出于版权问题会拒绝这类 prompt。

值得注意的是，Sora 生成的视频都是没有声音的，《Air Head》中主角 Sonny 的声音是 Patrick 本人的声音。

Shy Kids 团队表示已经开始为《Air Head》制作一部精彩的、人物有自我意识的、或许带点讽刺意味的续集。但对于电影制作等实际项目来说，Sora 可能还需要一段时间才能达到创作者所需的精确度。

**参考链接：**
https://www.fxguide.com/fxfeatured/actually-using-sora/
https://www.youtube.com/watch?v=reMnn6bV_fI
https://twitter.com/dotey/status/1783765343975960915

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。