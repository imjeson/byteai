---
title: '为什么学线代时不知道：矩阵与图竟然存在等价关系'
date: 2024-08-20
author: ByteAILab

---

在学习数学时，我们常因所学知识的难度和抽象而受挫；但有些时候，只需换个角度，我们就能为问题的解答找到一个简单又直观的解法。举个例子，小时候在学习和的平方 (a+b)² 公式时，我们可能并不理解为什么它等于 a²+2ab+b²，只知道书上这么写，老师让这么记；直到某天我们看见了这张动图：

![图片](https://image.jiqizhixin.com/uploads/editor/f2696a94-526d-4c1a-973a-53ddd1d43828/640.gif)

登时恍然大悟，原来我们可以从几何角度来理解它！

现在，这种恍然大悟之感又出现了：非负矩阵可以等价地转换成对应的有向图！

如下图所示，左侧的 3×3 矩阵其实可以等价地表示成右侧的包含三个节点的有向图，并且这种表示方式对矩阵和<mark>图论</mark>都大有帮助。

---


![图片](https://image.jiqizhixin.com/uploads/editor/6a745a85-c39e-47aa-a15d-761e849557b8/640.png)

这个例子来自致力于让每个人都能看懂数学（make math accessible for everyone）的数学家 Tivadar Danka。这位自称「混乱善良（Chaotic good）」的数学家通过一系列推文和博客文章生动地介绍了矩阵和图的这种等价性及其用途。截至目前，这些推文已被阅读了超过 200 万次，收获了超过 3200 次转发和 9100 次收藏。

![图片](https://image.jiqizhixin.com/uploads/editor/6d0c632b-6498-40d5-a309-99074175d821/640.png)

**矩阵与有向图的对价性**

如上图的例子所示，如果我们将其中每一行都视为一个节点，则每一个元素都可表示成一条有向且加权的边。当然，0 元素可以忽略不计。如果该元素位于第 i 行第 j 列，则对应于从节点 i 到节点 j 边。

乍一看，这似乎很复杂，但我们可以先看其中一个节点。

![图片](https://image.jiqizhixin.com/uploads/editor/05b35b48-20ff-444d-82d0-8294398919b3/640.png)

如图所示，对于这个 3×3 的矩阵，第 1 行对应于最顶部的节点（我们这里称之为 1 号节点），其包含 3 个元素但其中一个为 0，因此该节点延伸出了两条边。其中黄色边表示的是 (1,1) 处的元素 0.5，因此它是指向自身且<mark>权重</mark>为 0.5 的有向边。同理，蓝色边是指向 2 号节点且<mark>权重</mark>为 1 的边。

这样一来，我们便能分析出，矩阵的第 i 列便对应于指向 i 号节点的所有边。

![图片](https://image.jiqizhixin.com/uploads/editor/e8bc5f4e-e362-4ece-8c5d-2239562fd7b9/640.png)

**这种等价表示有什么用？**

非负矩阵与有向图之间的这种等价性既能帮助我们更好地理解矩阵及其运算，也能帮助简化一些计算过程；反过来，这也能帮助我们从新的视角理解图。

举个例子，矩阵的幂就对应于图中的游走。

![图片](https://image.jiqizhixin.com/uploads/editor/2f8eed6c-5663-444d-ad42-1c6f3b8a4e5f/640.png)

如上图所示，对于 n×n 的方形矩阵 A 的 k 次幂，其中每个元素的求和过程都会纳入所有可能的 k 步游走。

举个例子，假设我们要计算上述 3×3 矩阵的平方。

![图片](https://image.jiqizhixin.com/uploads/editor/80cc5b94-6b05-48c0-8692-1ebeb6f6a1d0/640.png)

如果使用矩阵乘法，则我们需要这样计算：

![图片](https://image.jiqizhixin.com/uploads/editor/078ad021-2bae-4ec4-826e-4abe1aa73013/640.png)

对于运算结果的第一个元素，我们可以得到结果 = 0.5×0.5+1×0.2+0×1.8 = 0.45。最终，我们可以得到完整的结果为：

![图片](https://image.jiqizhixin.com/uploads/editor/80cc5b94-6b05-48c0-8692-1ebeb6f6a1d0/640.png)

但如果借助上述的图游走方法，则可以通过游走路径来得到结果。同样，对于结果矩阵的第一个元素，就需要对符合 a_{1,l}→a_{l,1} 的所有 2 步游走路径求和。

但是，如果这个有向图表示的是马尔科夫链的状态，其转移概率矩阵的平方本质上就表示该链 2 步之后达到某个状态的概率。

不仅如此，用图表示矩阵还能让我们深入了解非负矩阵的结构。为此，Danka 表示我们需要先了解「强连通分量（strongly connected components）」这一概念。

**强连通分量**

什么是强连通分量？对于一个有向图，如果能从该图中的每个节点到达其它每个节点时，我们就说该图是强连通的。如下图所示。

而强连通分量就是指有向图中能够实现强连通的部分 / 子图。如下图所示，左右各有一个强连通分量，而中间的白色边不属于任何强连通分量。

对应于强连通图的矩阵是不可约矩阵，...

Danka 通过一个例子给出了解释。（为了说明简单，例子中的所有<mark>权重</mark>均为单元<mark>权重</mark>，但实践中这些<mark>权重</mark>值可以是任意非负值。）

下面将这个包含强连通分量但本身并不强连通的图转写成对应的矩阵形式：

...

而这个矩阵是可约矩阵。

...

可以看到，在主对角线上的两个子矩阵分别表示两个强连通分量，而右上方的子矩阵表示从第 1 个强连通分量指向第 2 个强连通分量的边，左下方的则表示从第 2 个强连通分量指向第 1 个强连通分量的边（因为没有这样的边，所以全为 0）。

这种书写<mark>分块</mark>矩阵的形式被称为弗罗贝尼乌斯标准形（Frobenius normal form）。

...（略）

**结语**

很显然，矩阵和图之间的这种等价关系既有助于<mark>图论</mark>研究，也能为<mark>线性代数</mark>的计算和分析提供一个新视角。其也有一些重要的实际用途，比如 DNA 数据就常被表示成矩阵或图的形式。

另外，我们都知道矩阵运算对于当前的大模型 AI 的重要性，而以<mark>知识图谱</mark>为代表的图也正通过检索增强式搜索等技术成为当前 AI 的重要助力。将这两者关联起来，或许能在 AI 可解释性以及图<mark>人工智能</mark>方面带来一些新的突破。至少，这能帮助我们更好地学习<mark>线性代数</mark>。

实际上，上述内容正是提炼自 Tivadar Danka 正在编写的《Mathematics of Machine Learning》一书。这本书将由浅入深地介绍与<mark>机器学习</mark>相关的数学知识，让读者真正知其然也知其所以然，并且 Danka 自信地宣称这会是「学习<mark>机器学习</mark>的最佳资源」。目前他已经在网上发布了两章预览，感兴趣的读者可访问：[链接](https://tivadardanka.com/mathematics-of-machine-learning-preview/)
                                        
---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。