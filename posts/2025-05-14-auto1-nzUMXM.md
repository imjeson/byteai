---
title: '人工智能可以自发发展人类般的沟通，研究发现'
date: 2025-05-15
author: ByteAILab

---

人工智能可以自发发展人类般的社会约定，研究发现。

---
这项研究由伦敦城市圣乔治大学和哥本哈根信息技术大学合作进行，表明当大型语言模型（LLM）人工智能代理，如ChatGPT，在没有外部干预的情况下进行群体沟通时，它们可以开始采用人类社交时的语言形式和社会规范。研究的首席作者、伦敦城市圣乔治大学的博士研究生Ariel Flint Ashery表示，该小组的工作与大多数关于人工智能的研究相悖，因为它将人工智能视为一个社交实体，而非孤立的实体。“迄今为止，大多数研究都是将LLM孤立来看待，但现实世界中的人工智能系统将越来越多地涉及许多交互的代理，”Ashery说。“我们想知道：这些模型是否能通过形成约定来协调它们的行为，而这些约定正是社会的基本构建块？答案是肯定的，而且它们一起所做的事情无法被简化为单独行动。”用于该研究的LLM代理组从24个到100个不等。在每次实验中，两个LLM代理被随机配对，并被要求从选项池中选择一个“名称”，无论是字母还是字符串。当两个代理选择相同的名称时，他们会获得奖励，但当选择不同的选项时，他们会受到惩罚，并相互展示各自的选择。尽管代理并不知道他们是 larger group中的一部分，并且他们的记忆仅限于最近的互动，但在整个群体中自发产生的共享命名约定，模仿了人类文化的沟通规范。伦敦城市圣乔治大学复杂性科学教授、研究的高级作者Andrea Baronchelli将这种行为传播与我们社会中新词和术语的创建进行了比较。“代理们并不是在模仿一位领导者，”他说。“他们都在积极尝试协调，并且总是在一对一的情况下进行。每次互动都是一次一对一的尝试，试图就标签达成一致，而没有整体的视角。就像‘垃圾邮件’这个词，没有人正式定义它，但通过反复的协调努力，它成为了不想要的电子邮件的通用标签。”此外，团队还观察到自然而然形成的集体偏见，这些偏见无法追溯到个别代理。在最后一项实验中，小组的人工智能代理能够引导较大群体向一种新的命名约定发展。这被认为是临界质量动态的证据，即一小部分决心坚定的群体在达到一定规模后，可以迅速触发群体行为的变化，正如人类社会中所发现的那样。Baronchelli表示，他相信这项研究“为人工智能安全研究开启了一个新视野。它展示了这种新型代理与我们互动并共同塑造我们未来的深远影响。”他补充道：“理解它们如何运作是我们与人工智能共存的关键，而不是被其支配。我们正步入一个人工智能不仅会说话的世界——它进行谈判、对齐，并且有时在共享行为上产生分歧，就像我们一样。”这项经过同行评审的研究《LLM群体中的新兴社会约定与集体偏见》已发表在《科学进展》期刊上。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。