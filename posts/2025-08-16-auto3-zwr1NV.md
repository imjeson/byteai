---

title: 'Cadence 通过 NVIDIA 提升十亿门 AI 设计的功耗分析'
date: 2025-08-17
author: ByteAILab

---

新的 Cadence Palladium 动态功耗分析应用程序使 AI/ML 芯片和系统的设计者能够创建更具能效的设计并加快上市时间。![图片](https://ai-techpark.com/wp-content/uploads/Cadence-Boosts.jpg){ width=60% }

---
Cadence（纳斯达克：CDNS）今天宣布，通过与 NVIDIA 的密切合作，在预硅设计的功耗分析方面取得了重大突破。借助 Cadence® Palladium® Z3 企业仿真平台的先进能力，利用新的 Cadence 动态功耗分析（DPA）应用程序，Cadence 和 NVIDIA 实现了曾被认为不可能的目标：在短短几个小时内实现十亿门 AI 设计的硬件加速动态功耗分析，涵盖数十亿个周期，其准确率高达 97%。这一里程碑使得针对 AI、机器学习（ML）和 GPU 加速应用的半导体和系统开发者能够设计出更具能源效率的系统并加速其上市时间。

当今最先进的半导体和系统的巨大复杂性和计算要求给设计师带来了挑战，以往设计师无法在现实条件下准确预测其功耗。传统的功耗分析工具无法在几百万次周期之外进行扩展，导致时间表不切实际。借助与 NVIDIA 的紧密合作，Cadence 通过硬件辅助的功耗加速和并行处理创新，克服了这些挑战，使得在早期设计中能够实现数十亿次周期的前所未有的精度。

“Cadence 和 NVIDIA 正在建立我们通过深度合作所开发的变革性技术的悠久历史，”Cadence 的企业副总裁兼总经理 Dhiraj Goswami 说。“这个项目重新定义了界限，使数十亿个周期在两到三小时内得以处理。这使客户能够自信地满足积极的性能和功耗目标，加快其硅片上市时间。”

“随着代理 AI 和下一代 AI 基础设施时代的迅速发展，工程师需要复杂的工具来设计更节能的解决方案，”NVIDIA 硬件工程副总裁 Narendra Konda 表示。“通过将 NVIDIA 的加速计算专业知识与 Cadence 的 EDA 领导地位相结合，我们正在推进硬件加速功耗分析，以实现加速计算平台的更精确效率。”

Palladium Z3 平台使用 DPA 应用程序在现实工作负载下准确估计功耗，允许在芯片制造前验证功能、功耗和性能，当时设计仍然可以优化。特别是在 AI、ML 和 GPU 加速应用中，早期的功率建模提高了能源效率，同时避免了因过度或不足设计半导体而导致的延误。Palladium DPA 集成于 Cadence 的分析和实施解决方案中，使设计师能够在整个设计过程中处理功耗估算、减小和签核，从而获得尽可能高效的硅片和系统设计。

---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。