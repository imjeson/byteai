---
title: 'RAGFlow开源Star量破万，是时候思考下RAG的未来是什么了'
date: 2024-07-09
author: ByteAILab

---

AIxiv专栏是机器之心发布学术、技术内容的栏目。过去数年，机器之心AIxiv专栏接收报道了2000多篇内容，覆盖全球各大高校与企业的顶级实验室，有效促进了学术交流与传播。

---
如果您有优秀的工作想要分享，欢迎投稿或者联系报道。投稿邮箱：liyazhou@jiqizhixin.com；zhaoyunfeng@jiqizhixin.com

本文作者为张颖峰，英飞流 InfiniFlow 创始人 CEO，连续创业者，先后负责 7 年搜索引擎研发，5 年数据库内核研发，10 年云计算基础架构和大数据架构研发，10 年人工智能核心算法研发，包括广告推荐引擎，计算机视觉和自然语言处理。先后主导并参与三家大型企业数字化转型，支撑过日活千万，日均两亿动态搜索请求的互联网电商业务。

搜索技术是计算机科学中最难的技术挑战之一，迄今只有很少一部分商业化产品可以把这个问题解决得很好。大多数商品并不需要很强的搜索，因为这和用户体验并没有直接关系。...

以上这种基于语义相似度的方法已经工作了很多年：首先，将数据分块（例如根据段落），然后通过 Embedding 模型把每个块转成向量保存到向量数据库。在检索过程中，把提问也转成向量，接着通过向量数据库检索到最接近该向量的数据块，这些数据块理论上包含跟查询语义最相似的数据。

在整个链路中，LLMOps 工具可以操作的事情有：

- 解析和切分文档。通常采用固定大小来把解析好的文本切成数据块。
- 编排任务，包括数据写入和查询时，负责把数据块发到 Embedding 模型；返回的向量连同数据块共同发给向量数据库；根据提示词模板拼接向量数据库返回的内容。
- 业务逻辑组装。例如用户对话内容的生成和返回，对话跟业务系统的连接，等等。

这个流程的建立很简单，但搜索效果却很一般，因为这套朴素的基于语义相似度的搜索系统包含若干局限：

- Embedding 是针对整块文本的处理，对于一个特定的问题，它无法区分文字中特定的实体 / 关系 / 事件等权重明显需要提高的 Token，这样导致 Embedding 的有效信息密度有限，整体召回精度不高。
- Embedding 无法实现精确检索。例如如果用户询问 “2024 年 3 月我们公司财务计划包含哪些组合”，那么很可能得到的结果是其他时间段的数据，或者得到运营计划，营销管理等其他类型的数据。
- 对 Embedding 模型很敏感，针对通用领域训练的 Embedding 模型在垂直场景可能表现不佳。
- 对如何数据分块很敏感，输入数据的解析、分块和转换方式不同，导致的搜索返回结果也会大不同。而依托于 LLMOps 工具的体系，对于数据分块的逻辑往往简单粗暴，忽视了数据本身的语义和组织。
- 缺乏用户意图识别。用户的提问可能并没有明确的意图，因此即便解决了前述的召回精度问题，在意图不明的情况下，也没有办法用相似度来找到答案。
- 无法针对复杂提问进行回答，例如多跳问答。

因此可以把这类以 LLMOps 为核心的 RAG 看作 1.0 版本，它的主要特点在于重编排而轻效果，重生态而轻内核。因此，从面世一开始就迅速普及，普通开发者可以借助于这些工具快速搭建起原型系统，但在深入企业级场景时，却很难满足要求，并且经常处于无计可施的状态。随着 LLM 快速向更多场景渗透，RAG 也需要快速进化，毕竟搜索系统的核心是找到答案，而不是找到最相似的结果...

---
。注意：Title、Date、Body 三个部分的内容，放入到对应的位置。最后只需要按照格式标准输出为Makedown源文件格式内容。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。