title: 'Inworld Runtime：首个针对消费者应用的AI运行时'
date: 2025-08-18
author: ByteAILab

---

今天，Inworld AI发布了Inworld Runtime——首个为消费者应用程序设计的AI运行时。![图片](https://ai-techpark.com/wp-content/uploads/Inworld-Runtime.jpg){ width=60% }

---
它使开发者能够更快地从原型转向生产，并支持用户增长从10到1,000万用户，几乎不需要修改代码。通过自动化AI操作，Inworld Runtime释放了工程资源用于新产品开发，并提供工具设计和部署无代码实验。Inworld目前的合作伙伴，包括主要媒体公司、AAA游戏工作室和AI原生初创企业，已经将Runtime作为其下一代实时、多百万用户AI功能和体验的AI堆栈基础。

为了加速与这些客户的合作，Inworld将Runtime构建为内部基础设施，以应对消费者AI的独特需求：在多百万的并发用户规模下保持实时性能，满足以用户为中心的参与质量期望，其成本远低于每人每天一分钱。随着来自健康/健身、学习和社交应用的公司开始接触Inworld，团队发现这些公司面临的挑战与Runtime已经在内部解决的挑战完全相同，因此决定公开发布它。

“Inworld Runtime的构建是因为我们自己需要它。现有工具无法满足我们合作伙伴所需的速度和规模，”Inworld AI首席执行官Kylan Gibbs说。“当我们意识到每个消费者AI公司都面临这些障碍时，我们知道必须开放我们所构建的东西。我们看到行业达到了一个转折点，成千上万的开发者正面临我们曾经遇到的扩展壁垒，因此我们在过去一年中奋力增加超出我们内部需求的能力，以创建加速整个消费者AI生态系统的通用后端。”

在消费者AI领域的领军者所需的三个关键因素
通过四年的消费AI应用部署，Inworld发现三项关键因素决定了成功或失败。所有三项的卓越表现是必需的，任何一项的弱点都将阻止消费者AI功能或应用达到市场领导地位：
1. 从原型到生产的时间
虽然创建AI演示只需几小时，但达到生产就绪通常需要6个月以上的基础设施和质量提升工作。团队必须处理提供商停机、实施回退、管理速率限制、提供和加速计算能力、优化成本并确保一致的质量。在与行业领导者合作的过程中，Inworld看到大多数消费者AI项目要么实现跃升，要么停滞不前，死在原型和可扩展现实之间的差距中。

2. 对新产品开发的资源分配
发布后，大多数工程团队将超过60%的时间花费在维护任务上：调试提供商变更、管理模型更新、处理规模问题和优化成本。这让为新功能开发的资源所剩无几，导致产品停滞不前，而竞争对手却在进步。Inworld亲身经历了这一点，因为即使是创新团队也会陷入维护周期，而无法构建用户下一个想要的东西。

3. 实验速度
消费者偏好不断演变，但传统的部署周期为2-4周，无法与这一速度相匹配。团队需要测试数十种变体，衡量真实用户影响，并在没有代码部署和应用商店审批摩擦的情况下扩大赢家。与业内合作伙伴的合作显示，快速学习者获胜，但现有基础设施使快速迭代几乎不可能。

“我们在19天内从原型扩展到100万用户，成本减少超过20倍。”——Fai，Status首席执行官

Inworld Runtime的技术设计
Inworld Runtime通过多项创新来提供这些能力，包括：
1. 自适应图
基于C++的图执行系统，解决了大多数AI框架遇到的跨平台扩缩限制，配有针对Node.js、Python等的SDK。开发者使用预优化节点作为构建块（来自顶级提供商的LLM、TTS、STT、知识、记忆等API）来组合应用程序，处理低级集成工作，并自动优化组件之间的数据流。相同的图能够在不需要大量代码更改和管理端点的情况下，从10位测试用户无缝扩展到1000万并发用户。通过友好的接口直接实现从原型到生产的飞跃，时间只需几天，而非几个月。

2. 自动化MLOps
除了基本操作外，Runtime还提供自-contained基础设施自动化，集成了在每次交互中捕获日志、追踪和指标的遥测。可操作的洞察，如识别错误、用户模式和优化机会，可通过Portal（Inworld的可观察性和实验管理平台）进行汇报。Runtime在提供商之间执行自动故障转移，管理模型的容量并智能地处理速率限制。它还支持自定义本地部署，为企业优化模型托管。随着应用程序的扩展，Inworld提供访问所有必要云基础设施的权限，以训练、调整和托管自定义模型，打破默认模型的成本质量范畴。

3. 实时实验
一键部署或扩展实验。配置与代码分离，能够即时进行A/B测试，而不必面对部署障碍。Runtime可以通过SDK定义变体，自动同时运行数百个实验，并通过Portal管理测试不同的模型、提示、图形配置和逻辑流。变化在几秒内部署，并自动测量对用户指标的影响。

Inworld Runtime早期采用者的验证结果
Runtime部署证明了一致的技术成就：

Inworld的最大合作伙伴（主要知识产权所有者、媒体公司和AAA工作室）已经将Runtime作为其AI堆栈的基础
Wishroll在19天内从原型扩展到100万用户，成本减少超过95%
Little Umbrella能够在使用Inworld减少现有标题的更新和维护工作量的同时，推出新的AI游戏
Streamlabs构建了一个多模态实时流媒体助手，其特点在六个月前甚至都不可行
Bible Chat升级和扩展了其语音功能，同时将语音成本降低了85%
Nanobit为数百万用户提供个性化AI叙事，实现可持续的单位经济学

可用性和定价
开发者可以立即开始下载Runtime SDK，地址为inworld.ai/runtime，配有全面的文档和迁移指南。Runtime原生与Cursor、Claude Code、Google CLI、Windsurf和Zencoder等代码助手协同工作。开发者可以开始自己的项目，也可以使用Inworld的模板和演示应用作为灵感。Runtime灵活部署在客户端应用程序中，或者在任何云提供商的服务器上，亦或通过Inworld管理的模型托管进行自定义本地安装。投入生产后，可以使用Portal进行可观察性和快速实验。

Runtime定价完全基于使用情况，无需前期成本。开发者可以在所有模型和功能上进行实验，并仅为成功扩展支付费用，确保与消费者应用经济学的对齐，因为使用增长时成本必须保持可持续。借助Anthropic、Google、Mistral和OpenAI的最先进模型，开发者可以在选择适合其用例的最佳模型时实现最大选择自由。Runtime还通过Lightning-fast提供商Groq、Tenstorrent和Fireworks AI提供对顶级开源模型（如Deepseek、Llama和Qwen）的访问。与现有Microsoft或Google关系的开发者可以通过Azure市场和Google云市场利用其云承诺来访问Runtime。

---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。