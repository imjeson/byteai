---

title: '一家芯片公司，猛追英伟达'
date: 2024-08-26
author: ByteAILab

---

文章来源：[半导体行业观察](https://mp.weixin.qq.com/s/gd7PPipYTOQhbUbpu0eKjg)
来源：内容编译自nextplatform。

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1724381690737/FmIHacsesLBrm7cjEzqOXnQpgr1e.png)

当前的 AI 训练和一些 AI 推理集群有两个网络。

---
后端网络将计算引擎组（通常是 GPU 加速器，通常是 Nvidia 的加速器）相互连接，以便它们可以共享工作和数据。前端网络将计算引擎的 CPU 主机相互连接、连接到存储以及连接到外部世界。

InfiniBand 已逐渐成为后端网络的主导，而以太网则倾向于用于前端网络。Arista Networks 和 Cisco Systems 等公司也希望在升级前端网络的同时，在后端占有一席之地。

思科在其最近的财务报告中表示，其 Silicon One ASIC 在后端 AI 集群网络试验中得到了一定程度的应用，但它也看到企业在准备部署 AI 训练和推理系统时...

...量将达到几万，目标是 100,000 个 GPU。所以我认为明年更有希望。其中一些可能会在今年实现。但我认为我们已经非常投入——从试验到试点，试验的数量为数百个。今年，我们的 GPU 数量达到了数千个。但我不会只关注第四季度。我会关注全年，然后说，是的，我们已经达到了数千个。因此，我们预计今年人工智能的收入占总收入的比例将只有个位数。但我们真的、真的预计明年的收入将达到每年 7.5 亿美元或更多。

Ullal 表示，Arista 赢得了五份与未具名超大规模提供商和云计算构建商进行试验的合同中的四份，并希望明年将这一比例提高到五份。

与此同时，Arista 发现大型企业和二级服务提供商正在采取行动升级其网络。那些拥有 100 Gb/秒以太网设备的人现在正在考虑 200 Gb/秒、400 Gb/秒甚至 800 Gb/秒的设备。那些使用传统 10 Gb/秒和 40 Gb/秒网络的人正在考虑 100 Gb/秒或 200 Gb/秒。

Arista 的另一个有趣的业务领域是那些将工作负载转移到云端的企业，现在他们“对公共云感到失望”，正如 Ullal 所说，他们希望建立新的基础设施，将这些工作负载转移到自己的数据中心或主机托管设施中...

...戏的真正目标。它希望从我们期望在企业中部署的具有数十个 GPU 的中等集群一直到拥有 100,000 个 GPU 的强大集群，并着眼于 UEC 一年前推出时为自己设定的 100 万个端点设计目标。

以下是 Arista 从网络角度对 AI 前景的看法。首先，它声称其 Etherlink 7060X 交换机可以提供 64 个以 800 Gb/秒运行的端口或 128 个以 400 Gb/秒运行的端口，这些固定端口设备非常适合互连几个计算引擎机架，这些引擎可以是 GPU 或其他类型的引擎，通常统称为 XPU：

最新的 7060X 交换机基于 Broadcom Tomahawk 4 和 Tomahawk 5 ASIC。

现在，对于拥有数百个运行 AI 训练的 XPU 的大型集群，Arista 建议使用单个模块化 7800R4 交换机，该交换机具有 576 个以 800 Gb/秒运行的端口或 1,152 个以 400 Gb/秒运行的端口，并在 XPU 之间提供单跳，不需要在 GPU 端口上进行拥塞控制或自适应路由。（如果您对前端网络使用相同的交换机，则可能需要这样做。）像这样。

显然，上图显示的 XPU 数量不正确。当前的 7800R 交换机基于 Broadcom 的 Jericho 2c+ 和 Jericho 3-AI 交换机芯片。

如果您想要进一步扩展，Arista 于今年 6 月推出了 7700R 分布式 Etherlink 交换机，它采用叶/主干网络并将其折叠成准模块化外形，并允许将其作为具有单跳的单个设备进行管理。（我们强烈怀疑这些“虚拟”单跳在 DES 盒内有几个实际的物理跳，就像它们在模块化交换机内一样。）

如您所见，Etherlink DES 设置具有叶子和主干，并提供了此架构的规模。7700R 基于 Jericho 3-AI 芯片。

Arista 表示，单层 Etherlink 拓扑可以支持超过 10,000 个 XPU，而双层拓扑可以在单个结构中支持超过 100,000 个 XPU。当未来有兼容 UEC 的 DPU 可用时，Arista 表示它将支持这些 DPU，因为它们可以卸载交换机和集群主机节点上的拥塞控制和自适应路由功能，以提高网络性能——就像 Nvidia 已经对 Spectrum-X 所做的那样。7800R4-AI 和 7700R4 DES 交换机自 6 月发布以来一直在进行客户测试，预计将在今年下半年上市。但是，正如 Ullal 所说，预计明年将推出 AI 集群。

如果 Arista 收购 DPU 制造商或从头开始创建自己的 DPU，请不要感到惊讶。

与此同时，Arista 可以与潜在的 AI 客户合作，升级他们的前端网络，为 AI 做好准备，就像思科所做的那样。

参考链接：[https://www.nextplatform.com/2024/08/21/arista-banks-on-the-ai-network-double-whammy/](https://www.nextplatform.com/2024/08/21/arista-banks-on-the-ai-network-double-whammy/)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。