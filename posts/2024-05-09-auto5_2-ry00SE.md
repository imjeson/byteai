---
title: '10年前VAE经典论文获奖，ICLR 2024首个时间检验奖公布'
date: 2024-05-10
author: ByteAILab

---

ICLR 2024 评选出的时间检验奖，在各自领域可谓是开山之作。

由**深度学习**巨头、图灵奖获得者 Yoshua Bengio 和 Yann LeCun 在 2013 年牵头举办的[ICLR 会议](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917136&idx=2&sn=c762406e444e94a90d86c081693877e5&chksm=84e40d6eb39384784a3455a5e73135a2fd8dfbf1bdfb1659357e814c919dd5d0cb24e2675e0f&scene=21#wechat_redirect)，在走过第一个十年后，终于迎来了首届时间检验奖。

---


为了评选出获奖论文，项目主席审查了 2013 年和 2014 年 ICLR 论文，并寻找具有长期影响力的论文。

今年，由 Diederik P. Kingma、Max Welling 合作撰写的论文获得了该奖项，获奖论文为《 Auto-Encoding Variational Bayes 》；论文《 Intriguing properties of neural networks 》获得了亚军。

![图片](https://image.jiqizhixin.com/uploads/editor/8ff6ecfa-ca20-40c7-b8d8-649167cba9ae/640.png)

**ICLR 2024 时间检验奖**

论文《 Auto-Encoding Variational Bayes 》作者共有两位，他们当时均来自于阿姆斯特丹大学。

![图片](https://image.jiqizhixin.com/uploads/editor/2964ef50-3f47-4b6d-8872-74c68fa6811b/640.png)

- 论文地址：https://arxiv.org/pdf/1312.6114
- 论文标题：Auto-Encoding Variational Bayes
- 作者：Diederik P. Kingma 、 Max Welling

**获奖理由：**概率建模是对世界进行推理的最基本方式之一。这篇论文率先将**深度学习**与可扩展概率推理（通过所谓的重新**参数**化技巧摊销均值场变分推理）相结合，从而催生了变分自动编码器 (VAE)。这项工作的持久价值源于其优雅性。用于开发 VAE 的原理加深了我们对**深度学习**和概率建模之间相互作用的理解，并引发了许多后续有趣的概率模型和编码方法的开发。这篇论文对于**深度学习**和**生成模型**领域产生了重大影响。

![图片](https://image.jiqizhixin.com/uploads/editor/09cea89e-d540-4355-b8d1-2df528fa4f63/640.png)

作者介绍

Diederik P. Kingma 现在是谷歌的一名研究科学家。根据领英介绍，Kingma 曾经是 OpenAI 初创团队的一员，在 OpenAI 工作期间领导了一个算法团队，专注于基础研究。2018 年，Kingma 跳槽到谷歌，加入 Google Brain（现在合并为 Google **DeepMind**），专注于生成式模型研究，包括扩散模型和大型**语言模型**。

![图片](https://image.jiqizhixin.com/uploads/editor/203d7430-57ef-4ca6-a657-2cf0af5fb0c2/640.png)

Kingma 主要研究方向是可扩展的**机器学习**方法，重点是**生成模型**。他是**变分自编码器** (VAE，即本次获奖研究)、Adam **优化器**、Glow 和变分扩散模型等研究的主要作者。根据 Google Scholar 显示，Kingma 的论文引用量达到 24 万多次。

![图片](https://image.jiqizhixin.com/uploads/editor/1fcc196d-09c0-46ff-8cf7-7742ada52ed4/640.png)

论文另一位作者 [Max Welling](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650821738&idx=4&sn=ce0ebe31411fa92b3108395006937be9&chksm=84e59014b3921902196d9d66d9cbeecc0183428b8acc710fda9b0f22b5cecd279603f49500c7&scene=21#wechat_redirect) 现在为阿姆斯特丹大学**机器学习**教授。和一般**机器学习**研究者不同，Max Welling 并不是计算机专业科班出身，而是在世界顶尖公立研究型大学 —— 荷兰乌得勒支大学学了 11 年的物理，而且导师是荷兰理论物理学家、1999 年诺贝尔物理学奖得主 Gerard 't Hooft。在 Hooft 的指导下，Max Welling 于 1998 年拿到了量子物理学博士学位。

之后，Max Welling 曾先后在加州理工学院（1998-2000）、伦敦大学学院（2000-2001）和多伦多大学（2001-2003）担任博士后研究员。2003-2013 年，他历任加州大学欧文分校的助理教授、副教授和教授。2012 年，他开始担任阿姆斯特丹大学的教授和**机器学习**研究主席。

Max Welling 在 2011 年参与的一篇论文《 Bayesian Learning via Stochastic Gradient Langevin Dynamics 》还获得了 ICML 2021 时间检验奖，主题是「基于随机梯度 Langevin 动力学的**贝叶斯学习**」。在学术成就方面，Max Welling 的论文被引量达到了 13 万多次。

![图片](https://image.jiqizhixin.com/uploads/editor/26229f3a-c34a-4cb7-abf9-19c0df779122/640.png)

在得知获奖的消息后，Kingma、Max Welling 师徒俩人还进行了互动：

**时间检验奖亚军论文**

ICLR 2024 亚军论文颁给了《 Intriguing properties of neural networks 》。论文作者共有七位，他们当时分别来自谷歌、纽约大学、蒙特利尔大学。

在过去的十年中，他们中的大多数已经离开了原来的公司和机构。

Christian Szegedy 现在为 xAI 联合创始人；Wojciech Zaremba 为 OpenAI 联合创始人；Ilya Sutskever 是 OpenAI 联合创始人（不过自从 OpenAI 发生宫斗后，暂无消息 ）；Joan Bruna 现在为纽约大学副教授（Associate Professor）；Dumitru Erhan 为谷歌 **DeepMind** 研究总监；**Ian Goodfellow** 加入谷歌 **DeepMind**；Rob Fergus 现在为谷歌 **DeepMind** 的研究科学家。

![图片](https://image.jiqizhixin.com/uploads/editor/8a6502cd-82c1-4df9-8e52-d81decb41bde/640.png)

- 论文地址：https://arxiv.org/pdf/1312.6199
- 论文标题：Intriguing properties of neural networks
- 作者：Christian Szegedy、Wojciech Zaremba、Ilya Sutskever、Joan Bruna、Dumitru Erhan、**Ian Goodfellow** 、 Rob Fergus

**获奖理由：**随着**深度**神经网络在实际应用中越来越受欢迎，了解**神经网络**何时以及如何出现不良行为非常重要。本文强调了**神经网络**可能容易受到输入中几乎察觉不到的微小变化的影响。这一想法催生了对抗性攻击（试图欺骗**神经网络**）以及对抗性防御（训练**神经网络**不被欺骗）的研究。

https://blog.iclr.cc/2024/05/07/iclr-2024-test-of-time-award/

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。