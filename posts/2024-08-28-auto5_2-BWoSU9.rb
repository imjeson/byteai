```
---

title: '孟瑜获杰出博士论文奖，中科大获最佳学生论文，KDD 2024全部奖项放出'
date: 2024-08-29
author: ByteAILab

---

ACM SIGKDD（国际数据挖掘与知识发现大会，KDD） 会议始于 1989 年，是数据挖掘领域历史最悠久、规模最大的国际顶级学术会议，也是首个引入大数据、数据科学、预测分析、众包等概念的会议。

今年的 KDD 大会是第 30 届，8 月 25 日 - 29 日在西班牙巴塞罗那召开，最佳论文奖、时间检验奖、杰出博士论文奖等奖项也逐一揭晓。

---


其中有多位华人研究者获奖，孟瑜的《Efficient and Effective Learning of Text Representations》获得了 KDD 2024 杰出博士论文奖，最佳论文奖（研究方向）颁给了六位华人学者参与的《CAT: Interpretable Concept-based Taylor Additive Models》，最佳学生论文（研究方向）颁给了中国科学技术大学、华为合作的《Dataset Regeneration for Sequential Recommendation》。KDD 2024 最佳论文奖（应用数据科学方向）由领英获得，此外，大会还颁发了两项时间检验奖。

## 杰出博士论文奖

KDD 2024 杰出博士论文奖颁发给了《Efficient and Effective Learning of Text Representations》，作者是弗吉尼亚大学助理教授孟瑜（Yu Meng）。

孟瑜于 2024 年加入弗吉尼亚大学 (UVA) 计算机科学 (CS) 系，担任助理教授（tenure-track）。此前，他获得了伊利诺伊大学厄巴纳 - 香槟分校 (UIUC) 的博士学位，与韩家炜教授一起工作。他还曾在普林斯顿 NLP 小组担任访问研究员，与陈丹琦一起工作。

论文摘要：文本表示学习在广泛的自然语言处理 (NLP) 任务中发挥了关键作用。这些表示通常是通过深度神经网络将原始文本转换为向量获得的。LLM 的最新进展已经证明了学习通用文本表示的巨大潜力，可适用于广泛的应用。这一成功由两个关键因素支撑：

- 在预训练和微调中使用广泛的文本数据来训练 LLM；
- LLM 的规模可扩展到包含数百亿甚至数千亿个参数。

因此，训练 LLM 需要大量成本，包括获取大量带标签的数据以及支持这些大型模型所需的基础设施。在这些挑战的基础上，本文旨在开发高效且有效的文本表示学习方法，涉及以下关键内容：

- 利用球面空间进行文本表示学习。表示空间的传统选择是欧几里得空间，但非欧几里得球面空间在通过方向相似性捕捉语义相关性的研究方面表现出卓越的能力。本文的工作重点是利用球面表示空间进行文本表示学习的自监督技术。
- 使用球面文本表示法发现主题结构。基于在球面空间中学习到的文本表示法，本文开发了通过联合建模主题和文本语义自动从给定语料库中发现主题结构的方法。
- 使用 LLM 生成训练数据以实现自然语言理解 (NLU)。要在 NLU 任务上实现稳健的性能，通常需要大量人工标注的训练样本来微调预训练的文本表示。为了减轻人工标注的需求，本文开发了一种新范式，使用 LLM 作为训练数据生成器来取代人工标注过程。

...

更多信息，可参考大会官网：

[https://kdd2024.kdd.org/awards/](https://kdd2024.kdd.org/awards/)

---
```
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。