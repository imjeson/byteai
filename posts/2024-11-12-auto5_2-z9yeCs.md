---
title: '连OpenAI都推不动Scaling Law了？MIT把「测试时训练」系统研究了一遍，发现还有路'
date: 2024-11-13
author: ByteAILab

---

昨天，The Information 的一篇文章让 AI 社区炸了锅。

这篇文章透露，OpenAI 下一代旗舰模型的质量提升幅度不及前两款旗舰模型之间的质量提升，因为高质量文本和其他数据的供应量正在减少，原本的 Scaling Law（用更多的数据训练更大的模型）可能无以为继。

---
此外，OpenAI 研究者 Noam Brown 指出，更先进的模型可能在经济上也不具有可行性，因为花费数千亿甚至数万亿美元训练出的模型会很难盈利。

这篇文章引发了业界对于未来 AI 迭代方向的讨论 —— 虽然 Scaling Law 放缓这一说法令人担忧，但其中也不乏乐观的声音。有人认为，虽然从预训练来看，Scaling Law 可能会放缓；但有关推理的 Scaling Law 还未被充分挖掘，OpenA...

其实，除了测试时计算，还有另外一个近来非常受关注的概念 —— 测试时训练（ Test-Time Training ，TTT），二者都试图在测试（推理）阶段通过不同的手段来提升模型的性能，但 TTT 会根据测试时输入，通过显式的梯度步骤更新模型。这种方法不同于标准的微调，因为它是在一个数据量极低的环境中运行的 —— 通常是通过单个输入的无监督目标，或应用于一个或两个 in-context 标注示例的有监督目标。

不过，TTT 方法的设计空间很大。目前，对于哪些设计选择对 LM（特别是对新任务学习）最有效，人们的了解还很有限。

在一篇新论文中，来自 MIT 的研究者系统地研究了各种 TTT 设计选择的影响，以及它与预训练和采样方案之间的相互作用。看起来，TTT 的效果非常好，至少从论文标题上看，它的抽象推理能力惊人（surprising）。

具体来说，作者确定了将 TTT 有效应用于 few-shot 学习的几个关键要素：

- 在与测试时类似的合成任务上进行初始微调；
- 用于构建测试时数据集的增强型 leave-1-out 任务生成策略；
- 训练适用于每个实例的适应器；
- 可逆变换下的自我一致性（self-consistency）方法。

实验环节，研究者在抽象与推理语料库（ARC）中对这些方法进行了评估。ARC 语料库收集了很多极具挑战性的 few-shot 视觉推理问题，被认为是测试 LM 泛化极限的理想基准。目前的大多语言模型在 ARC 上均表现不佳。

通过对这些部分...

更多研究细节，可参考原论文。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。