---
title: '中山大学联合字节智创数字人团队提出MMTryon虚拟试穿框架，效果优于现有SOTA'
date: 2024-07-09
author: ByteAILab
---

虚拟换装技术在特效以及电商的场景下有着广泛的应用，具有较高的商业潜质与价值。近期，中山大学联合字节跳动智能创作数字人团队提出了一种多模态多参考虚拟试穿 (VITON) 框架 MMTryon，可以通过输入多个服装图像及指定穿法的文本指令来生成高质量的组合试穿结果。

---
对于单图换装，MMTryon有效的利用了大量的数据设计了一个表征能力强大的服装编码器, 使得该方案能处理复杂的换装场景及任意服装款式；对于组合换装，MMTryon消除了传统虚拟换装算法中对服装精细分割的依赖，可依靠一条文本指令从多张服装参考图像中选择需要试穿的服装及对应的穿法，生成真实自然的组合换装效果。

Pretrain 服装编码器结合多模态和多参考注意机制，效果更精确灵活

虚拟换装技术旨在将模特所穿服饰或者衣服的平铺图穿到目标人物身上，达到换装的效果，但是之前虚拟试穿的方案存在一些技术难点没有解决，首先，现有的方法通常是为单件试穿任务（例如上衣/下衣、连衣裙）而设计的，并且无法自定义着装风格（例如，外套拉上/拉开拉链、上衣塞入/塞出等。另外，之前的方案严重依赖特定于类别的分割模型来识别试穿区域，如下图所示如果分割错误则将直接导致试穿结果中出现明显的试穿错误或者伪影等情况。

为了解决这些问题，我们提出了MMTryon，将参考图像中的服装信息与文本指令中的着装风格信息通过一种新颖的多模态和多参考注意机制来进行表示，这使得我们的方案支持组合式换装以及多样的试穿风格。此外，为了消除对分割依赖性，MMTryon 使用了表征能力丰富的服装编码器，并利用新颖的可扩展的数据生成流程增强现有的数据集，这样在推理阶段，MMtryon无需任何分割，仅仅通过文本以及多个试穿对象即可实现高质量虚拟换装。

在开源的数据集以及复杂场景下进行的大量实验在定性和定量上证明了 MMTryon 优于现有 SOTA 方法。

详细技术方案见：[链接](https://arxiv.org/abs/2405.00448)

首先研究团队预训练了一个服装编码器，在这一stage中MMTryon利用文本作为query，将得到的特征与grouding dino + SAM所得到的mask计算一个query损失，目标是经过text query 后仅激活文本对应区域的特征，这样可以摆脱对于服装分割的依赖，同时利用大量的pair对更好的编码服装特征，之后，为了更稳定的训练组合换装，需要多件服装组合式换装的pair图，但是这样的pair图采集成本很高。为此，研究团队提出了一个基于大模型的数据扩增模式，利用视觉语言模型以及grouding dino + SAM去得到了不同区域的mask，来保护对应的上衣或者下衣区域，利用stable diffusion XL 去重绘保护区域外剩下的内容，构建了100w的增强数据集，训练中将我们的增强数据集与90w原始数据一起加入训练。基于增强的数据集以及服装编码器， MMTryon设计了多参考图像注意力模块和多模态图文注意力模块，其中多参考图图像注...

应用落地和展望

MMTryon是一个新颖而强大的虚拟试穿框架，能够根据文本和多件服装参考图自由生成具有逼真试穿效果的高保真虚拟换装结果。 为了解决组合换装数据获取成本高的问题，研究团队设计了预训练的服装编码器以及增强的数据构建链路，为了消除对高精度分割网络的依赖，MMTryon 设计了text query loss 使得推理无需依赖服装分割模型，可以利用文本锁定用户指定的服装区域。 为了支持组合式换装以及多样的试穿风格，MMTryon 引入了多模态指令注意力和多参考注意力模块，在开源的vton测试集和in the wild复杂场景测试集下进行的实验证明了 MMTryon 与现有方法相比具有更加优越的合成效果。

团队介绍

智能创作团队是字节跳动AI&多媒体技术团队，通过建设领先的计算机视觉、音视频编辑、特效处理等技术，支持抖音、剪映、头条等公司内众多产品线；同时为外部ToB合作伙伴提供业界前沿的智能创作能力与行业解决方案。其中，智能生成方向专注于建设行业领先的智能生成技术，丰富智能创作内容生态。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。