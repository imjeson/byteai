title: 'CoreWeave推出NVIDIA GB200 Grace Blackwell系统大规模应用'
date: 2025-04-19
author: ByteAILab

---

初始客户包括IBM、Mistral AI和Cohere  
CoreWeave，AI超级云计算商™，今天宣布Cohere、IBM和Mistral AI是首批获得NVIDIA GB200 NVL72机架级系统和CoreWeave全栈云服务的客户——这项组合旨在推动AI模型的开发和部署。![图片](https://ai-techpark.com/wp-content/uploads/CoreWeave-2.jpg){ width=60% }

---
  
各企业和组织的AI创新者现在可以访问专门为推理和代理型AI构建的先进网络和NVIDIA Grace Blackwell超级芯片，突显了CoreWeave在向市场推出先进AI云解决方案方面一贯的领先地位。  
“CoreWeave旨在快速前进——我们一次又一次地证明了这一点，成为首个大规模运营最先进系统的公司，”CoreWeave的联合创始人兼首席执行官Michael Intrator说。“今天是我们工程实力和速度的证明，也是我们对推动下一代AI不断追求的体现。我们很高兴看到前瞻性的公司在我们的平台上已经实现了新的突破。通过提供最先进的计算资源，CoreWeave使企业和AI实验室能够更快速地创新并部署曾经难以实现的AI解决方案。”  
“NVIDIA的高性能计算与超大规模副总裁Ian Buck表示：“全球的企业和组织都在争相将推理模型转变为将改变人们工作和娱乐方式的代理型AI应用。CoreWeave快速部署NVIDIA GB200系统提供了实现AI工厂所需的基础设施和软件。”  
CoreWeave提供先进的AI云解决方案，同时最大化效率并打破性能记录。该公司最近在最新发布的MLPerf v5.0结果中，使用NVIDIA GB200 Grace Blackwell超级芯片创下了新的AI推理行业纪录。MLPerf推理是一个行业标准套件，用于在现实部署场景中测量机器学习性能。  
去年，该公司是首批提供NVIDIA H100和NVIDIA H200 GPU的公司之一，并且是首批展示NVIDIA GB200 NVL72系统的公司之一。  
CoreWeave的云服务组合经过优化，适用于NVIDIA GB200 NVL72，为客户提供性能和可靠性，并包括CoreWeave Kubernetes服务、基于Kubernetes的Slurm（SUNK）、CoreWeave Mission Control等。CoreWeave的NVIDIA Blackwell加速实例能够扩展至多达110,000个Blackwell GPU，配合NVIDIA Quantum-2 InfiniBand网络。  
除了IBM、Mistral AI和Cohere之外，CoreWeave最近还与ChatGPT的创造者OpenAI签订了多年合约。  

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。