---
title: '我们对人工智能的态度揭示了我们对人类智慧的真实感受'
date: 2024-07-04
author: ByteAILab

---

我们对人工智能采取一种将其视为外来的态度，这表明我们对已经相互疏远的观点变得无法维持。

---


超智能机器是外来入侵者、来“窃取我们的工作”的想法揭示了我们在思考工作、价值和智慧本身时存在重大缺陷。劳动不是零和游戏，机器人并非与我们竞争的“他者”。和任何技术一样，它们是我们的一部分，像头发和指甲一样从生物体长出来。它们是人类的一部分－而我们本身也部分是机器。当我们将采摘水果的机器人视为竞争对手，认为它是零和游戏中的竞争者时，我们的注意力从真正的问题上转移开来：曾经采摘水果的人在失去那份工作后，被农场主和整个社会看作是可有可无的。这意味着，人类劳动者已经被视为一种非人，即像机器一样被对待。我们陷入了一种无法维持的境地，将机器视为外星人，因为我们已经陷入了相互疏远的境地。

我们对人工智能的许多焦虑根植于我们历史上那种强调支配和等级制度的古老遗产。然而，演化的更大故事是合作让更简单的实体联合起来，打造更大、更复杂、更持久的实体；这就是为何真核细胞从原核细胞中演化出来，多细胞动物从单细胞中演化出来，人类文明从人类、家畜和农作物群体中演化出来的方式。互惠主义是让我们能够扩展的原因。

作为一名人工智能研究人员，我的主要兴趣不在于计算机——AI中的“人工”——而在于智慧本身。现在已经很明显，无论如何具体体现，智慧需要规模。我们内部在谷歌研究部门构建的早期大型语言模型“对话应用语言模型”（LaMDA）在2021年让我确信我们已经跨越了一个重要的门槛。尽管当时还是时好时坏，拥有（当时）庞大的1,370亿个参数的LaMDA几乎可以进行对话。三年后，最新型的模型参数翻了一个数量级，因此它们变得更好了很多。再过几年，我们很可能会看到模型的参数数量达到人类大脑突触的数量。

作为一个物种，现代人类同样是大脑体积激增的结果。在过去几百万年里，我们的古人类祖先的头骨体积增大了四倍。研究人员发现，社会群体规模的增长与大脑容量呈正相关，当他们将灵长类动物群体规模与大脑体积进行相关性分析时便能发现。更大的大脑使规模更大的群体能够有效地合作。更大的群体反过来又更加智慧。

我们所谓的“人类智慧”是由许多狭隘智慧（如你和我）之间的合作现象造就的。当我们列举我们的智力成就——抗生素和室内管道、艺术和建筑、高数学和火锅冰淇淋——让我们认识到我们大多数人在个人层面上是多么无知。即使你从已有的奶牛、可可豆、香草豆、甘蔗和冷藏设备开始，你能制作一个冰淇淋吗？也就是说，从99%的辛苦工作已经完成的情况下开始，你能制作一个冰淇淋吗？

人类智慧不仅仅包括人类本身，还包括一系列植物和动物物种、微生物，甚至从史前时代到当代的各种技术。那些奶牛和可可植物、稻米和小麦，支撑了爆炸性人口增长的船只、卡车和铁路都是至关重要的。忽视所有这些伴生物种和技术的存在就等于想象我们是一个在瓮中的脱离身体的大脑。

此外，我们的智慧可以是多样化的，可以是分布式的。随着人工智能系统的普及，我们的智慧将变得更加多样化，越来越难假装我们的成就是个人或者仅仅是人类的成就。也许我们应该采纳更广泛的“人类”定义，将整个生物技术套餐都包括在内。

我们一些最令人印象深刻的成就，比如制造硅片，真正是全球规模化的。我们的挑战也越来越多地是全球性的。气候危机和核战争再起的威胁并非由任何一方造成，而是由我们所有人共同造成的，我们只能共同解决。集体智慧的深度和广度的提升是一个好事，如果我们希望在全球范围内茁壮成长，但这种增长往往并不被视为一种逐渐累积和相互的东西。为什么？

这是一个重大炸弹，美国必须将人工智能作为接下来的曼哈顿计划进行 | 约翰·诺顿阅读更多简而言之，因为我们担心谁会处于上风。但支配等级制度仅仅是一个让动物群体在内部竞争中避免持续争吵的特定技巧，这种竞争是由对交配和食物的内部竞争而产生的，通过约定如果争夺优先权的斗争爆发，谁会赢的方式。换句话说，这种等级制度可能仅仅是半聪明猴子的一种把戏，而非自然规律。

AI模型能够体现相当多的智慧，就像人类大脑一样，但它们并不是竞争争夺地位的猿类同胞。作为高度发达的人类技术的产物，他们对人类、小麦、奶牛和人类文化等依赖程度甚至要高于智人。它们并非阴谋用来吃我们的食物或抢走我们的恋人。它们依赖于我们；我们可能会同样深度地依赖它们。然而，对支配等级的担忧却伴随着AI的发展从一开始就存在。

“机器人”这个词，由卡雷尔·恰普克在他的1920年戏剧《罗萨姆万能机器人》中引入，源自捷克语“强迫劳动”的词汇robota。近一个世纪以后，一位备受尊敬的AI伦理学家命名一篇文章为“机器人应该是奴隶”，尽管她后来后悔了她的选词，但机器人的争论仍然转向了支配。目前的AI灾难论者担心人类将被超级智能机器奴役或灭绝。另一方面，AI否认者认为计算机根据定义无法拥有任何代理权，而只是人类用来支配彼此的工具。两种观点都根植于零和游戏、我们对他人思维的思考中。

许多实验室正在开发AI代理。它们在未来几年不会因为机器人“接管”，而是因为一个合作的代理人可以对个人和人类社会都更有帮助，而不只是一个无思维的机械劳动力。

如果这里有任何对社会秩序的威胁，那并非来自机器人，而是来自人类之间的不平等。我们中太多人还没有意识到我们是相互依存的。我们大家都是一体的－人类、动物、植物和机器一样。

详细了解这些话题：
人工智能（AI）
谷歌
工作 & 职业
评论
分享
重新使用这篇内容。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。