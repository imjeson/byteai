---
title: '一夜暴涨1.6万亿！英伟达净利暴增628%，但AI芯片销售放缓讯号已经出现'
date: 2024-05-28
author: ByteAILab

---

AI 大模型对算力的需求持续推高英伟达业绩：疯狂的股价飙涨，疯狂的营收翻倍，疯狂到令人难以置信的利润率。

钛媒体App 5月24日消息，截至今早美股收盘，“AI之王”英伟达（NASDAQ：NVDA）市值一天内暴涨2180亿美元（约合人民币1.56万亿元），达到2.56亿美元市值——超过台积电、阿斯麦、AMD、高通、应用材料、德州仪器、美光科技、英特尔等半导体巨头的市值总和。

---
同时，股价也首次冲破1000美元/股，创下历史新高。

截止收盘，英伟达逆市涨9.32%，报1037.99美元/股。

消息面上，美股5月22日盘后，英伟达发布截至4月28日的2025财年第一财季业绩，当季实现营收260亿美元，同比大增262%，环比增长18%，再创单季营收历史新高；净利润为148.81亿美元，环比增长21%，同比增长628%。

此前连续四个财季，英伟达业绩均大幅跑赢市场预期，当季势头持续。同时，英伟达宣布将拆股，6月7日实施一股拆十股，利好投资人获利，从而引发华尔街“狂欢”，高盛、伯恩斯坦、花旗、摩根士丹利、杰富瑞等多家投行齐调英伟达目标价。

彭博亿万富翁指数最新数据显示，英伟达联合创始人、CEO黄仁勋资产净值已达到913亿美元，在全球富豪榜排名第17位。

然而，英伟达业绩似乎已经达到“天花板”，销售呈现放缓迹象。本季英伟达收入增长跟彭博分析比大概只有高5%左右，远低于此前26%，而且英伟达预计二季度营收280亿美元，同比仅增长5%-10%，上下浮动2%，增速远低于预期。

半导体分析师陆行之认为，本季英伟达财测看不到获利预期，“降温讯号”已经出现，而增长的关键因素是拆股，但预计接下来重点则回到基本面，需要观察B100、B200芯片的销售情况。

中国数据中心收入下滑，英伟达披露其占比已从19%降至约5%

具体来看，英伟达收入来源分为四个板块：数据中心、游戏、专业可视化以及汽车电子业务。

其中，受益于AI服务器市场火热，当季，英伟达数据中心业务实现营收226亿美元，环比增长23%，同比增长427%，这一同比增幅较上财季的409%仍在扩大。该业务在总营收中占比也由上财季的83%提升至87%。

英伟达CFO科莱特·克雷斯（Colette Kress）在财报电话会上称，这主要得益于对Hopper GPU计算平台的持续强劲需求。随着英伟达2022年推出的Hopper架构计算产品陆续交付，当季数据中心计算产品营收为194亿美元，环比增长29%，同比增长478%。网络产品受限于供应，营收环比下降5%，同比增长242%，至32亿美元。

克雷斯强调，与去年相比，计算收入增长了5倍以上，网络收入增长了3倍以上。同时，得益于CUDA算法，英伟达能将H100上的大语言模型推理速度提高多达3倍，换言之能将大模型提供服务的成本降低到原来的1/3。

...

英伟达披露，最新季度226亿美元的数据中心收入中，有大约45%的收入占比都来自云计算大厂。

“在英伟达AI基础设施上每投入1美元，云厂商有机会在四年内获得5美元的托管服务收入。”克雷斯表示，在NVIDIA CUDA上训练和推理AI正推动云租赁收入增长的显著加速，给云供应商的投资带来“即时且丰厚的回报”。

英伟达称，其GPU能为云租赁客户提供“最佳的模型训练时间、最低的模型训练成本、最低的大语言模型推理成本”。

据悉，目前，英伟达H200已投入生产，预计第二季度发货。黄仁勋将第一台H200系统交付给OpenAI团队，并在上周为其出色的旗舰模型GPT-4o演示提供支持。H200推理性能几乎是H100的两倍。

克雷斯表示，英伟达新款硬件的投资回报更高。例如，使用具有700亿个参数的Llama 3，单个英伟达HGX H200服务器每秒可以提供24000个token，同时支持超过2400名用户。

这意味着，以当前的每token价格在HGX H200服务器上每花费1美元，提供Llama 3 token的 API提供商可以在4年内产生7美元的收入。

黄仁勋在财报会议期间反复强调，GPU需求惊人，订单爆棚，而英伟达交付压力过大，有大约有15000~20000家生成式 AI 初创公司在竞争GPU资源。

“客户对我们施加了很大的压力，要求我们尽快交付并启动系统。”黄仁勋说，“我认为需求非常非常高，超过了我们的供应……长远来看，我们正在彻底重新设计计算机的工作方式。”

黄仁勋强调，下一代旗舰芯片Blackwell GPU已经开始量产，而且在Hopper上运行的软件栈将在Blackwell上完美运行。

“今年我们将看到大量的Blackwell收入。”黄仁勋称。

“继Blackwell之后，还有另一款芯片，我们的产品节奏更新到一年一次——以一年为周期，正如我们像世界解释的那样。我们希望客户看到我们的路线图。“新的CPU、新的GPU、新的网络NIC、新的交换机……一大堆芯片即将到来。”黄仁勋兴奋的表示，“最妙的是所有这些都运行CUDA，所有这些都运行我们的整个软件栈。”

今年，英伟达将为Blackwell提供100种不同的计算机系统配置，而Hopper的配置数量只有一半。

天风国际证券分析师郭明錤指出，英伟达下一代R系列/R100 AI芯片将于2025年第四季度量产，采用台积电3nm制程、4个reticle设计，搭配8颗HBM4，重点改善能耗。最早在明年，R100 AI GPU就将登场。

谈到主权AI（Sovereign AI），克雷斯表示，AI的重要性引起了每个国家的关注，英伟达相信主权AI的收入将从去年的0发展到今年的数十亿美元。

然而，根据华尔街日报、陆行之等机构分析，目前英伟达还有三大重要挑战：库存高涨、芯片制造压力众多、不断变化的 AI 推理市场。

首先，陆行之认为，本季英伟达营收增长很不错，但是库存居然还是增加，这意味着，之前A100大缺货的状况已经有大幅改善，也很明显说明英伟达GPU芯片销售处于降温。同时，英伟达毛利率出现下滑，可能由于市场竞争低价产品比重增加，或是之前高毛利率中小型客户都拿到货了。因此，下面需要观察H100、B100、B200的销售状况，以评估接下来英伟达的长期业绩。

其次，在芯片制造端，英伟达还面临谷歌、微软、AMD、英特尔、博通等其他竞争对手抢订单，造成英伟达芯片制造时间低于预期。华尔街日报称，谷歌多年来一直与博通合作生产自己的 AI 芯片；亚马逊则于11月宣布推出新的 AI 芯片，同月微软表示也将开始生产定制 AI 芯片，而这些芯片背后的制造方基本是台积电、日月光等制造端厂商。

最后，英伟达还必须适应不断变化的 AI 市场，才能保持领先地位。

在 AI 热潮的第一年，企业投资的重点大部分都放在构建或训练生成式 AI 模型上，这需要巨大的计算能力，而英伟达的A100/H100芯片非常适合这种能力。但如今，更多小型 AI 公司也在不断寻找构建和部署小型模型的方法，这些模型可以有效完成特定任务，但不需要依赖英伟达芯片提供那么多的计算能力，简单一个 AI 推理芯片也可以做到。

中国科学院院士、“图灵奖”获得者、上海期智研究院院长姚期智日前表示，比起已知的重要赛道，更重要的是“如何能够发现新的赛道”，譬如像 AI 推理，这是一个当今大模型非常欠缺的部分，大家也都可以看到这会是将来的下一个里程碑，是大家竞争的高地。

红杉资本在 3 月份估计，该行业向英伟达的芯片投入了 500 亿美元来训练大型语言模型，但生成式 AI 初创公司的收入仅为 30 亿美元。

但黄仁勋曾提到，英伟达在 AI 推理方面作用也很大，而且最重要的是能够降低TCO（总拥有成本）。

“我们应该能够扩展英伟达架构，以适应这个新的计算时代，并开启这场新的工业革命，我们不仅制造软件，而且制造AI tokens，我们将大规模地这样做。”黄仁勋表示。

伯恩斯坦研究公司 (Bernstein Research) 的分析师斯泰西·拉斯冈 (Stacy Rasgon)认为，黄仁勋塑造计算未来的宏伟抱负，应该有助于英伟达击败那些试图蚕食其 AI 主导地位的竞争对手。他们需要确保“护城河”持续带来竞争优势。

黄仁勋强调，未来，AI 将为几乎所有行业带来显著的生产力提升，帮企业提高成本和能效，扩大收入机会。

“下一场工业革命已经开始。各大公司和国家正与英伟达合作，将价值数万亿美元的传统数据中心转向加速计算，并建立AI工厂，以生产一种新商品——AI。”黄仁勋称。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。