---
title: '太酷了！iPhone、iPad、MacBook老旧设备组成异构集群，能跑Llama 3'
date: 2024-07-17
author: ByteAILab
---

假如你有闲置的设备，或许可以试一试。

这次，你手里的硬件设备也能在 AI 领域大展拳脚了。

---


将 iPhone、iPad、Macbook 进行组合，就能组装成「异构集群推理方案」， 然后顺畅的运行 Llama3 模型。

![异构集群正在运行中。](https://image.jiqizhixin.com/uploads/editor/7b96807a-4318-4497-9f26-b87a17207537/640.gif)

值得一提的是，这个异构集群可以是 Windows 系统，也可以是Linux、iOS 系统，并且对 Android 的支持很快到来。

根据项目作者 @evilsocket 的介绍，这个异构集群包括 iPhone 15 Pro Max、iPad Pro、MacBook Pro (M1 Max)、NVIDIA GeForce 3080、2x NVIDIA Titan X Pascal。所有代码都已经上传到 GitHub。

看到这，网友纷纷表示，这位老哥确实不简单。

不过也有网友开始担心能耗问题，暂且不管速度，电费都耗不起。来回搬数据，损耗太大了。

### 项目介绍

上述功能的实现，离不开一个名为 Cake 的 Rust 框架。Cake 可以完成大模型（例如 Llama3）的分布式推理，旨在将消费级硬件组合成异构集群，其中消费级硬件采用多种操作系统，包括：iOS、Android、macOS、Linux 和 Windows，从而使 AI 更易于访问。

![Cake框架](https://image.jiqizhixin.com/uploads/editor/fa4dfa0f-54b8-41f9-aa58-b2dd5f67c356/640.png)

项目地址：https://github.com/evilsocket/cake

Cake 的主要思路是将 transformer 块分片到多个设备，以便能够让通常不适合单个设备 GPU 内存的模型运行推理。对同一工作线程上的连续 transformer 块的推理是分批进行的，以便最大限度地减少数据传输造成的延迟。

Cake 目前支持的系统和设备如下：

![系统和设备支持](https://image.jiqizhixin.com/uploads/editor/e9708056-f87e-421d-8f85-8dda03565d06/640.png)

### 编译

安装 Rust 后，运行下列代码：

```nginx
cargo build --release
```

假如用户想要在应用程序中生成 iOS 绑定，可以进行下述操作：

```nginx
make ios
```

### 使用

运行 worker 节点：

```bash
cake-cli --model /path/to/Meta-Llama-3-8B \ # model path, read below on how to optimize model size for workers
         --mode worker \                    # run as worker
         --name worker0 \                   # worker name in topology file
         --topology topology.yml \          # topology
         --address 0.0.0.0:10128            # bind address
```

运行 master 节点：

```sql
cake-cli --model /path/to/Meta-Llama-3-8B \
         --topology topology.yml
```

其中 topology.yml 确定哪些层由哪个 worker 提供服务：

```properties
linux_server_1:
  host: 'linux_server.host:10128'
description: 'NVIDIA Titan X Pascal (12GB)'
layers:
    - 'model.layers.0-5'
linux_server_2:
  host: 'linux_server2.host:10128'
description: 'NVIDIA GeForce 3080 (10GB)'
layers:
    - 'model.layers.6-16'
iphone:
  host: 'iphone.host:10128'
description: 'iPhone 15 Pro Max'
layers:
    - 'model.layers.17'
ipad:
  host: 'ipad.host:10128'
description: 'iPad'
layers:
    - 'model.layers.18-19'
macbook:
  host: 'macbook.host:10128'
description: 'M1 Max'
layers:
    - 'model.layers.20-31'
```

关于内存和磁盘空间优化问题，用户可能希望只向 worker 提供模型中实际需要的数据，而不是整个文件夹，在这种情况下，可以使用 cake-split-model 。例如，要生成较小版本的 llama3 safetensors，可以采用如下代码：

```perl
cake-split-model --model-path path/to/Meta-Llama-3-8B \ # source model to split
                 --topology path/to/topology.yml \      # topology file
                 --output output-folder-name
```

*参考链接：https://x.com/tuturetom/status/1812654489972973643*
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。