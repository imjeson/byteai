---
title: 'Inworld Runtime：首个面向消费者应用的AI运行时'
date: 2025-08-16
author: ByteAILab
---

今天，Inworld AI发布了Inworld Runtime——首个专为扩展消费者应用而设计的AI运行时。![图片](https://ai-techpark.com/wp-content/uploads/Inworld-Runtime.jpg){ width=60% }

---
它让开发者能够更快地从原型走向生产，并以最小的代码更改支持用户从10人增长到1000万用户。通过自动化AI操作，Inworld Runtime释放了工程资源用于新产品开发，并提供了设计和部署无代码实验的工具。Inworld目前的合作伙伴，包括主要媒体公司、AAA游戏工作室和AI原生初创企业，已经将Runtime作为其下一个世代实时、多百万用户AI特性和体验的AI堆栈基础。

为了加速与这些客户的合作，Inworld构建了Runtime，作为内部基础设施，处理消费者AI的独特需求：在数百万用户并发的规模下保持实时性能、专注于参与度的用户特定质量期望，以及每天每用户成本低于一美分。随着来自健康/健身、学习和社交应用公司的不断询问，Inworld的团队意识到这些公司面临的挑战与Runtime内部解决的挑战完全一致，因此决定将其公开发布。

“Inworld在构建Runtime的过程中是出于自身的需要。现有工具无法满足我们合作伙伴所需的速度与规模。”Inworld AI的CEO Kylan Gibbs表示。“当我们意识到每个消费者AI公司都面临这些相同的障碍时，我们知道必须向外界开放我们所构建的。在我们观察到行业达到拐点时，成千上万的开发者开始遭遇我们曾经经历的同样的扩展墙，因此我们在过去一年里快速增加了超出我们内部需求的功能，创造了一个加速整个消费者AI生态系统的通用后端。”

### 消费者AI领导者确定的三个因素

在部署消费者AI应用的四年中，Inworld发现了三个决定成功或失败的关键因素。对这三者的卓越表现是必要的，任何一项的弱点都会阻碍消费者AI特性或应用达成市场领导地位：

1. 从原型到生产的时间
   尽管创建一个AI演示只需数小时，但实现生产就绪通常需要超过6个月的基础设施和质量改进工作。团队必须处理提供者的故障、实施后备方案、管理速率限制、配置和加速计算能力、优化成本，并确保一致的质量。在与行业领导者合作的过程中，Inworld观察到大多数消费者AI项目要么成功跨越，要么停滞不前，在原型和可扩展现实之间的鸿沟中死掉。

2. 新产品开发的资源分配
   发布后，大多数工程团队花费超过60%的时间在维护任务上：调试提供者变化、管理模型更新、处理规模问题及优化成本。这给新特性的构建留下了很少的资源，导致产品停滞不前，而竞争者则在不断推进。Inworld对此深有体会，即使是创新性的团队也会陷入维护周期，而无法构建用户下一个想要的功能。

3. 实验速度
   消费者偏好不断变化，但传统的部署周期为2-4周无法与此速度匹配。团队需要测试大量变体、衡量实际用户影响，并在没有代码部署和应用商店审批阻力的情况下扩展赢家。通过与行业合作伙伴的协作，Inworld发现，学习最快的机构即为胜利者，但现有基础设施几乎让快速迭代变得不可能。

“我们在19天内从原型扩展到100万用户，同时成本降低超过95%。” - Fai，Status的CEO

### Inworld Runtime的技术设计

Inworld Runtime通过多个创新交付这些能力，包括：

1. 自适应图
   基于C++的图执行系统，解决了大多数AI框架在跨平台扩展方面的限制，提供Node.js、Python等的SDK。开发者使用预优化的节点作为构建块来组合应用，这些节点具有来自顶级提供者的LLM、TTS、STT、知识、内存等API，处理低级集成工作并自动优化组件之间的数据流。相同的图形可以毫不费力地从10个测试用户扩展到1000万并发用户，且几乎不需更改代码或管理终端。配合亲和编码友好的接口，这使得从原型到生产的跃升在数天内而非数月内实现。

2. 自动化MLOps
   除了基本操作外，Runtime提供集成的遥测，使基础设施自动化，捕获每个交互的日志、追踪和指标。可操作的洞察，比如识别错误、用户模式和优化机会，通过Inworld的可观察性和实验管理平台Portal呈现。Runtime在提供者之间执行自动故障转移，管理跨模型的容量，并智能处理速率限制。它还支持定制的本地部署，并为企业提供优化的模型托管。随着应用程序的扩展，Inworld提供了访问必要的云基础设施，以训练、调整和托管自定义模型，突破默认模型在成本和质量上的瓶颈。

3. 实时实验
   一键部署或扩展实验。配置与代码分离，使得可以即时进行A/B测试，而没有部署摩擦。Runtime可以通过SDK定义变体，并通过Portal管理测试，同时自动运行数百个实验，测试不同的模型、提示、图配置和逻辑流程。更改可以在几秒钟内部署，并自动测量对用户指标的影响。

### Inworld Runtime早期用户的验证结果

Runtime的部署展现了持续的技术成就：

- Inworld最大的合作伙伴（主要IP所有者、媒体公司和AAA工作室）已经将Runtime作为其AI堆栈的基础。
- Wishroll在19天内从原型扩展至100万用户，成本降低超过95%。
- Little Umbrella能够在使用Inworld减少现有标题的更新和维护工作量的同时推出新的AI游戏。
- Streamlabs构建了一个多模态实时流媒体助手，其特性在六个月前甚至都不可行。
- Bible Chat升级并扩展了其语音功能，同时将语音成本降低了85%。
- Nanobit向数百万用户提供个性化的AI叙事，并实现了可持续的单位经济。

### 可用性与定价

开发者可以立即通过下载Runtime SDK开始，网址为inworld.ai/runtime，提供全面的文档和迁移指南。Runtime本地与Cursor、Claude Code、Google CLI、Windsurf和Zencoder等代码助手兼容。开发者可以从自己的项目开始，或使用Inworld的模板和演示应用作为灵感。在客户端应用中、任何云提供商的服务器上或通过Inworld托管模型的自定义本地安装，Runtime都能灵活部署。一旦进入生产，Portal可用于观察和快速实验。

Runtime的定价完全基于使用，无需前期费用。开发者可以测试所有模型和功能，只需为成功扩展的部分付费，确保与消费者应用经济学一致，而成本必须在用户增长的同时保持可持续。通过获取来自Anthropic、Google、Mistral和OpenAI的尖端模型，开发者获得最大选择，以便轻松测试并选择适合其用例的最佳模型。Runtime还通过闪电般快速的提供者Groq、Tenstorrent和Fireworks AI提供访问顶级开源模型，如Deepseek、Llama和Qwen。与现有的Microsoft或Google关系的开发者可以通过Azure Marketplace和Google Cloud Marketplace利用其云承诺访问Runtime。

---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。