---
title: 'AI安全与治理调查：Immuta'
date: 2024-05-01
author: ByteAILab

---

80%的数据专家认为，人工智能使数据安全变得更具挑战性，增加了敏感信息曝光风险和人工智能攻击的可能性。![图片](https://ai-techpark.com/wp-content/uploads/2024/04/AI-Security-960x540.jpg){ width=60% }

---

数据安全领军者Immuta今天宣布了《AI安全与治理报告》，该报告对近700名工程领导、数据安全专业人员和治理专家就他们对AI安全与治理的展望进行了调查。报告提供了组织如何采用人工智能、如何应对新兴安全和隐私挑战，以及如何更新治理指南以安全地利用这项技术的洞察。
调查结果显示，人工智能的采用仍然非常普遍，超过一半的数据专家（54%）表示其组织已经利用了至少四个人工智能系统或应用程序。还有超过四分之三（79%）的人报告他们在过去12个月增加了用于人工智能系统、应用程序和开发的预算。
然而，这种快速的采用也带来了巨大的不确定性。例如，80%的数据专家认为，人工智能正在使数据安全变得更具挑战性。专家们对通过LLMs无意中暴露敏感数据以及通过人工智能模型进行敌意攻击的风险表示担忧。事实上，57%的受访者在过去一年内看到了人工智能攻击的显著增加。
虽然快速的人工智能采用肯定带来了新的安全挑战，但对其潜力的乐观态度正在推动组织进行调整。例如，数据领导者相信，人工智能将增强当前的安全实践，如人工智能驱动的威胁检测系统（40%）和使用人工智能作为高级加密方法（28%）。随着这些好处在安全风险面前变得明显，许多组织（83%）正在更新内部隐私和治理指南，并采取措施应对新的风险：
78%的数据领导者表示，其组织已经对人工智能安全进行了特定风险评估。72%正在通过监控人工智能预测的异常来推动透明度。61%已经建立了基于目的的访问控制措施，以防止未经授权的人工智能模型使用。37%表示他们已经制定了全面的策略，以确保符合最近和即将实施的人工智能法规和数据安全需求。
Immuta的产品管理副总裁Matt DiAntonio说：“当前的标准、法规和控制并没有足够快地适应人工智能的快速发展，但未来令人乐观。”。“该报告清楚地概述了许多人工智能安全挑战，以及组织如何寻求人工智能来帮助解决这些挑战。人工智能和机器学习能够自动化流程，快速分析大量数据集以改善威胁检测并实现高级加密方法以保护数据。随着组织在其人工智能之旅上的成熟，防止敏感数据无意间或恶意地暴露给人工智能模型，确立围绕生成性人工智能数据管道和输出的严密的安全和治理战略至关重要。”
尽管许多数据领导者表示人工智能使安全变得更具挑战性，但85%的人表示他们对其组织的数据安全策略能够跟上人工智能发展的步伐有所信心。与仅仅去年的研究发现50%的人强烈或有些认同其组织的数据安全策略无法跟上人工智能发展步伐形成对比，这表明存在成熟曲线，许多组织正推动人工智能倡议，尽管存在风险，因为预期的回报是值得的。
人工智能的快速变化无疑令人振奋，但也充满未知。特别是由于法规不断变化，许多模型缺乏透明度。数据领导者应该将他们的乐观态度与现实相结合，即人工智能将继续改变，合规的标准也将随之变化。无论人工智能的未来是什么，有一点是显而易见的：没有数据安全策略的负责任的人工智能战略。公司需要建立支持数据安全策略的治理，这种治理不是静态的，而是随着创新为业务带来结果而动态调整。

Immuta委托独立市场调研机构UserEvidence进行2024年AI安全与治理调查。要阅读完整报告，请访问：

如果您正在寻找一种方式来跟上当前和即将到来的人工智能领域，并降低您的数据风险，请花29分钟与Immuta共度。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。