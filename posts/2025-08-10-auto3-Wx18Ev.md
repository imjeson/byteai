---

title: '首款无限上下文大型语言模型颠覆12亿美元RAG市场'
date: 2025-08-11
author: ByteAILab

---

硅谷初创公司iFrame™ AI悄然与一家领先的云服务提供商达成了近2000万美元的交易，推出全球首款具有无限上下文窗口的大型注意力模型——这一突破有望颠覆专业服务行业，并削弱OpenAI等公司的基于高成本、冗余数据检索服务的收入。![图片](https://ai-techpark.com/wp-content/uploads/First.jpg){ width=60% }

---
 

与去年震撼AI生态系统的DeepSeek类似，iFrame的Asperanto和Sefirot-10模型消除了检索管道和微调的需要，兑现了前谷歌首席执行官埃里克·施密特有关无限上下文模型即将来临的预测，旨在重塑我们对自主AI应用的理解。

近十年来，人工智能行业一直被困在变换器的注意力矩阵中——这一引擎驱动着OpenAI、谷歌和Anthropic的每一个主要AI，使得即便是最先进的模型也陷入了数字遗忘状态。

经过三年的隐秘研发，iFrame™推出全球首款大型注意力模型（LAM），这种架构不仅拉伸了上下文窗口，更使得这一概念本身变得过时。通过完全移除注意力矩阵，iFrame™创造了一个能够在一次传递中本地推理数TB数据的模型：无RAG，无微调，无花招。与其训练一个数十亿美元的大型语言模型进行提炼和微调，以便进行可用推理，不如直接将数TB数据上传至注意力块，数秒内即可升级AI知识。

“无论好坏，我帮助AI逃脱了矩阵——字面上而言，”iFrame创始人、单子结构框架的创造者弗拉德·帕宁在近期采访中表示。这个突破并非来自对现有AI研究的迭代，而是源于对宇宙拓扑数学的深入研究，灵感来自于著名的隐匿者格里戈里·佩雷尔曼，他在2002年解决了庞加莱猜想。

“每个人都在尝试从接受的叙事中优化矩阵，”帕宁解释说。“我则大胆地寻求一个被矩阵计算并行性教义明确排除的门的钥匙。”

这对整个AI硬件和软件生态系统构成了根本挑战。像AWS、Azure和谷歌这样的GPU巨头有潜力在一夜之间将其数据中心利用率提高四倍。iFrame的架构从底层设计上运用去中心化网络，利用现有硬件上的每一位可用内存。它绕过了使NVIDIA成为AI之王的GPU VRAM瓶颈，开辟了在全球分布式设备网络上运行大型AI模型的世界之路。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。