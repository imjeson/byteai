---

title: '首个无限上下文大模型颠覆12亿美元RAG市场'
date: 2025-08-09
author: ByteAILab

---

硅谷初创公司 iFrame™ AI 已悄然与一家领先的云服务提供商达成近2000万美元的协议，推出全球首个无限上下文窗口的大规模注意力模型（Large Attention Model, LAM）——这项突破性进展有望颠覆专业服务行业，并削弱OpenAI等公司的昂贵且冗余的数据检索服务所带来的收入。![图片](https://ai-techpark.com/wp-content/uploads/First.jpg){ width=60% }

---


正如去年的DeepSeek所震撼的AI生态系统一样，iFrame的Asperanto和Sefirot-10模型消除了检索管道和微调的需要，完美实现了前谷歌CEO埃里克·施密特最近的预测：无限上下文模型即将亮相，旨在重塑我们对自主AI应用的理解。

近十年来，人工智能行业一直困于变压器的注意力矩阵中——这一引擎驱动着OpenAI、谷歌和Anthropic等所有主要AI，即使是最先进的模型也陷入了数字失忆的状态。

经过三年的潜行模式，iFrame™ 正在推出全球首个大型注意力模型（LAM），其架构不仅扩展了上下文窗口——它使这一概念变得毫无意义。通过完全移除注意力矩阵，iFrame™创建了一种能够在单次传递中原生推理TB级数据的模型：无需RAG，无需微调，无需花招。与其训练多亿参数的LLM并将其提炼和微调为可用的推理，使用iFrame™，只需将TB级数据上传至注意力模块，即可在几秒钟内升级AI知识。

“无论怎样，我都帮助AI逃脱了矩阵——字面意思。” iFrame创始人及Monoidal Framework的创作者弗拉德·帕宁在最近的采访中表示。这个突破并非源于对现有AI研究的迭代，而是源于对宇宙拓扑数学的深度研究，受到著名隐士格里戈里·佩雷尔曼的启发，他在2002年解决了庞加莱猜想。

“每个人都在试图优化矩阵，以符合其接受的叙事。”帕宁解释道。“我却鲁莽地寻找一把钥匙，试图打开一个在矩阵计算平行性教义中明确被排除的门。”

这是对整个AI硬件和软件生态系统的根本挑战。像AWS、Azure和谷歌这样的GPU巨头可以在一夜之间将其数据中心利用率提升四倍。iFrame的架构从根本上设计为在去中心化网络上运行，利用可用硬件上每一位的内存。它绕过了使NVIDIA成为AI之王的GPU VRAM瓶颈，并为一个在全球分布式设备上运行的大型AI模型的世界开辟了道路。

GlobeNewswire
GlobeNewswire是全球最大的新闻发布网络之一，专注于将企业新闻稿、财务披露和多媒体内容发送给媒体、投资社区、个人投资者和公众。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。