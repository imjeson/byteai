---

title: '融资6.4亿美元，AI芯片公司迅速崛起，Yann LeCun出任技术顾问'
date: 2024-08-08
author: ByteAILab

---

Groq是一家开发芯片以比传统处理器更快地运行生成式 AI 模型的初创公司，该公司周一表示，已在由贝莱德 (Blackrock) 领投的新一轮融资中筹集了 6.4 亿美元。Neuberger Berman、Type One Ventures、思科、KDDI 和三星 Catalyst Fund 也参与其中。

---

这笔资金使 Groq 的总融资额超过 10 亿美元，公司估值达到 28 亿美元，这对 Groq 来说是一次重大胜利，据报道，该公司最初希望以略低的估值（25 亿美元）筹集3 亿美元。这笔资金是 Groq 在 2021 年 4 月的先前估值（约 10 亿美元）的两倍多，当时该公司在 Tiger Global Management 和 D1 Capital Partners 领投的一轮融资中筹集了 3 亿美元。
Meta 首席人工智能科学家 Yann LeCun 将担任 Groq 的技术顾问，英特尔代工业务前负责人、惠普前首席信息官 Stuart Pann 将加入这家初创公司担任首席运营官，Groq 今天还宣布了这一消息。考虑到 Meta 在自己的人工智能芯片上的投资，LeCun 的任命有点出人意料——但毫无疑问，这让 Groq 在竞争激烈的领域获得了一个强大的盟友。
Groq 于2016 年崭露头角，目前正在开发所谓的 LPU（语言处理单元）推理引擎。该公司声称，其 LPU 可以运行现有的生成式 AI 模型，其架构与 OpenAI 的ChatGPT和GPT-4o类似，速度是后者的 10 倍，能耗仅为后者的十分之一。
Groq 首席执行官乔纳森·罗斯 (Jonathan Ross) 因帮助发明张量处理单元 (TPU)而声名鹊起 ，这是谷歌用于训练和运行模型的定制 AI 加速器芯片。近十年前，罗斯与企业家、谷歌母公司 Alphabet X 登月实验室前工程师道格拉斯·怀特曼 (Douglas Wightman) 合作，共同创立了 Groq。
Groq 提供了一个由 LPU 驱动的开发者平台，名为 GroqCloud，该平台提供“开放”模型，如 Meta 的 Llama 3.1 系列、谷歌的 Gemma、OpenAI 的 Whisper 和 Mistral 的 Mixtral，以及允许客户在云实例中使用其芯片的 API。（Groq 还为去年年底推出的人工智能聊天机器人 GroqChat 提供了一个游乐场。）截至 7 月，GroqCloud 拥有超过 356,000 名开发人员；Groq 表示，本轮融资的部分收益将用于扩大容量并添加新模型和功能。
Groq 首席运营官 Stuart Pann 告诉 TechCrunch：“这些开发人员中有很多都在大型企业工作。据我们估计，财富 100 强企业中有超过 75% 的人都在使用 Groq。”
随着生成式人工智能的持续热潮，Groq 面临着来自其他人工智能芯片新贵以及人工智能硬件领域强大巨头 Nvidia 日益激烈的竞争。
据估计，Nvidia 控制着用于训练和部署生成式 AI 模型的 AI 芯片市场的 70% 至 95%，该公司正在采取积极措施来保持其主导地位。
Nvidia 承诺每年发布一款新的 AI 芯片架构，而不是像以往那样每隔一年发布一款。据报道，该公司正在建立一个新的业务部门，专注于为云计算公司和其他公司设计定制芯片，包括 AI 硬件。
除了 Nvidia，Groq 还与亚马逊、谷歌和微软竞争，这些公司都提供（或即将提供）用于云端 AI 工作负载的定制芯片。亚马逊拥有 Trainium、Inferentia 和 Graviton 处理器，可通过 AWS 获得；谷歌云客户可以使用上述 TPU，并适时使用谷歌的Axion芯片；微软最近为其 Cobalt 100 CPU 推出了 Azure 实例预览版，Maia 100 AI Accelerator 实例将在未来几个月内推出。
一些分析师认为，在未来五年内，人工智能芯片市场的年销售额可能达到 4000 亿美元，Groq 可能会将 Arm、英特尔、AMD 以及越来越多的初创公司视为竞争对手。Arm和AMD 的人工智能芯片业务尤其蓬勃发展，这要归功于云供应商为满足生成式人工智能的容量需求而不断增加的资本支出。
D-Matrix 去年年底筹集了 1.1 亿美元，用于将其所谓的首创推理计算平台商业化。今年 6 月，Etched以 1.2 亿美元的价格脱颖而出，购买了一款定制处理器，用于加速当今占主导地位的生成式 AI 模型架构，即 transformer。据报道，软银的孙正义正寻求筹集 1000 亿美元成立一家芯片企业，与 Nvidia 竞争。据说 OpenAI 正在 与 投资公司洽谈启动一项 AI 芯片制造计划。
为了开拓自己的市场，Groq 正在大力投资企业和政府推广。
今年 3 月，Groq收购了Definitive Intelligence，后者是一家总部位于帕洛阿尔托的公司，提供一系列面向企业的 AI 解决方案，并组建了一个名为 Groq Systems 的新业务部门。Groq Systems 的业务范围包括为希望将 Groq 芯片添加到现有数据中心或使用 Groq 处理器构建新数据中心的组织（包括美国政府机构和主权国家）提供服务。
最近，Groq 与政府 IT 承包商 Carahsoft 合作，通过 Carahsoft 的经销商合作伙伴向公共部门客户销售其解决方案，并且该初创公司已签署意向书，准备在欧洲公司 Earth Wind & Power 的挪威数据中心安装数万个 LPU。
Groq 还与沙特阿拉伯咨询公司 Aramco Digital 合作，在中东未来的数据中心安装 LPU。
在建立客户关系的同时，总部位于加州山景城的 Groq 也在向下一代芯片迈进。去年 8 月，该公司宣布将与三星的代工业务签约生产 4nm LPU，预计这些 LPU 的性能和效率将超过 Groq 的第一代 13nm 芯片。
Groq 表示，计划到 2025 年第一季度末部署超过 108,000 个 LPU。

---

风险投资持续流入人工智能初创企业

Groq 并不是唯一一家成功利用人工智能炒作的基础设施供应商。事实上，6.4 亿美元远不是我们近年来看到的初创公司获得的最大一笔收入。
您可能还记得，早在 5 月份，GPU 巨头 CoreWeave 就在 C 轮融资中获得了11 亿美元，几周后它就成功说服黑石集团、贝莱德和其他公司以其 GPU 作为抵押获得75 亿美元贷款。
与此同时，另一家 GPU 云运营商 Lambda Labs 自 2 月份以来利用其 GPU 缓存获得了总计 8.2 亿美元的新资金和债务融资，但看起来它还不满足。上个月我们了解到，据报道，Lambda 正在与风险投资公司洽谈再获得 8 亿美元的资金，以支持部署更多 Nvidia GPU。
尽管风险投资资金不断流入人工智能初创企业，但华尔街的一些人似乎越来越担心这些数十亿美元的人工智能基础设施投资是否会带来回报。
但这并没有阻止 Cerebras 等机器学习新贵寻求首次公开募股 (IPO)。上周，这家以餐盘大小的模型训练加速器而闻名的公司透露，它已秘密申请公开上市。
首次公开募股的规模和价格范围尚未确定。Cerebras 对人工智能训练问题采取了相当不同寻常的方法，帮助它从 G42 等公司获得了超过 9 亿美元的承诺。
与此同时，除了英特尔这个相当引人注目的例外（英特尔计划裁员至少 15%，第二季度利润同比下降 16 亿美元）之外，芯片供应商和转售其加速器访问权的云提供商一直是人工智能热潮的最大受益者。上周，AMD透露其MI300X GPU 占其数据中心销售额的 10 亿美元以上。
然而，似乎直到本月晚些时候市场领导者 Nvidia 公布其收益和前景后，人工智能炒作列车是否会脱轨的真正试金石才会到来。

英伟达的问题，会否引起AI巨变？

最近，有新闻指出，英伟达顶级产品 Blackwell 系列“GB200”因为缺陷导致交付时间推迟了三个多月。此次延迟预计将影响微软、谷歌和 Meta 等大型科技公司的商业计划，这些公司原本打算利用价值数十至数百万亿韩元的 GB200 来增强其 AI 服务。行业分析师认为，全球 AI 行业的“垄断风险”已成为现实，英伟达和台积电都面临问题，这两家公司占据了 AI 加速器设计和生产市场 90% 以上的份额。
Blackwell 系列包括“B100”和“B200”，封装了八个 192GB 第五代 HBM（HBM3E）和一个 GPU，而“GB200”则在两个 B200 上增加了一个中央处理器 (CPU)。据报道，问题出现在顶级型号 GB200 上。尽管 GB200 的定价超过 40,000 美元（约合 5400 万韩元），比其前身 H100 高出 30% 以上，但微软和谷歌等客户下了价值数十至数百万亿韩元的订单。NVIDIA 甚至最近要求负责 Blackwell 生产的台积电将产量提高 25%。
据市场研究公司TechInsights统计，去年NVIDIA在AI加速器市场的占有率高达97.2%。而代工Blackwell的台积电，在AI加速器领域的代工市场份额预估超过95%。AI半导体供应链向特定企业集中，风险极大，一位半导体行业人士指出，“AI半导体供应链向特定企业集中，风险极大”，并预测“三星和AMD将有机会”。
专家预测，此次设计缺陷事件将加剧“反英伟达”风潮，加速大型科技公司“英伟达/台积电替代战略”。AMD和谷歌纷纷推出自研GPU，将自己定位为英伟达的竞争对手。实际动向正在观察中。最近，微软和谷歌向第二大AI加速器公司AMD派遣员工，共同开发下一代产品。微软还开始采购AMD的AI加速器“MI300X”。苹果在AI模型训练方面，已经采用谷歌的TPU芯片，而非英伟达芯片。
NVIDIA 的“反垄断”风险也在增加。有报道称，美国司法部正在调查 NVIDIA 涉嫌违反反垄断法。占据超过 80% AI 芯片市场份额的 NVIDIA 被指控威胁对试图购买竞争对手产品的客户进行报复。继法国之后，另一个反垄断风险可能会阻碍 NVIDIA 的单打独斗。
向AMD和谷歌供应HBM的三星电子预计将受益于AI加速器市场的多元化。三星电子目前向AMD供应第4代HBM——HBM3，并已有效确保了HBM3E的供应。最近，三星还一直在推动其代工和先进封装“交钥匙服务”，以替代台积电。不过，短期内，SK海力士和三星电子的HBM3E交货时间表也预计将因这一设计缺陷而略有延迟。GB200共配备16个第5代HBM——HBM3E。由于Blackwell上市前订单激增，SK海力士和三星电子一直在转换生产线，专注于HBM3E。如果Blackwell的上市推迟到明年，可能会对他们今年下半年的业绩产生负面影响。
尽管面临挑战，但 NVIDIA
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。