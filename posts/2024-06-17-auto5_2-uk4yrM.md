---
title: '字节豆包、武大提出 CAL：通过视觉相关的 token 增强多模态对齐效果'
date: 2024-06-18
author: ByteAILab

---

当前主流的视觉语言模型（VLM）主要基于大语言模型（LLM）进一步微调。因此需要通过各种方式将图像映射到 LLM 的嵌入空间，然后使用自回归方式根据图像 token 预测答案。

---


在这个过程中，模态的对齐是通过文本 token 隐式实现的，如何做好这一步的对齐非常关键。

针对这一问题，武汉大学、字节跳动豆包大模型团队和中国科学院大学的研究人员提出了一种基于对比学习的文本 token 筛选方法（CAL），从文本中筛选出与图像高度相关的 token，并加大其损失函数权重，从而实现更精准的多模态对齐。

CAL 有以下几个亮点：

- 可以直接嵌套到训练过程，无需额外预训练阶段。
- 在 OCR 和 Caption benchmarks 上获得了明显的提升，从可视化中可以发现 CAL 使得图片模态对齐效果更好。
- CAL 使得训练过程对噪声数据抵抗能力更强。

研究动机

目前视觉语言模型依赖于图片模态的对齐，如何做好对齐非常关键。目前主流的方法是通过文本自回归的方式进行隐式对齐，但是每个文本 token 对图像对齐的贡献是不一致的，对这些文本 token 进行区分是非常有必要的。

CAL 提出，在现有的视觉语言模型（VLM）训练数据中，文本 token 可以被分为三类：

- 与图片高度相关的文本：如实体（例如人、动物、物体）、数量、颜色、文字等。这些 token 与图像信息直接对应，对多模态对齐至关重要。
- 与图片低相关度的文本：如承接词或可以通过前文推断出的内容。这些 token 实际上主要是在训练 VLM 的纯文本能力。
- 与图片内容相悖的文本：这些 token 与图像信息不一致，甚至可能提供误导信息，对多模态对齐过程产生负面影响。

在训练过程中，后两类 token 整体而言实际上占据了较大比例，但由于它们并不强依赖于图片，对图片的模态对齐作用不大。因此，为了实现更好的对齐，需要加大第一类文本 token，即与图片高度相关部分 token 的权重。如何找出这一部分 token成为了解决这个问题的关键所在。

方法

找出与图片高度相关 token 这个问题可以通过 condition contrastive 的方式来解决。

具体来说，在训练过程中，CAL 将图文序列和单独的文本序列分别输入到大语言模型（LLM）中，得到每个文本 token 的 logit。通过计算这两种情况下的 logit 差值，可以衡量图片对每个 token 的影响程度。logit 差值越大，说明图片对该 token 的影响越大，因此该 token 与图像越相关。

CAL 在 LLaVA 和 MGM 两个主流模型上进行了实验验证，在不同规模的模型下均实现了性能提升。

包含以下四个部分的验证：

- 使用 CAL 的模型在各项基准测试指标上表现更佳。
  
  ![图片](https://image.jiqizhixin.com/uploads/editor/b64f0041-1df0-4d4d-ae36-e4ca0030852d/640.png)
  
  ![图片](https://image.jiqizhixin.com/uploads/editor/4b0e011f-4a2a-4f53-a436-591ccf789c7a/640.png)
  
- 通过按比例随机交换两个图文对中的文本来制造一批噪声数据（图文错配），并用于模型训练，CAL 使得训练过程具有更强的数据抗噪性能。
  
  ![图片](https://image.jiqizhixin.com/uploads/editor/493ae588-31a3-41f1-9166-3b076c86d2dc/640.png)
  
- 对 QA case 中的答案部分计算其与图片 token 的注意力分数分布，并将其绘制在原图上，CAL 训练的模型拥有更清晰的注意力分布图。
  
  ![图片](https://image.jiqizhixin.com/uploads/editor/6ccdcfe4-edca-4981-8e75-63f779976faf/640.png)
  
- 将每个图片 token映射为它最相似 LLM 词表中的文本 token，将其绘制到原图上，CAL 训练的模型映射内容更接近图片内容。
  
  ![图片](https://image.jiqizhixin.com/uploads/editor/fbcda4fc-6af7-4d47-8344-436630b827c3/640.png)

团队介绍：

字节跳动豆包大模型团队成立于 2023 年，致力于开发业界最先进的 AI 大模型技术，成为世界一流的研究团队，为科技和社会发展作出贡献。

豆包大模型团队在 AI 领域拥有长期愿景与决心，研究方向涵盖 NLP、CV、语音等，在中国、新加坡、美国等地设有实验室和研究岗位。团队依托平台充足的数据、计算等资源，在相关领域持续投入，已推出自研通用大模型，提供多模态能力，下游支持豆包、扣子、即梦等 50 + 业务，并通过火山引擎开放给企业客户。目前，豆包 APP 已成为中国市场用户量最大的 AIGC 应用。欢迎加入字节跳动豆包大模型团队。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。