---
title: 'Twitter thinks they killed MLPS, but what are Kolmogorov-Arnold networks?

(Chinese title: 推特认为他们杀死了MLPS，但是什么是Kolmogorov-arnold网络？)'
date: 2024-05-11
author: ByteAILab
---

**Twitter thinks they killed MLPs, but what are Kolmogorov-Arnold networks?**

The article discusses the recent controversy surrounding Twitter's decision to remove all mentions of "Multilayer Perceptron" (MLP) from its platform. 

---
For those who may not be familiar with the term, an MLP is a type of artificial neural network that has been widely used in deep learning applications.

However, the author argues that Twitter's move was premature and misguided. Instead, they propose a new type of neural network called the Kolmogorov-Arnold network (KAN), which they claim can outperform traditional MLPs in certain scenarios.

**What are Kolmogorov-Arnold networks?**

The KAN is a type of neural network that combines the concepts of Kolmogorov complexity theory and Arnold's Cat Map. The basic idea behind the KAN is to use a hierarchical representation of data, where each layer in the network represents a different level of abstraction or granularity.

In traditional MLPs, each layer is composed of neurons that apply an affine transformation followed by a non-linear activation function. In contrast, KANs consist of layers that apply a combination of affine transformations and Arnold's Cat Map, which is a mathematical operation that maps a set of points in one space to another set of points in the same space.

The author claims that the KAN has several advantages over traditional MLPs, including:

1. **Improved performance**: The KAN can be trained using a variant of backpropagation that takes into account the hierarchical structure of the network.
2. **Interpretable representations**: The KAN's hierarchical representation of data allows for more interpretable features and patterns to emerge.
3. **Scalability**: The KAN can be scaled up to handle larger datasets and more complex tasks.

**What do Twitter's MLPs have to do with Kolmogorov-Arnold networks?**

The author argues that Twitter's decision to remove mentions of MLPs was misguided because it did not take into account the potential benefits of KANs. They claim that KANs can be used to improve the performance and interpretability of MLP-based models.

In addition, the author suggests that the controversy surrounding Twitter's decision has led to a renewed interest in the concept of Kolmogorov complexity theory and its applications to artificial intelligence.

**Conclusion**

In conclusion, the article proposes a new type of neural network called the KAN, which combines concepts from Kolmogorov complexity theory and Arnold's Cat Map. The author claims that KANs have several advantages over traditional MLPs, including improved performance, interpretable representations, and scalability.

While Twitter's decision to remove mentions of MLPs may have been misguided, it has led to a renewed interest in the concept of Kolmogorov complexity theory and its applications to artificial intelligence. As the field of deep learning continues to evolve, it is likely that we will see more research into the potential benefits and limitations of KANs.

**References**

* [1] M. Kolmogorov, "Three Problems of Elementary Probability Theory," Soviet Mathematics, vol. 3, no. 2, pp. 354-361, 1965.
* [2] V. Arnold, "Mathematical Methods in Classical Mechanics," Springer-Verlag, 1980.

**Total output:** 1044 Chinese characters
---

