---
title: 'LLM仍然不能规划，刷屏的OpenAI o1远未达到饱和'
date: 2024-09-25
author: ByteAILab

---

实验证明，大模型的 System 2 能力还有待开发。

规划行动方案以实现所需状态的能力一直被认为是智能体的核心能力。

---
随着大型语言模型（LLM）的出现，人们对 LLM 是否具有这种规划能力产生了极大的兴趣。

最近，[OpenAI 发布了 o1 模型](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650934313&amp;idx=1&amp;sn=3e89923751621fed57602ffe4ba751f4&amp;chksm=84e7c857b3904141d5ef61e834efeb469e7982498aca47cfe92cadcf3912908754e752793c2a)，一举创造了很多历史记录。o1 模型拥有真正的通用推理能力。在一系列高难基准测试中展现出了超强实力，相比 GPT-4o 有巨大提升，让大模型的上限从「没法看」直接上升到优秀水平，不专门训练直接数学奥赛金牌，甚至能在博士级别的科学问答环节上超越人类专家。

那么，o1 模型是否具备上述规划能力？

2022 年，来自亚利桑那州立大学（ASU）的研究团队开发了评估 LLM 规划能力的基准 ——PlanBench。现在，亚利桑那州立大学研究团队全面审视了当前 LLM 在 PlanBench 上的表现，包括 o1 模型。值得注意的是，虽然 o1 在基准测试上性能超过了竞争对手，但它还远未达到饱和状态。

[SOTA 性能的 LLM 仍然不会规划]

对于 vanilla LLM（通过 RLHF 微调的 Transformer 模型）来说，PlanBench 基准仍然充满挑战，即使在最简单的测试集上，模型表现也不佳。

下表为当前和前一代 LLM 的结果，测试领域包括 Blocksworld 和 Mystery Blocksworld...

更多内容请参阅原文下载：[LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench](https://arxiv.org/pdf/2409.13373)

[![图片](https://image.jiqizhixin.com/uploads/editor/5b64ae38-76da-466e-bb77-2a64b2bbd6ae/640.png)](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW94YALpSt7pGOl72C3AweLadhBNef7G3yh4XYOKflSUPe1PJ52pKHIqyBibrbhCpuI2BHOpiczUBYkA/640?wx_fmt=png&amp;from=appmsg)

[![图片](https://image.jiqizhixin.com/uploads/editor/139649a3-e425-4876-9a3d-ad42640481cc/640.png)](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW94YALpSt7pGOl72C3AweLaq1QBPLhtSDjl4IajmrYDibWGG0NEczicpYcRm72wodPBYn6YdN3w1iaYw/640?wx_fmt=png&amp;from=appmsg)

[从近似检索到近似推理：评估 o1]

标准自回归 LLM 通过近似检索生成输出，但这些模型面临一个问题，即在 System 1 任务中表现出色，但在对规划任务至关重要的类似 System 2 的近似推理能力上表现不佳。

回顾之前的研究，从 LLM 中获取可靠规划能力的最佳方法是将它们与生成测试框架中的外部验证器配对，即所谓的 LLM-Modulo 系统。o1 尝试以不同的方式为底层 LLM 补充类似 System 2 的能力。

据了解，o1 是将底层 LLM（很可能是经过修改的 GPT-4o）结合到 RL 训练的系统中...

[![图片](https://image.jiqizhixin.com/uploads/editor/11a373bb-2fa6-4546-b8e5-538c6f3ff755/640.png)](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW94YALpSt7pGOl72C3AweLa7ypicg6WReWQ45JtHOVIoVPIOLXJUtgoHeGDEicOjYWIDhia7IicHLSQ4A/640?wx_fmt=png&amp;from=appmsg)

[准确率 / 成本权衡与保证]

研究团队发现：o1-preview 似乎在每个问题使用的推理 token 数量方面受到限制。如果 o1 的正式版本消除了这一限制，可能会提高整体准确性，但也可能导致...

[![图片](https://image.jiqizhixin.com/uploads/editor/0a6445a7-ebad-4e4d-989b-dae94e15afbd/640.png)](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW94YALpSt7pGOl72C3AweLaHtibJyiatK7SwhO61d3N6Xv2rkiayzMcBA2FzuUGPR762NVtibvnXWS1dQ/640?wx_fmt=png)

[![图片](https://image.jiqizhixin.com/uploads/editor/4fd0042e-ed82-4525-9018-bffd88f7201e/640.png)](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW94YALpSt7pGOl72C3AweLalslKhF9QYt9HxiaBEgCOovpO11r2Mia3Iicjf5jibDZaTO1gL42VcmCgxA/640?wx_fmt=png)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。