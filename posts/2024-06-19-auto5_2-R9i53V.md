---
title: '吴恩达团队新作：多模态多样本上下文学习，无需微调快速适应新任务'
date: 2024-06-20
author: ByteAILab

---

AIxiv专栏是机器之心发布学术、技术内容的栏目。过去数年，机器之心AIxiv专栏接收报道了2000多篇内容，覆盖全球各大高校与企业的顶级实验室，有效促进了学术交流与传播。

---
如果您有优秀的工作想要分享，欢迎投稿或者联系报道。投稿邮箱：liyazhou@jiqizhixin.com；zhaoyunfeng@jiqizhixin.com

本研究评估了先进多模态基础模型在 10 个数据集上的多样本上下文学习，揭示了持续的性能提升。批量查询显著降低了每个示例的延迟和推理成本而不牺牲性能。这些发现表明：利用大量演示示例可以快速适应新任务和新领域，而无需传统的微调。

论文地址：https://arxiv.org/abs/2405.09798
代码地址：https://github.com/stanfordmlgroup/ManyICL

背景介绍

在近期的多模态基础模型（Multimodal Foundation Model）研究中，上下文学习（In-Context Learning, ICL）已被证明是提高模型性能的有效方法之一。

然而，受限于基础模型的上下文长度，尤其是对于需要大量视觉 token 来表示图片的多模态基础模型，已有的相关研究只局限于在上下文中提供少量样本。

令人激动的是，最新的技术进步大大增加了模型的上下文长度，这为探索使用更多示例进行上下文学习提供了可能性。

基于此，斯坦福吴恩达团队的最新研究——ManyICL，主要评估了目前最先进的多模态基础模型在从少样本 (少于 100) 到多样本（最高至 2000）上下文学习中的表现。通过对多个领域和任务的数据集进行测试，团队验证了多样本上下文学习在提高模型性能方面的显著效果，并探讨了批量查询对性能和成本及延迟的影响。

方法概览

本研究选择了三种先进的多模态基础模型：GPT-4o、GPT4 (V)-Turbo 和 Gemini 1.5 Pro。出于 GPT-4o 优越的表现，研究团队在正文中着重讨论 GPT-4o 和 Gemini 1.5 Pro， GPT4 (V)-Turbo 的相关内容请于附录中查看。

数据集方面，研究团队在 10 个跨越不同领域（包括自然影像、医学影像、遥感影像和分子影像等）和任务（包括多分类、多标签分类和细粒度分类）的数据集上进行了广泛的实验。

为了测试增加示例数量对模型性能的影响，研究团队逐步增加了上下文中提供的示例数量，最高达到近 2000 个示例。同时，考虑到多样本学习的...
---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。