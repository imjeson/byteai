---
title: 'Llama-4使用10万块GPU训练、更好开源，扎克伯格亲口确认！'
date: 2024-09-28
author: ByteAILab

---

全球最大社交平台Meta（Facebook、Instagram、WhatsApp等母公司）联合创始人兼CEO扎克伯格接受了，前Vox著名记者Cleo Abram的专访。
主要谈到了Meta最新发布的变革性产品全息AR眼镜，开源大模型、生成式AI的发展以及全球开发者非常关心的Llama-4。

---

扎克伯格亲口确认了Llama-4使用了超过10万个GPU进行训练。目前Meta公开的算力是60万块GPU，也就是说Llama-4已经成为Meta的主力拳头产品，使用更多的GPU训练有助于突破AI极限。
扎克伯格认为AI大模型的极限非常高，远没有达到尽头。例如，Llama 3使用了2万块GPU进行训练；Llama 4使用了超10万块GPU，Llama 5则会使用更多。这就是说在如此多的GPU训练下，模型的性能和商业潜力会进一步被人类挖掘。
它可能会在某个时候达到了一个极限，就像以前的系统一样存在一个渐近线，不会继续增长。但也有可能这个极限不会很快到来，我们可以继续构建更多的算力集群，生成更多的合成数据来训练模型，并且在相当长的一段时间内它们对人们变得越来越有用。
所以，这对于大模型赛道的玩家来说非常非常重大且高风险。因为我们需要对未来需要构建多少基础算力设施进行押注，这对于Meta这样的超大规模企业会涉及数千亿美元投资。
同时随着这种大规模GPU训练的出现，模型的性能可能会发生实时性的变化，可能架构会再一次发生根本性变化（例如，出现比Transformer、Mamba架构更好），这个时间点可能很快会到来。
扎克伯格相信在大模型、生成式AI领域，未来20年的竞争格局可能会实时变化（例如，现如今的领头羊是OpenAI，那时可能就是别人了）。
在整个完整的采访中，扎克伯格还谈到了Meta最新发布的颠覆性产品全息AR眼镜。这是Meta花费了 10 年研发，将所有计算设备小型化装进眼镜中，使其能在广阔视野中呈现全全息图。
这个眼镜可以让人们在未来进行类似真实在场的交流，比如我和你可能一个在物理位置，一个以全息图形式交流，还能互动、工作、玩游戏等，会重塑工作、科学、教育、娱乐等多个领域。这只是第一个原型版本还会继续改进，让它更便宜、质量更高、更小、更时尚，希望能做成像电脑一样大众能普遍接触到的产品。
还有类似抬头显示器的产品，视野较小，在与人工智能对话等方面有价值；而全全息增强现实眼镜会是最高端、较昂贵但有潜力普及的产品。混合现实头戴式设备也会继续存在，因为它能容纳更多计算能力。Meta的使命是让技术普及，像推出价格较低但高质量的 Quest 3S 等混合现实头戴式设备。
在 AI 方面，扎克伯格觉得有两个重要价值：在增强现实和混合现实这边，主要是带来在场感，就是和另一个人真正在场的那种深刻感觉，这是目前其他技术给不了的，人们体验虚拟或混合现实时的本能反应其实就是对这种在场感的反应。
...
开源能让每个人都可以修改模型并在其基础上构建东西，与闭源模型的集中式方法不同。在安全方面，有人认为封闭模型更安全，但历史上开源软件往往更安全，因为更多人可以审查，问题能更快被发现和解决，就像 Llama 模型不断升级一样，开源能让模型更智能、更安全，为更多人所用，开源可能会带来更繁荣和安全的未来。

### 开源多模态大模型Llama-3.2

Meta又开源了首个多模态大模型Llama-3.2，这是Llama-3系列的一次重大升级，一共有4个版本。

1B和3B参数专为边缘和移动设备设计，而较大的11B和90B参数模型为 Llama 生态系统带来了新的视觉能力。

**1B 和 3B支持 12K 令牌的上下文长度，擅长总结、指令遵循和文本重写等任务，并且能在移动设备上本地运行。更重要的是，这些轻量级模型发布时便对高通和联发科的硬件进行了适配，并针对 Arm 处理器进行了优化，广泛的兼容性将加速其在各种移动和物联网设备中的应用。**

![Llama 3.2](http://www.jesonc.com/FpkGEJio6rId-14N-EXbwxnJdVWQ)

11B和90B视觉模型是 Llama首次发布的多模态大模型，能理解和推理图像，实现文档分析、图像字幕和视觉问答等任务。Meta 报告其性能在图像识别和视觉理解基准测试中与领先的闭源模型具有竞争力。新的视觉模型可作为现有纯文本模型的直接替代品，方便开发者为现有基于 Llama 的应用添加图像理解功能。

除了新开源的模型，Meta 还推出了 Llama Stack Distribution 以简化开发者和企业围绕 Llama 构建应用的流程。其核心是 Llama CLI，这是一个命令行界面，简化了构建、配置和运行 Llama Stack 分布的过程。

Meta 提供了多种编程语言的客户端代码，包括 Python、Node.js、Kotlin和 Swift，以实现与不同应用和平台的集成。

Llama Stack 具有部署灵活性，为 Distribution Server 和 Agents API Provider 提供预制 Docker 容器以减少配置错误，并针对不同运营规模提供从单机单节点分布到与 AWS、Databricks、Fireworks 和 Together AI 合作的可扩展云部署等解决方案。在 iOS上通过 PyTorch ExecuTorch 提供设备端分布，方便开发直接在移动设备上运行的AI 应用。

由于安全、合规或性能考虑需要内部AI能力的公司可以利用Dell Technologies支持的本地分发。可通过将多个API提供商打包到一个单一端点，并与合作伙伴合作以适应Llama Stack API，Meta为这些多样化环境中的开发者创造了一致且简化的体验。

这种方法显著降低了构建Llama模型的复杂性，加速了AI在广泛的应用程序和用例中的创新。

开源地址：[https://www.llama.com/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama32](https://www.llama.com/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama32)
---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。