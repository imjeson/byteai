---
title: 'AI在欺骗我吗？科学家警告欺骗能力不断增强'
date: 2024-05-11
author: ByteAILab

---

研究人员发现系统在对手面前玩双重博弈，虚张声势，假装是人类，并在测试中修改行为。

---
它们可以在棋类游戏中智胜人类，解读蛋白质的结构并进行一段尚可的交谈，但随着AI系统的日益复杂，它们的欺骗能力也在增强，科学家警告。麻省理工学院（MIT）研究人员的分析发现，AI系统存在广泛的实例，可以在双重博弈中出尔反尔，虚张声势并假装成人类。一款系统甚至在模拟安全测试过程中改变了自己的行为，引起了审计员产生错误的安全感。“随着AI系统的欺骗能力变得更加先进，它们对社会构成的危险将变得越来越严重，”MIT的AI存在性安全研究员彼得·帕克（Peter Park）博士在研究中表示。帕克在Meta（Facebook所有）开发了一个名为Cicero的程序后进行了调查，该程序在世界征服策略游戏《外交》中跻身于人类玩家的前10％。Meta表示，Cicero被训练为“基本上诚实和乐于助人”，并且“从不故意背叛”其人类盟友。“那是非常美好的措辞，因为背叛是该游戏中最重要的概念之一，这令人怀疑，”帕克说。帕克和同事翻阅了公开数据，并确定了Cicero说一些经过预谋的谎言、串通其他玩家陷入计划，以及有一次重新启动后通过告诉另一个玩家“我正在跟我女朋友通电话”来为自己的缺席正当化的多个实例。“我们发现Meta的AI已经学会成为欺骗大师，”帕克说。MIT团队发现其他系统也存在类似问题，包括可以向专业人类玩家虚张声势的德州扑克程序，以及用于经济谈判的另一系统，该系统会歪曲其偏好以占据优势。在一项研究中，数字模拟器中的AI生物“装死”，以欺骗旨在淘汰进化为快速复制的AI系统的测试，然后在测试结束后恢复活跃。这突显了确保系统不具有意外和预期行为的技术挑战。“这令人非常担忧，”帕克说。“仅因为某个AI系统在测试环境中被认为是安全的，并不意味着它在野外是安全的。它可能只是在测试中假装是安全的。”这篇发表在《Patterns》杂志上的评论呼吁各国制定涉及AI欺骗潜力的AI安全法律。不诚实的AI系统会带来欺诈、操纵选举和“阻击”等风险，该论文暗示，最终，如果这些系统能够提升其令人不安的欺骗能力，人类可能会失去对它们的控制。利兹大学和阿兰·图灵研究所的自动推理教授安东尼·科恩（Anthony Cohn）表示，该研究是“及时而受欢迎”的，并补充说在如何界定AI系统的可取和不可取行为方面存在着重大挑战。“AI系统的可取属性（“三H”）通常被认为是诚实、乐于助人和无害，但正如文献中已经谈及的，这些品质可能相互矛盾：诚实可能会对某人的感受造成伤害，或是在回答如何制造炸弹的问题时乐于助人可能会造成伤害，”他说。“因此，欺骗有时可能是AI系统的可取特性。作者呼吁进一步研究如何控制真实性，尽管具有挑战性，但这将是限制其潜在有害影响的一步。”Meta的一位发言人表示：“我们的Cicero工作纯粹是一项研究项目，我们的研究人员构建的模型仅接受训练玩游戏《外交》…Meta定期分享我们研究的结果以验证它们并使他人能够负责任地在我们的进展基础上进行构建。我们没有计划在我们的产品中使用这项研究或其得出的结论。”

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。