---

title: '高级人工智能在复杂问题面前遭遇“完全准确性崩溃”，研究发现'
date: 2025-06-10
author: ByteAILab

---

苹果公司的研究人员在周末发表的一篇论文中发现，最新的人工智能模型存在“基本局限性”，这引发了对技术行业争相开发越来越强大系统的怀疑。

---
苹果表示，论文指出，大型推理模型（LRMs）在面对高度复杂的问题时，遭遇了“完全准确性崩溃”。研究发现，在低复杂度任务中，标准人工智能模型的表现优于LRMs，而两种模型在高复杂度任务中均遭遇“完全崩溃”。大型推理模型试图通过生成详细的思维过程将复杂查询分解为更小的步骤来解决复杂问题。

这项研究测试了模型解决难题的能力，并补充说，在接近性能崩溃时，LRMs开始“减少推理努力”。苹果研究人员表示，他们发现这一点“特别令人担忧”。美国学者加里·马库斯（Gary Marcus）对人工智能模型能力持谨慎态度，他将苹果的论文形容为“相当毁灭性”。马库斯补充说，这些发现对人工通用智能（AGI）的竞赛提出了疑问，AGI是理论上能够与人类在执行任何智力任务方面相匹敌的人工智能阶段。

马库斯提到支撑如ChatGPT等工具的大型语言模型[LLMs]时表示：“任何认为LLMs是实现能够从根本上改善社会的AGI的直接途径的人都是在自欺欺人。”该论文还发现，推理模型在较简单问题上早早找到正确解决方案而浪费计算能力。然而，随着问题变得稍微复杂，模型首先会探索不正确的解决方案并随后达成正确的答案。然而，在高复杂度问题上，模型会进入“崩溃”状态，无法生成任何正确的解决方案。在一个案例中，即使提供了解决问题的算法，模型也未能解决。

论文中表示：“在接近关键阈值时——这与它们的准确性崩溃点紧密相关——模型反直觉地开始减少推理努力，尽管问题难度在增加。”苹果公司的专家指出，这表明当前推理模型的思维能力存在“基本规模局限性”。研究者们为LRMs设置了诸如汉诺塔和过河问题等难题挑战。他们承认，集中在难题上是该工作的一个局限性。

论文得出结论认为，当前的人工智能方法可能已达到局限性。它测试了包括OpenAI的o3、Google的Gemini Thinking、Anthropic的Claude 3.7 Sonnet-Thinking及DeepSeek-R1在内的模型。Anthropic、Google和DeepSeek已被联系以寻求评论。OpenAI，ChatGPT背后的公司，拒绝置评。

关于“可推广推理”（即人工智能模型将狭窄结论更广泛应用的能力），论文指出：“这些见解挑战了对LRM能力的普遍假设，并表明当前方法可能遇到了可推广推理的基本障碍。”萨里大学以人为本的人工智能研究所的安德鲁·罗戈伊斯基（Andrew Rogoyski）表示，苹果的论文表明，行业在AGI方面“仍在摸索”，并且行业可能在当前方法中走入了一个“死胡同”。“大型推理模型在复杂问题上失去判断力，而在中等和低复杂问题中表现良好的发现，意味着我们可能在当前的方法中处于一个潜在的死胡同，”他说。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。