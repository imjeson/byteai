---
title: '寒武纪1号诞生：谢赛宁Yann LeCun团队发布最强开源多模态LLM'
date: 2024-06-29
author: ByteAILab

---

# 寒武纪1号诞生：谢赛宁Yann LeCun团队发布最强开源多模态LLM

就像动物有了眼睛，谢赛宁 Yann LeCun 团队的 Cambrian-1 能让 AI 获得强大的视觉表征学习能力。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibX8NO2BYWZUIEMa0dB6R2NVhWCDKF9H1HnU9JO92wtvOzX2WHHibWW69kB3AibVLCUyOEeDwYBMxibA/640?wx_fmt=png&amp;from=appmsg)

古往今来，许多哲学家都探究过这个问题：理解语言的含义是否需要以感官为基础？尽管哲学家们看法不一，但有一点却不言而喻：坚实有效的感官定基（grounding）至少能带来助益。

---


比如科学家们普遍相信，寒武纪大爆发期间视觉的出现是早期动物演化的关键一步；这不仅能帮助动物更好地找寻食物和躲避捕食者，而且还有助于动物自身的进化。事实上，人类（以及几乎所有动物）的大多数知识都是通过与物理交互的感官体验获取的，比如视觉、听觉、触觉、味觉和嗅觉。这些感官体验是我们理解周围世界的基础，也是帮助我们采取行动和决策的关键。

这些思想不仅仅能用来探究哲学概念，而且也具有实用价值，尤其是近期多模态大型语言模型（MLLM）的发展，更是让视觉表征学习与语言理解来到了实践应用的关注核心。语言模型表现出了非常强大的规模扩展行为，而多模态学习领域的近期进展也很大程度上得益于更大更好的 LLM。

另一方面，人们仍旧没有充分探索视觉组件的设计选择，并且这方面的探索与视觉表征学习的研究有所脱节。这主要是因为这方面的研究非常困难：MLLM 涉及复杂的训练和评估流程，需要考虑的设计选择非常多。

近日，纽约大学谢赛宁和 Yann LeCun 团队以视觉为中心对 MLLM 进行了探索，填补了这一空白；他们还基于这些探索成果构建了 Cambrian-1（寒武纪 1 号）系列模型。（本文有三位共同一作：Shengbang Tong（童晟邦）、Ellis Brown 和 Penghao Wu。）

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibX8NO2BYWZUIEMa0dB6R2NAhdfI2Zp1ibzPiaLrIzLoEunhKLz6nb8asZy9FG6gFQeSmfZopOo1blA/640?wx_fmt=png&amp;from=appmsg)

- 论文标题：Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs
- 论文地址：[https://arxiv.org/pdf/2406.16860](https://arxiv.org/pdf/2406.16860)
- 网站：[https://cambrian-mllm.github.io](https://cambrian-mllm.github.io)
- 代码：[https://github.com/cambrian-mllm/cambrian](https://github.com/cambrian-mllm/cambrian)
- 模型：[https://huggingface.co/nyu-visionx/](https://huggingface.co/nyu-visionx/)
- 数据：[https://huggingface.co/datasets/nyu-visionx/Cambrian-10M](https://huggingface.co/datasets/nyu-visionx/Cambrian-10M)
- CV-Bench：[https://huggingface.co/datasets/nyu-visionx/CV-Bench](https://huggingface.co/datasets/nyu-visionx/CV-Bench)
- 评估：[https://github.com/cambrian-mllm/cambrian](https://github.com/cambrian-mllm/cambrian)

具体来说，他们将 MLLM 指令微调用作了多种视觉表征的评估协议，如图 1 所示。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibX8NO2BYWZUIEMa0dB6R2Ng2xggkMibEMKYwgPqr5BSnEm1NevScpOpfaI0jLoqnYMr9ic2zJrmgjQ/640?wx_fmt=png&amp;from=appmsg)

该团队表示：「我们这项研究的动机源自当前多模态学习研究的两个潜在问题：1）过度且...
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。