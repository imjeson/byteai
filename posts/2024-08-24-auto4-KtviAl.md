---

title: '一家芯片公司，猛追英伟达'
date: 2024-08-25
author: ByteAILab

---

当前的 AI 训练和一些 AI 推理集群有两个网络。后端网络将计算引擎组（通常是 GPU 加速器，通常是 Nvidia 的加速器）相互连接，以便它们可以共享工作和数据。

---
前端网络将计算引擎的 CPU 主机相互连接、连接到存储以及连接到外部世界。InfiniBand 已逐渐成为后端网络的主导，而以太网则倾向于用于前端网络。Arista Networks 和 Cisco Systems 等公司也希望在升级前端网络的同时，在后端占有一席之地。思科在其最近的财务报告中表示，其 Silicon One ASIC 在后端 AI 集群网络试验中得到了一定程度的应用，但它也看到企业在准备部署 AI 训练和推理系统时升级其系统和前端网络。Arista 现在在其客户中看到了类似但略有不同的模式，因为它正在等待 2025 年 AI 网络的以太网热潮。过去两年来，Arista 一直在重新调整其产品线，以迎接这一热潮，并且像思科一样，它是超级以太网联盟的创始冠军，该联盟的明确目标是让以太网取代 AI 集群中的 InfiniBand——这或许是一种意想不到的副作用，在传统的 HPC 模拟和建模以及数据分析和存储集群中也是如此。

我们回顾了 Arista 最近的财务业绩，以进行观察。我们还想简要介绍一下 Arista 为在其本土 AI 领域与 InfiniBand 竞争而构建的 Etherlink 系列交换机。Arista 是我们数据中心的 13 大公共供应商之一，我们将其用作衡量该生态系统财务健康状况的指标。

...

参考链接
https://www.nextplatform.com/2024/08/21/arista-banks-on-the-ai-network-double-whammy/
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。