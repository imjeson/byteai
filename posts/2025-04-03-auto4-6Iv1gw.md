---

title: 'DeepSeek真帮黄仁勋了，你们怎么不信呢？'
date: 2025-04-04
author: ByteAILab

---

文章来源：[直面AI](https://mp.weixin.qq.com/s/hYftBspdZdK3DJ2_YPp7ww)

北京时间3月19日凌晨，站在圣何塞GTC大会的舞台上，连黄仁勋自己都调侃：GTC是AI届的超级碗。

几周以来，外界已经对黄仁勋在GTC的演讲万分期待。

---
这个演讲可不好做，在DeepSeek的冲击之下，英伟达今年的股价已经下跌了12%。这不再是发布新产品，高喊AI就是未来就可以完成任务的演讲，今年，黄仁勋需要回答很多问题。

而这场持续了两个半小时的演讲也的确和往年有很大的不同，黄仁勋在一开始就花了很长的时间去解释为什么推理时代缩放定律没有死、为什么英伟达依然非常重要。而后，他不仅拿出了Blackwell的超大杯产品，还透露了下一代芯片，甚至下下代架构，时间一直蔓延到2028年。压轴出场的，则和黄仁勋勾画的AI发展路线图中的最后一站“物理AI”相关。

黄仁勋拯救了英伟达股价吗？至少从当日来看，截至收盘英伟达股价跌了3.43%，总市值缩水至2.82万亿美元。到底是市场还需要几天时间消化，还是黄仁勋“游说”失败，还得等等看。

**演讲要点：**

1. 发布超大杯Blackwell Ultra，性能提升1.5倍。
2. 下一代AI“超级芯片”Vera Rubin，计划2026年底推出，并透露下下代芯片架构为Feynman，计划2028年推出。
3. AI工厂的操作系统Dynamo，推理框架，资源利用最大化，搭配Blackwell强上加强。
4. 推出“AI超级电脑”DGX Spark、DGX Station，提高本地运行大型AI模型的能力。
5. 宣布网络组件的最新动作，推出Spectrum X和Quantum X交换机。
6. 发布首个开放式人性机器人基础模型Isaac GROOT N1；并宣布与谷歌DeepMind和迪士尼研究院合作开发Newton开源物理引擎。

### 01、现场“开课”，

**黄仁勋：你们真的都搞错了**

自从号称训练只用了几百万美元的DeepSeek推理模型问世，世界就没有停止对英伟达的质疑。起先，黄仁勋不语。然后，他开始发声，在采访中和财报会议上表示推理时代仍然需要大量计算，仍然需要英伟达的力量。这次，他终于把这点摊开揉碎地说明了一番。

在发布会上，老黄拿出例子，让Llama3.3（LLM的代表）和DeepSeek R1（推理模型的代表）回答同一个问题：

“在我的婚礼上，需要7个人围坐同一桌。我的父母和岳父岳母不能挨着坐。此外，我妻子坚称她在我左手边的话，拍照更好看。同时，我需要坐在伴郎身边。我们怎么安排座位？如果我们邀请牧师和我们坐一起呢？”

看完这个问题，大部分人可能已经头大了。要回答它，不仅要识别其中包含多少个不同的需求，还要同时满足所有需求。有意思的是，最后又有一个进一步的问题，需要先回答主问题再补充这个问题的答案。

Llama 3.3非常简单粗暴，回答得很快，只用了439个tokens。但是，它的回答并不正确，未能满足所有要求。快、省但对于提问的人来说无用。

DeepSeek R1则反复思考，尝试了很多可能，反复检验答案，最终消耗了8559个tokens，才最终给出了答案。时间久，消耗大，但是给出的答案准确。

而每一个token生成的背后，都是整个模型的加载。推理模型更复杂，也就需要更多地计算。DeepSeek R1的参数规模达到6800亿，下一代有可能达到数万亿参数规模。

两相对比，DeepSeek R1比Llama 3.3多生成了20倍的tokens，计算需求高出150倍。“大模型推理是一种极限计算。”老黄表示。

通过这个对比，老黄很直观地告诉大家：推理模型也许预训练的时候消耗少，但推理起来可是实打实的吸金兽。英伟达GTC的官方博文中，把Tokens视为AI的语言和货币。

“去年，关于扩展定律Scaling Law，全世界几乎都预测错了。”老黄在台上再次强调。他进一步指出，如今扩展定律从一个变成了三个：预训练、后训练（微调）和推理。

那英伟达在推理时代要做什么呢？两方面：一方面，让芯片能在单位时间内处理更多tokens，另一方面，让单位算力的成本和能耗降低。

黄仁勋此前就在财报会议上表示，Blackwell就是为推理而生的，这次演讲中在说清楚推理模型为什么需要更多算力之后，黄仁勋也拿出图表，展开讲了讲这一点。

以Blackwell和Hopper做对比，都是1兆瓦功耗，Hopper数据中心每秒生成250万tokens。Blackwell数据中心提高了25倍，如果是推理模型，则比Hopper好40倍。

这让图表中出现了一个向上鼓的曲线，这个曲线正是黄仁勋想让各位AI制造商关注的“赚钱要点”。黄仁勋称，成本是AI输出的token，收益就是用户获得的token。如果纵轴是前者，横轴是后者，横轴扩张更多时——也就是收益比成本扩张更多时——一个漂亮的利润弧线就出现了。

为了强调Blackwell是为推理而生这一点，老黄甚至不惜“拉踩”Hopper，称：“当Blackwell开始大量出货的时候，就算你送Hopper，别人基本也不会要的。”

之前老黄总说，（英伟达AI芯片）买得越多越省钱，现在他更进一步，告诉大家，买得越多越赚钱。

### 02 软硬兼施，

**Blackwell超大杯与“AI工厂操作系统”Dynamo**

花了40分钟讲明白为什么英伟达依然能打，为什么说Blackwell是为推理而生之后，黄仁勋当然还得说说新产品。

首先是Blackwell Ultra，专为AI推理时代而打造，Ultra的后缀大家也不陌生了，超大杯。“我们专为这一刻设计了Blackwell Ultra，一个多功能平台，（利用它）可以高效地进行预训练、后训练和推理。”

其中GB300 NVL72在一个机架规模设计中连接了72个Blackwell Ultra芯片，并包含36个基于Arm Neoverse的Grace CPU。较上一代性能提升1.5倍，与Hopper相比收入潜力提高50倍。还是以DeepSeek R1为例，老款Hopper运行这个模型时每秒只能处理100 tokens，而GB300 NVL72每秒能处理1000 tokens。这意味着用户获得回答的速度大大提高。

而HGX B300 NVL16系统相比于Hopper一代，推理速度提升11倍，计算能力提升7倍，内存大4倍。

英伟达一直都有软硬兼施的策略，此前也针对自家的芯片做了不少优化（不过，DeepSeek的开源周展示的一些优化甚至比英伟达还强），这次黄仁勋也同步官宣了开源推理框架Dynamo。

黄仁勋将之称为“AI工厂的操作系统”。这样说可能有点抽象，具体来说，Dynamo像一个交通指挥官，帮助GPU之间实现更好的通信。对思考和生成可以进行独立优化，高效利用资源。如此一来，（还是回到演讲开头强调的token问题上）每秒就能产生更多token了。

不过，黄仁勋也表示，Hopper虽然也可以用Dynamo优化，但是效果不会那么明显。

为推理而生的Blackwell再加上为推理优化而生的Dynamo，就是强上加强，DeepSeek R1的吞吐量一下提高30倍。

### 03 下一代更好

**2028年还不够远，黄仁勋勾勒AI发展路径图**

除了现在，黄仁勋当然还得谈到未来。英伟达下一代AI芯片Vera Rubin首次走到台前，黄仁勋介绍，该名称来源于天文学家Vera Rubin（以暗物质研究著称）。

其中CPU Vera内容容量是前代的4倍多，内存带宽是前代的2倍多，而GPU Rubin讲配备299GB的HRM4。用老黄的话说就是“几乎所有细节都是新的”。

这一代Grace Blackwell（GB）将在今年下半年发货，Vera Rubin将在2026年下半年发货。黄仁勋也预告了Vera Rubin的超大杯，Rubin Ultra，对比GB300性能提升13倍，预计2027年下半年发货。

除此之外，连Vera Rubin之后的下一代AI芯片架构也被揭露，它被命名为Feynman，这个名字同样取自于一位科学家，对量子计算领域有突出和贡献的Richard Phillips Feynman。黄仁勋预告，Feynman甲沟将于2028年登场。

此外，值得注意的是，在演讲一开始，黄仁勋给出了AI的发展路线图，从2012年深度学习突破的起点AlexNet开始，经历Perception AI（感知AI，这个阶段AI主要用于理解数据，如识别语音、图片等）、Generative AI（生成式AI，也就是现阶段的以ChatGPT为代表的技术）。

接下来，已经看到苗头的是Agentic AI（代理AI），从简单的数据生成到执行任务。最终，AI的终极目标是Physical AI（物理AI），实现从软件到硬件、从虚拟到现实的跨越。让AI具备物理行动能力，如机器人和自动驾驶技术的发展。

英伟达作为AI计算的核心玩家，显然希望引领这一进程。对物理AI这部分的具体展开，在黄仁勋的此次演讲中占比并不算高，但作为压轴出现，足见其重要程度。

舞台上出现了《星球大战》中的小机器人Blue，它在舞台上走来走去、摇头晃脑，看起来充满好奇心，不得不说看起来就非常灵动。这个机器人搭载了英伟达Isaac GR00T N1，号称是全球首个开源且完全可定制的人性机器人基础模型。模型包含双系统架构，一个系统负责快思考，另一个负责慢思考。据英伟达介绍，该模型能轻松掌握抓取、移动等复杂人物。

与此同时，黄仁勋还宣布正在与谷歌DeepMind和迪士尼研究院合作下一代开源仿真物理模型Newton，专为机器人开发而生。“通用性机器人的时代已经到来。”

### 04 老黄委屈，

**英伟达推出好产品还远远不够**

英伟达的高速增长也一直伴随着“泡沫”担忧，很长的一段时间，这家公司不断推出新的产品，但市场波动时有发生。很多次财报发布时，明明业绩全线飘红，黄仁勋也大表信心，股价还是会抖三抖。

“我们发了新东西，但人们立刻就会说，好，然后呢？这放在任何公司身上都不是正常的。”这次，黄仁勋很少见地在GTC的舞台上倒了点苦水：“这不是买个笔记本电脑”。他表示，这既需要计划，也需要资源和人，规划是以几年为计的。

也许这也解释了为什么黄仁勋这次演讲持续了两个半小时（去年不到两小时），为什么他一口气掏出这么多成果，为什么AI芯片连2028年的下下代都透底了，为什么在最后拿出了AI发展路径的最后一站“物理AI”的最新成果。

老黄这次该讲的、能讲的都讲了，尽力了。至于人们还会不会问“然后呢”，他也管不了了。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。