---
title: '曾毅：从科学和社会的视角对当代人工智能的反思'
date: 2024-08-11
author: ByteAILab

---

来源：[见地沙龙](https://mp.weixin.qq.com/s/V22xDtCP9TiWOrgclxtoAw)

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1723183929651/FpN38QjKVwb2lL_GTCjBcCWvkg2L.jpg)

曾 毅 人工智能科学家，中国科学院自动化研究所研究员

本文为曾毅先生在2023见地年会的发言，原主题为《从科学和社会的视角对当代人工智能的反思》。

我讲几个关键词。

---


**第一个关键词是“自大”**。

现在对于人工智能对世界的描述是用什么来描述的？是用X来描述的，就是参数。现在的人工智能研究，参数是百亿的、千亿的、万亿的，但有统计学家说，统计学就是用200个参数来描述人工智能学家用几百亿的参数才能做的事情。

这给我们很大的反思：当人工智能研究有万亿的参数来描述一个世界的时候，这个万亿的参数实际上就是万亿的X，代表万亿种变化，也代表着万亿的不确定性。既然它有万亿个不确定性，也有万亿个可能性。这个时候，它实际上带给我们的是万亿个未知，而这种未知是无限的想象还是无限的风险，我觉得是非常危险的地方。所以，人工智能研究者，实际上将这种不确定性、风险描述成了机遇，这是非常危险的。

**第二个关键词是“说谎”**。

人工智能是如何开始的？在一个屋子里，有一个机器，有一个人，当你无法区分你的对话对象是人还是机器的时候，说明这个机器达到了人类水平的智能，这是图灵提出的图灵测试。所以人工智能起源于“欺骗”，它通过欺骗达到衡量智能的水平。但图灵从来没有说过，当人工智能达到足以欺骗人类的时候，你应当用这种服务去欺骗人类。但这却是现在的人工智能天天在做的事情，就是用看似智能的事情来欺骗人类。

比如说到ChatGPT有什么样的能力，有人说它已经达到了人类水平。但是搞人工智能的人很少讲，当它的正确率远远超过人类的时候，比如做一件事，人的正确率只有90%，它可以做到99.9%，但当你看剩余00.1%的时候发现，那些错误不是人类会犯的错误，人工智能会犯。人工智能的研究者，特别是产业的推动者，绝不希望你看到这一面。

另一个例子，我说“写一个毛笔字”是几个字，它说“‘写一个毛笔字’是4个字；抱歉抱歉，我之前回答有误，‘写一个毛笔字’实际上是5个字”。我以为它明白了，我让它再说，“重新计算，‘写一个毛笔字’实际上是6个字”，我说再数，它说“我再次核对，确实是5个字”。我说再数，它说“重新计算后，实际上是5个字”，好像真的明白了，我说不对，再数，“重新计算以后，实际上是6个字”，我说还不对，“我再次核查，确实是6个字”。

人工智能现在达到了看似智能的信息处理水平，在数据量足够大的时候，它的输出在某些时候惊艳了你，但是惊艳你的部分恰恰是基于大量数据的统计，而那一部分统计可能是你不熟悉的，特别是超出你的领域的时候，它给出的反馈可能是你并不熟悉的，或者是你并不在行的部分。

...

本文链接：[https://www.aixinzhijie.com/article/6846388](https://www.aixinzhijie.com/article/6846388)
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。