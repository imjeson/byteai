---
title: '外滩大会上，我们看到了人工智能五年后的样子'
date: 2024-09-10
author: ByteAILab

---

在一些悲观者看来，人工智能的发展似乎变慢了。

2022 年底，ChatGPT  发布，五天用户注册超过百万，两个月后月活用户超过 1 亿，以此为起点，几乎每家科技大公司都卷入这场生成式 AI 的风暴当中，几乎每个科技创业者也都试图寻找起飞的机会，半年融资两轮、一年估值破 10 亿美元的 “黄金时代” 似乎又回来了，a16z 创始人 Marc Andreessen 2011 年提出「软件在蚕食世界」（Software is eating the world），在 2023 年，大家谈论的话题变成了「人工智能蚕食世界」（AI is eating the world）。

---


然而，等到 2024 年，世界似乎依然是那个世界，我们的日常生活几乎没有因为人工智能发生任何变化，应用层面的 “iPhone 时刻” 始终只出现在各类演讲里，而非我们的手头上。

在技术端，大模型本身的能力也出现了诸多问题，GPT 5.0 迟迟未能发布，这让大家疑惑 Scaling Law 曲线是否正在放缓，进而质疑 Transformer 架构本身的潜力；大模型的「幻觉问题」也始终影响应用层面的落地，甚至有论文认为经过校准的语言模型必然会出现幻觉，与数据质量或者算法架构本身无关 —— 换言之，这几乎是个不可能解决的问题。

乐观者则认为，这些只是当技术爆炸真正进入日常世界时候，必然出现的缓冲期。

技术爆发时候，我们往往过于兴奋，以为未来正加速到来，不过，世界本身有自己的运作规律，需要基础设施来承接，需要应用层面来落地，甚至需要法律、道德和伦理层面做好更多准备。在外滩大会上，他们为自己的乐观能够找到充足的理由。

九月初，外滩大会在上海举办，上海黄浦世博园区也成了看见 AI 未来趋势的最重要窗口。有人在讨论它是否能够疏解孤独，也有人在讨论能否帮助缓解全球变暖，在展区里，依然有着众多带着创造力的人，来展示他们用 AI 设想的未来。我们对 AI 的悲观或者乐观，背后都隐含着我们对它的期待。

每个问题都是 AI 继续进化的契机。在外滩大会上，我们能够看到人工智能依然在发展，在论坛的讨论里，在每个展厅里，我们能够看到五年后 AI 的样貌。

**「算力军备竞赛」可能不会结束， 但平衡成本和提升效率越发重要**

2020 年，OpenAI 在一篇论文里提出 Scaling law，大意是大模型的性能与模型的具体结构 —— 深度、宽度和层数 —— 基本无关，主要由计算量、模型参数量和训练数据量三者的大小有关。

这一论断被称为 AI 领域的「摩尔定律」，也因为 OpenAI 的成功而成了很多从业者信奉的圭臬。在这一信念指引下，大模型的发展向着大算力、大参数和大数据的方向发展。先前的 AI 发展主要基于对各类模型的优化，而 Scaling Law 代表着一种新的范式：倘若有足够大的算力和数据，我们便能够解决人工智能发展的问题。

算力军备竞赛也由此开始。李飞飞团队新近发布的《人工智能指数报告》显示，最新人工智能模型的训练成本已经达到历史新高。GPT-4 的训练过程耗费了约 7800 万美元的计算资源，谷歌的 Gemini Ultra 模型的训练成本更是高达 1.91 亿美元。微软也启动「星际之门」超级计算机计划，预计投资将达到 1150 亿美元，而谷歌也迅速表示将在算力方面有更慷慨的投资。

烽火燃不息，倘若我们想要发展更好的大模型，在技术上继续有所突破，那么这场军备竞赛便不可能结束。不过，倘若目标是应用落地和商业闭环，那么落地部署的效率和成本与技术本身一样重要。于是，优化算力效率，提高数据质量，成了各个企业关注的焦点。

企业需要关注如何通过技术创新来实现算力的经济实用，以在不牺牲性能的情况下，控制投入成本，而异构计算是实现这一目标的关键技术之一。

异构计算是一种将不同类型和架构的计算单元，如 CPU、GPU、DSP、ASIC、FPGA 等，整合到一个系统中以提高计算性能和能效的技术，能够同时处理多种类型的计算任务，如图形处理、科学计算和 AI 推理，这使得它们非常适合现代数据中心和 AI 应用的需求。

异构计算优势明显。它可以协同多种计算单元，显著提高处理速度和系统吞吐量，尤其适用于大规模并行计算任务，并能将任务分配给最适合的计算单元执行，可以优化能源利用效率，降低数据中心的能耗。同时，异构计算支持灵活的硬件配置和软件编程，能够根据需求轻松扩展系统能力，开发者也能够根据算法需求选择最合适的硬件平台。

未来五年，异构计算需要逐步解决现有的问题，才能走向普及。异构计算需要开发者具备跨平台的编程和优化技能，缺乏统一的编程框架和标准，增加了开发难度，导致开发效率受限。此外，虽然长期来看成本更低，但初期硬件投资和研发成本相比现有成熟方案依然很高，需要大公司率先投入，促进应用。

**比起大模型，小模型更可能诞生「大应用」**

大约十五年前，移动互联网开始繁荣，也迎来了创业的黄金时代。与之相比，AI 时代创业更加艰难，首先因为成本更高，需要算力、数据、电力等外界条件，训练大模型所需要的资金，几乎没有草根创业者能够负担。在大模型领域，很可能会出现「赢家通吃」，最终只剩下几个主要的模型厂商。

不过，AI 是个庞大的生态，在算法、算力、数据和系统等领域都有着大量机会。

在外滩大会上，一个被讨论很多的机会是数据服务商。AI 大模型的性能在很大程度上取决于训练数据的规模和质量。数据数量的增加可以提供更多的样本，使模型能够学习到更多的特征和模式。如今 AI 发展的重要瓶颈，是现实世界的数据接近枯竭，而合成数据依然存在着很多问题，比如无法反映物理世界的复杂情况等。

于是，一批新型的数据服务商便可能成为 AI 时代的「卖水人」。它需要以更高的效率完成包括数据清洗、数据标注、数据整合和数据安全措施等方面的工作，确保数据的来源可靠、处理过程透明和结果可验证。高质量的数据为 AI 模型提供学习的基础，从而形成数据飞轮，推动其不断进化和改进。

更大的创业机会在应用端，尤其是在行业领域。不过，通往行业落地的大门可能并非大模型，而是小模型 / 端侧模型。

严格来说，「小模型」与「端侧模型」并不等同。小模型通常指的是参数规模远少于 GPT-3 或 Llama-13B 的大语言模型，如 1.5B、3B、7B 等；「端智能」则指的是部署在手机、电脑等用户设备上的模型，通常计算资源受限，无法直接运行大模型，于是也要特别设计新的模型。二者目标不同，不过终端设备能够流畅运行的，往往都是小模型，因此存在很多重合，我们也不做细致的区分。

小模型虽然参数规模小，不过往往专注于某一领域和任务的设计和优化，在这些方面可以达到甚至超过大模型的性能，如 Mistral-7B 模型在某些基准测试中超越了参数量更大的模型，显示出小模型在特定任务上的优势。

因为算力和能源消耗低，小模型更适合落地应用。在端侧，苹果在 iPhone 上使用的 DCLM 模型参数量为 70 亿。傅盛也曾提到，企业专用模型大概只需要百亿参数 —— 作为对比，GPT 4 的参数量高达 1.7 万亿。

小模型的发展将带来端智能的普及，未来五年率先落地的可能是一批「博士」水平的专业 AI。外滩大会上已经能看到不少很有潜质的产品雏形，涉及医疗、能源、教育等领域。借助这些专门化的 AI 工具，企业可以更容易地将 AI 技术集合到业务流程中，在行业中落地应用。

行业侧的落地应用也将有助于 AI 本身的进化。各个领域存在大量数据，在利用 AI 优化决策、提高效率的同时，AI 也能获得更高质量的数据，模型和算法也会不断演进与改变，从而推动整个人工智能领域的发展与成熟。

**端智能可能是大模型的终局，但手机智能未必是**

如今提到端侧模型，往往指的是手机，因为这是我们随手可触及的算力最强的设备，不过，手机可能只是端智能的过渡阶段。

手机智能的瓶颈很明显，首先是算力不足，但更重要的可能是内存不足。相比云端服务器，手机等设备的内存容量和存储空间都要小很多，但即便是小模型依然需要占用大量空间。

内存之外，能源和功耗问题也是一个问题。AI 计算过程功耗巨大，很容易导致电池电量不足，设备发热，甚至影响系统总体稳定性。

现在的解决方案一方面是提升手机性能，一方面则是设计更小的模型，以确保在有限的内存、算力、功耗限制下高效运行，如苹果便从 0 构建了专门的小模型，而非对现有的大模型来裁剪。

不过，长期来看，或许我们会有新的 AI Agent，成为人工智能时代下的新型终端形态。

我们期待的 AI Agent 并非简单地执行指令，而更像是具身智能理念在人工智能领域的具体体现，具有更高级别的自主性和智能，是能够在环境中自主行动、感知并做出决策的智能实体。

这意味着，AI Agent 不仅能够处理虚拟任务，还能够在物理世界中执行动作，提供更加丰富和直观的用户体验。这种结合也推动了人工智能在多个领域的创新应用，如自动驾驶汽车、智能家居、工业自动化等。

我们与 AI Agent 的交互方式也将发生新的变化。从早期的机器语言到图形用户界面（GUI）、手势控制，再到现在的全模态自然语言交互，人机交互的方式不断演进。全模态交互意味着机器可以通过多种方式（如语音、视觉、触觉等）理解和响应人类的指令，使得交互更加自然和直观。

随着交互方式的演进，机器不再仅仅是工具，而是能够提供陪伴、协助和情感支持的伙伴；应用入口也不再局限于传统的操作系统或应用程序界面，而是可以通过多种设备和场景进行交互。

这或许不会在 5 年的时间里发生，不过三到五年之后，更多人会拥有可以支持端
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。