---
title: '人工智能在面对人类智慧与创造力时显得苍白'
date: 2025-06-18
author: ByteAILab

---

加里·马库斯说得对——正如我们许多人多年所言，仅仅扩大计算规模无法解决生成性人工智能的问题（当十亿美元的人工智能在儿童能够解决的难题面前崩溃时，值得重新思考这一炒作，2023年6月10日）。

---
但他没有提到一个真正的原因：为什么一个七岁的孩子能够解决打汉诺塔难题，而计算机却做不到？我们是有身体的动物，生活在这个世界中。所有生物都是为了探索而生，从出生开始，我们用所有的感官进行探索。这让我们对世界及其万物有了模型。我们可以从少量实例中推断出一般真理，而这正是计算机所无法做到的。

一个简单的例子：要教会一个大型语言模型“猫”，你必须展示成千上万张猫的个体图像——它们可能在树上、在箱子里，或藏在一卷地毯里。即便如此，如果它遇到一只正在玩浴缸塞子的猫，它可能无法认出那是一只猫。而人类儿童只需观察两三只猫，并与它们互动，就能终其一生地识别任何猫。

除此之外，这种有身体的、进化而来的智力使我们在能量效率上极具优势，相较于计算机更加高效。驱动自动驾驶汽车的计算机使用的能量至少在千瓦级别，而一个人类驾驶者所消耗的能量只需二十多瓦的可再生能源——而且我们不需要额外的培根三明治来记忆新的路线。在气候紧急的时刻，这一行业巨大的能源需求或许让我们更能意识到与欣赏人类智能的非凡经济性、多样性、可塑性、创造力和灵巧性——这些品质是我们每个人凭借活着的权利所拥有的。

希拉·海曼
剑桥大学Minderoo科技与民主中心顾问委员会成员

我并不感到惊讶，苹果的研究人员发现了尖端人工智能模型中的“根本局限性”（尖端人工智能在复杂问题面前遭遇“完全准确度崩溃”，研究发现，2023年6月9日）。人工智能以大型推理模型或大型语言模型（LLM）的形式远未能够“推理”。这可以通过问ChatGPT或类似的模型一个简单的问题来检验：“如果9加10是18，那么18减10是多少？”今天的回答是8。其他时候，我发现它根本没有给出明确的答案。这突显了人工智能并不进行推理——目前，它是一种结合了蛮力和逻辑程序的系统，基本上就是用逻辑来减少蛮力的方法。一个应该更广泛宣传的术语是ANI——人工狭义智能，它描述了像ChatGPT这样的系统，这些系统在总结相关信息和重新表述句子方面表现优异，但距离能推理还有相当远。

但需要注意的是，LLM被询问相似问题的次数越多，它提供合理答案的可能性就越大。然而，这并不是推理，而是模型训练的结果。

格雷厄姆·泰勒
澳大利亚新南威尔士州莫纳瓦尔

你对今天在《卫报》上所读的任何内容有意见吗？请给我们发送电子邮件，我们将考虑在我们的读者信件部分发表。

探索更多关于这些主题的内容：人工智能（AI）、计算机、人类生物学、苹果、ChatGPT、神经科学、信件

分享
重复使用此内容
---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。