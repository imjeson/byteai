---
title: '阿联酋的TII用新的架构彻底改变了AI语言模型'
date: 2024-08-13
author: ByteAILab

---

The Falcon Mamba 7B是全球性能排名第一的开源State Space Language Model（SSLM），由Hugging Face独立验证SSLM具有低内存成本，不需要额外内存即可生成任意长度的文本块Falcon Mamba 7B也胜过传统的变压器架构模型，如Meta的Llama 3.1 8B和Mistral的7B新模型反映了阿布扎比在AI研究和开发方面的创新和开拓性方法

科技创新研究所（TII）是阿布扎比先进技术研究委员会（ATRC）的领先全球科学研究中心和应用研究支柱，发布了其Falcon系列中的新大语言模型，Falcon Mamba 7B。![图片](https://ai-techpark.com/wp-content/uploads/2024/08/UAE’s-TII-960x540.jpg){ width=60% }

---
这一新模型是全球性能排名第一的开源State Space Language Model (SSLM)，由Hugging Face独立验证。

作为Falcon的第一个SSLM，与以前所有使用基于变压器的架构的Falcon模型不同。这个新的Falcon Mamba 7B模型是研究所正在进行的开拓性研究的又一个例子，以及它开发的突破性工具和产品以开源格式提供给社区的示例。

ATRC秘书长、阿联酋总统战略研究和先进技术事务顾问Faisal Al Bannai表示：“Falcon Mamba 7B标志着TII连续第四次获得AI模型排名第一，强化了阿布扎比作为全球AI研究和开发中心的地位。这一成就凸显了阿联酋在创新方面的坚定承诺。”

对于变压器架构模型，Falcon Mamba 7B在HuggingFace的新推出的基准上胜过了Meta的Llama 3.1 8B、Llama 3 8B和Mistral的7B。与此同时，对于其他SSLMs，Falcon Mamba 7B在旧基准中击败了所有其他开源模型，并将成为HuggingFace的新更严格基准排行榜上的第一个模型。

TII首席执行官Najwa Aaraj表示：“技术创新研究所持续推动技术的边界，用其Falcon系列AI模型。Falcon Mamba 7B代表着真正的开创性工作，为未来的AI创新铺平道路，将增强人类能力并改善生活。”

State Space模型在理解随时间演变的复杂情况方面非常出色，比如整本书。这是因为SSLMs不需要额外内存来处理这样大量的信息。

另一方面，基于变压器的模型非常擅长记住和使用它们之前处理过的信息序列。这使它们非常擅长像内容生成这样的任务，然而，因为它们将每个单词与每个其他单词进行比较，这需要大量的计算能力。

SSLMs可以在估计、预测和控制任务等各个领域找到应用。类似于基于变压器的模型，它们也在自然语言处理任务中表现出色，并可应用于机器翻译、文本摘要、计算机视觉和音频处理等领域。

TII AI Cross-Center Unit代理首席研究员Hakim Hacid表示：“随着我们推出Falcon Mamba 7B，我为TII培养其发展的协作生态系统感到自豪。这次发布代表了一个重大的进步，激发了新的视角，进一步激发了智能系统的探索。在TII，我们正在推动SSLM和变压器模型的边界，以激发生成式AI中进一步的创新。”

Falcon LLMs已经被下载超过4500万次，证明了这些模型的出色成功。Falcon Mamba 7B将在TII Falcon License 2.0下发布，这是一种宽容的基于Apache 2.0的软件许可，其中包括促进AI负责任使用的可接受使用政策。有关新模型的更多信息，请访问FalconLLM.TII.ae。

---

注意：Title、Date、Body 三个部分的内容，放入到对应的位置。最后只需要输出为Makedown源文件格式内容。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。