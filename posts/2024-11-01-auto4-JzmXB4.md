---
title: '当AI取代真相，大模型如何一步步诱骗了人类的文明？'
date: 2024-11-02
author: ByteAILab

---

文章来源：[追问nestquestion](https://mp.weixin.qq.com/s/LN0K-p-4eYDbaNf0gByovQ)

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/8FD7B96F5E34993C64020C0DB54F4C00/1730426781892/Fv7s-fZCEso4Hn0rqWiwTr9Jj2f_.png)

如今，人们选择餐厅，多半会打开app搜索一番，再看看排名。然而美国奥斯汀的一家餐厅Ethos的存在证实这种选择机制多么不可靠。

---
Ethos在社交媒体instagram宣称是当地排名第一的餐厅，拥有7万余粉丝。

实际上，这家看起来很靠谱的餐厅根本不存在，食物和场地的照片都由人工智能生成。可它家发布在社媒上的帖子却得到了数千名不知情者的点赞和评论。大模型通过视觉形式误导公众认知，引发了人们对其潜在影响的深刻思考。

**▷** 图1：图源：X

大型语言模型（LLMs），由于其幻觉及涌现特性，总让人们忧虑其传播虚假信息的可能。然而这一现象背后的机理我们却不甚了解。大模型究竟如何改变人类的心理机制，让人们越来越难以判断一件事情真实与否，并失去对专业机构和彼此的信任？

2024年10月发表的一篇名为“Large language models (LLMs) and the institutionalization of misinformation（大语言模型与虚假信息的制度化）”的研究[1]，点出了大模型和虚假信息的关系：它比我们所了解的更为深远与复杂。

**▷** Garry, Maryanne, et al. "Large language models (LLMs) and the institutionalization of misinformation." Trends in Cognitive Sciences (2024).

### AI生成的虚假信息影响深远

类似开篇提到的虚假餐厅的例子，现实生活中发生了不止一次。2023年11月，搜索引擎Bing曾因为爬取了错误信息，而针对“澳大利亚是否存在”的问题，给出了如下图所示荒谬的回复。（事后官方很快对该问题进行了修复。）

**▷** 图2：Bing截图；图源：Bing

上面的例子，还可视为程序的bug，而普林斯顿的一项研究则系统性说明了AI生成数据的影响不止如此[2]。该研究发现，截止24年8月，至少5%的英文维基百科页面是由AI生成的，相对而言德语、法语和意大利语文章的占比较低。

维基百科（Wikipedia）是人工智能训练数据的重要来源，且被普遍视为权威的信息来源。尽管AI生成的内容并不一定都是虚假信息，但该研究指出，被标记为AI生成的维基百科文章通常质量较低，并具有较明显的目的性，往往是自我推广或对有争议话题持特定观点。

### AI生成的虚假信息如何利用了判断真假的启发式弱点

虽然虚假信息被发现后很快会被纠正，但如同小时候听过的“狼来了”的故事，一次次的接触虚假信息，会让磨损我们彼此间的信任。

我们判断一件事情是否为真时，有两种不同的思考方式，一是...
---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。