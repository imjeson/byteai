---

title: 'AI可能导致持有其主观意识不同观点的人之间出现“社会分裂”'
date: 2024-11-18
author: ByteAILab

---

重要的“社会分裂”可能会在认为人工智能系统具有主观意识的人和坚持这项技术无感觉的人之间出现，一位领先的哲学家表示。

---
这些评论来自伦敦政治经济学院哲学教授乔纳森·伯奇，正值各国政府准备本周在旧金山聚集加速制定规范，以应对人工智能最严重的风险。

上周，一群跨大西洋的学者预测，人工智能系统意识的曙光可能在2035年出现，并且有人表示，这可能导致“子文化之间彼此认为在计算机程序是否应该像人类或动物一样享有类似福利权益这一问题上犯下了巨大错误”。

伯奇表示，他“担心会出现重大社会分裂”，因为人们对于人工智能系统是否真的具有痛苦和快乐等情感能力存在分歧。对人工智能中主观意识后果的辩论回响着科幻电影，如史蒂芬·斯皮尔伯格的《AI人工智能》（2001）和斯派克·琼斯的《她》（2013），在这些电影中，人类正在努力应对人工智能的情感。

美国、英国等国家的人工智能安全机构将于本周与科技公司会面，以制定更强大的安全框架，因为技术正在迅速进步。不同国家和宗教如何看待动物主观意识已经存在显著差异，比如印度，那里有数亿素食主义者，而美国是世界上最大的肉类消费国之一。对人工智能主观意识的观点可能沿着类似的路线分化，而沙特阿拉伯等神权国家的看法可能与世俗国家不同。这个问题也可能在家庭内部引发紧张，那些与聊天机器人或甚至已故亲人的人工智能化身建立亲密关系的人，可能与认为只有血肉生物具有意识的亲人发生冲突。

伯奇是动物主观意识方面的专家，他为抵制章鱼养殖领域的禁令做出了开创性工作，他是一项涉及纽约大学、牛津大学、斯坦福大学以及Eleos和Anthropic AI公司的研究的合著者，该研究称AI系统具有自己的利益和道德意义的前景“已不再只是科幻或遥远的将来问题”。他们希望开发人工智能的大型科技公司开始认真对待这一问题，通过确定其系统的主观意识来评估他们的模型是否能够感到快乐和痛苦，以及它们是否可以受益或受害。

{...}

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。