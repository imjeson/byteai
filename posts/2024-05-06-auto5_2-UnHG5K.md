---

title: 'ICLR 2024 Spotlight | 负标签挖掘助力基于CLIP的分布外检测任务'
date: 2024-05-07
author: ByteAILab

---

在机器学习模型日益应用于开放世界场景中，如何有效识别和处理分布外（Out-of-Distribution, OOD）数据成为一个重要研究领域[1]。分布外数据的存在可能导致模型过度自信和错误预测，这在安全关键应用（如自动驾驶和医疗诊断）中尤为危险。

---
因此，发展一种有效的OOD检测机制，对于提高模型在实际应用中的安全性和可靠性至关重要。

传统的OOD检测方法主要集中在单一模态，特别是图像数据上，而忽视了其他潜在有用的信息源，例如文本数据。随着视觉-语言模型（VLMs）的兴起，它们在多模态学习场景中展示了强大的性能，特别是在处理需要同时理解图像和相关文本描述的任务中表现出色[2]。现有的基于VLMs的OOD检测方法[3,4,5]仅仅使用了ID标签的语义信息，忽略了VLMs模型强大的零样本性能，以及VLMs可以理解非常广阔的语义空间。基于此，我们认为VLMs在OOD检测中有巨大的未开发潜力，尤其是它们可以综合利用图像和文本信息来改善检测效果。

这篇文章围绕三个问题展开：

1.非ID标签的信息是否对零样本OOD检测有帮助？

2.如何挖掘出对零样本OOD检测有利的信息？

3.如何利用挖掘出的信息进行零样本OOD检测？

在这项工作中，我们提出了一种名为NegLabel的创新方法，该方法利用VLMs进行OOD检测。NegLabel方法特别引入了“负标签”机制，这些负标签与已知ID类别标签具有显著的语义差异，通过分析比较图像与ID标签和负标签的亲和性，NegLabel能够有效地区分出属于分布外的样本，从而显著增强模型对OOD样本的识别能力。

实验表明，NegLabel在多个零样本OOD检测基准测试中都达到了优越的性能，在大规模数据集如ImageNet-1k上能够达到94.21% AUROC和25.40% FPR95。与以往基于VLMs的OOD检测方法相比，NegLabel不仅不需要额外的训练过程，而且展示了更优越的性能。此外，NegLabel在不同的VLM架构上都表现出了优异的通用性和鲁棒性。

![image](https://image.jiqizhixin.com/uploads/editor/288bb825-d10d-40ce-9414-ce6fd6a05b6b/1714968059633.png)

Ø论文链接：[https://arxiv.org/pdf/2403.20078.pdf](https://arxiv.org/pdf/2403.20078.pdf)

Ø代码链接：[https://github.com/tmlr-group/NegLabel](https://github.com/tmlr-group/NegLabel)

接下来将简要地向大家分享我们近期发表在 ICLR 2024 上的分布外检测方向的研究结果。

### 预备知识
![image](https://image.jiqizhixin.com/uploads/editor/4946376a-da03-49cd-9f5d-ec05dd757969/1714968073950.png)

### 方法介绍
NegLabel的核心就是引入了“负标签”机制，这些负标签与已知ID类别标签具有显著的语义差异，通过分析比较图像与ID标签和负标签的亲和性，NegLabel能够有效地区分出属于分布外的样本，从而显著增强模型对OOD样本的识别能力。

![image](https://image.jiqizhixin.com/uploads/editor/9f0ffe51-c729-4b23-a435-2e857090ab3b/1714968096691.png)

图1. NegLabel的总览图

1. 如何选取负标签？
![image](https://image.jiqizhixin.com/uploads/editor/699257a2-007d-48b6-a41f-feded772ccdb/1714968116303.png)
![image](https://image.jiqizhixin.com/uploads/editor/10cf9d3a-1f4b-4a46-ac74-f8d38d43f4fb/1714968124573.png)

2. 如何利用负标签来进行OOD检测？
![image](https://image.jiqizhixin.com/uploads/editor/3e8ee5a6-f653-4407-8362-a87133ab8e96/1714968628543.png)
![image](https://image.jiqizhixin.com/uploads/editor/84d94bfd-8c46-405f-8f4a-4f2ca281cd2f/1714968659166.png)

3. 如何理解负样本可以促进零样本OOD检测？
![image](https://image.jiqizhixin.com/uploads/editor/af0c4abb-1ec6-466a-b1e0-6ee93c83ce93/1714968675602.png)

### 实验结果
我们的研究工作提供了多维度的实验结果以理解我们提出的方法性能及底层机理。

如下表所示，与诸多性能优良的基准方法和先进方法相比，本文提出的方法可以大规模数据集（如ImageNet）上在其基础上达到更优的分布外检测效果。

![image](https://image.jiqizhixin.com/uploads/editor/2d42d894-1cca-4298-b0da-4a65a4eb76e9/1714968702265.png)

此外，如下表所示，本文的方法在ID数据发生域迁移时有着更好的鲁棒性。

![image](https://image.jiqizhixin.com/uploads/editor/0d1ada12-10b1-4ce4-bf0a-c7bfc2ed006e/1714968706757.png)

在下列两个表格中，我们对NegLabel的各个模块还有VLMs的结构进行了消融实验。左表可以看出，NegMining算法和Grouping策略都可以有效提升OOD检测的性能。右表展示了我们提出的NegLabel算法在不同结构的VLMs有着良好的适应性。

![image](https://image.jiqizhixin.com/uploads/editor/0451acbc-578e-47e1-a51c-43c101bf28a3/1714968714440.png)

我们还对不同输入图像对于ID标签和负标签的亲和度进行了可视化分析，更多详细的实验和结果请参考原文。

![image](https://image.jiqizhixin.com/uploads/editor/3f290bf8-c0b5-467a-80b0-fb89b6033ca5/1714968720834.png)
![image](https://image.jiqizhixin.com/uploads/editor/4595a66d-30cf-4d79-816d-0a738b659ab6/1714968726456.png)

参考文献

[1] Hendrycks, D. and Gimpel, K. A baseline for detecting misclassified and out-of-distribution examples in neural networks. In ICLR, 2017.

[2] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal,Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, 2021.

[3] Sepideh Esmaeilpour, Bing Liu, Eric Robertson, and Lei Shu. Zero-shot out-of-distribution detection based on the pre-trained model clip. In AAAI, 2022.

[4] Yifei Ming, Ziyang Cai, Jiuxiang Gu, Yiyou Sun, Wei Li, and Yixuan Li. Delving into out-ofdistribution detection with vision-language representations. In NeurIPS, 2022a.

[5] Hualiang Wang, Yi Li, Huifeng Yao, and Xiaomeng Li. Clipn for zero-shot ood detection: Teaching clip to say no. ICCV, 2023.

[6] Christiane Fellbaum. WordNet: An Electronic Lexical Database. Bradford Books, 1998.
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。