---
title: '分析 1400 万篇论文发现：“AI 味”非常浓，中国使用 LLM 比例高达 35%'
date: 2024-06-28
author: ByteAILab

---

近日，来自德国图宾根大学Hertie脑健康人工智能研究所、图宾根人工智能中心的研究团、美国西北大学的研究者发布了一篇名为《通过多余词汇探究学术写作中 ChatGPT 的使用》（Delving into ChatGPT usage in academic writing through excess vocabulary）的论文。

论文通过细致的语言分析提出了一个惊人的结论：ChatGPT 等大语言模型辅助写作对科学文献产生了的影响，甚至超过了 COVID-19 疫情对学术写作的影响。

---


论文“AI味”有点浓：2024至少10%的论文使用了LLM

自OpenAI在2022年11月发布ChatGPT以来，学术文献的写作风格“AI味”变得有点浓，尤其是2024年。

“我们仅分析了出版年份从2010年到2024年的论文，得到了14182520篇摘要供分析。”该论文将分析了 PubMed 图书馆中超过 1400 万篇2010至2024年生物医学摘要的语料库，跟踪了过去十年科学写作的变化。

研究者惊讶地发现，至少10%的2024年发布的研究论文在撰写过程中使用了大型语言模型（如ChatGPT）进行辅助。在某些特定领域和国家，这一比例更是高得惊人。

研究人员首先确定了2024年相比以往年份显著更频繁出现的词汇。这些词汇包括 ChatGPT 写作风格中典型的许多动词和形容词，比如 “深入挖掘”、“复杂”、“展示” 和 “突出” 等。

通过分析词汇使用频率的变化，研究人员注意到，自ChatGPT发布以来，许多特定的风格词汇，如“delves（钻研）”“showcasing（展示）”“underscores（强调）”等词汇的使用频率显著增加，这反映出科学家们在撰写论文时，越来越多地借助ChatGPT来润色和修改文本。

论文采集了3个真实的 2023 年摘要的示例，来说明了这种 ChatGPT 风格的摘要语言表达方式：

根据这些具备AI生成色彩的标志词，研究人员估计在2024年，AI 文本生成器影响了至少10% 的所有 PubMed 摘要。

有趣的是，论文中研究者以新冠病毒等词汇对学术论文的影响对AI生成的影响做了对比。

发现在某些情况下，ChatGPT等AI生成工具给学术文献写作带来的影响，甚至超过了 “Covid”、“流行病” 或 “埃博拉” 等词汇在其所处时期的影响。 

...

LLM 真的可靠吗？研究者：需重估AI辅助论文写作的规则

科学家使用LLM辅助写作，是因为LLM可以提高文本的语法、修辞和整体可读性，帮助翻译成英文，并快速生成摘要。

然而，LLM 可能会捏造事实、强化偏见，甚至进行抄袭。

论文指出：“LLM因编造参考文献而臭名昭著, 提供不准确的总结，并做出看似权威、令人信服的虚假陈述。虽然研究人员可能会注意到并纠正LLM辅助的自己工作摘要中的事实错误，但发现LLM生成的文献综述或讨论部分中的错误可能更难。”

此外，LLM 还可以模仿训练数据中的偏差和其他缺陷，甚至是彻头彻尾的抄袭，这种同质化会降低科学写作的质量。该研究表明，尽管LLM存在以上种种限制，但 LLM 在学术写作中的使用率仍在上升。

学术界应该如何应对这一发展？一些人建议使用检索增强型 LLM，从可信来源提供可验证的事实或让用户向 LLM 提供所有相关事实，以保护科学文献免于积累细微的不准确性。其他人认为，对于某些任务，如同行评审，LLM并不适合，根本不应该使用。因此，出版商和资助机构出台了各种政策，禁止LLM参加同行评审, 作为合著者，或任何类型的未公开资源。

该论文注明：“我们没有使用 ChatGPT 或任何其他 LLM 来撰写手稿或进行数据分析。”

借助这一研究，研究者在论文中呼吁重新评估当前有关 LLM 用于学术的政策和法规：“LLM 的使用对科学写作的影响确实是前所未有的，甚至超过了新冠疫情引起的词汇量的剧烈变化。LLM 的使用可能伪装得很好，难以察觉，因此其采用的真实程度可能已经高于我们测量的范围。这一趋势要求重新评估当前有关 LLM 用于学术的政策和法规。”

研究者在论文结尾处写道：“我们希望未来的工作能够更细致地深入追踪 LLM 的使用情况，并评估哪些政策变化对于应对 LLM 在科学出版领域兴起所带来的复杂挑战至关重要。”

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。