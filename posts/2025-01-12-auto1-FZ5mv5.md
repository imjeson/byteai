---
title: '“想看看她的捏造”: 性别深度伪造的黑暗世界与抗争的女性'
date: 2025-01-13
author: ByteAILab

---

它始于一封匿名邮件。

---
“我真的非常抱歉打扰你，”邮件写道。字下方是三个链接，指向一个网络论坛。“有大量的图片会引发情绪问题……它们包含了你的不雅合成照片。”乔迪（不是她的真实名字）愣住了。这位27岁的剑桥郡女性之前曾面临他人盗用她的照片，设置假约会和社交媒体账户的问题。她曾向警方报告，但被告知无法采取任何行动，因此将这件事抛在脑后。

但这封邮件，写于2021年3月10日，却让她无法忽视。她点击了链接。“就像时间静止了一样，”她说。“我记得大声尖叫。彻底崩溃。”这个论坛是一个替代性的色情网站，上面有数百张她的照片——单独的、度假的、和朋友和室友的——以及评论称她们是“荡妇”和“妓女”，请求其他人对她们进行评分，或幻想他们会做什么。发布图片的人还邀请论坛的其他成员使用乔迪的衣着得体照片，利用人工智能制作性暗示的“深度伪造”内容。“从未做过，但真想看看她的捏造……很乐意聊天/给你更多她的资料……:D，”他们写道。作为回应，用户们发布了他们的作品：数百张合成图像和视频显示一个女人的身体搭配上乔迪的面孔。有些图像显示她穿着校服，在教室里被老师侵犯。其他则完全“裸露”。“我在每一幅作品中都与他发生了性关系，”她说。“这种震惊和毁灭感至今萦绕在我心头。”

这些虚假的图像——现在已被删除——是越来越多的在线合成色情图片和视频中的一部分，性质如此恶劣，以至于在英国和世界范围内被制作、交易和销售——在社交媒体应用、私人信息、游戏平台，以及成人论坛和色情网站上。

上周，政府宣布了对明确深度伪造内容的“打击”，承诺扩展现有法律，使得在未经同意的情况下制作这些图像成为刑事罪，同时分享它们自2024年1月以來就已违法。但创造深度伪造内容的 soliciting（邀请他人制作）这一行为将不被涵盖。政府还未确认这一罪行是否应该基于同意，运动倡导者称它必须如此，或受害者是否需要证明施害者具有恶意意图。

在位于德文郡外克斯特的报复色情热线总部，28岁的资深从业者凯特·沃辛顿表示：“亟须更严格的法律——没有漏洞。”该热线成立于2015年，是一个专门为亲密图像虐待的受害者提供服务的机构，部分由内政部资助。深度伪造案件数量创历史新高：自2017年以来，合成图像滥用的报告增加了400%。但这些案例在整体亲密图像虐待案件中所占比例仍然较小——去年只有50起案子，仅占总案子的约1%。主要原因在于这些案件极大地被低估，沃辛顿说：“很多时候，受害者根本不知道自己的图像已被分享。”

该团队注意到，许多施害者的深度伪造行为似乎是出于“收藏者文化”。“通常这不是为了让当事人知晓，”沃辛顿说道。“它是为了性快感而被出售、交换、交易——或者是为了地位。如果你是发现并分享这一内容的人，附带Snap、Instagram、LinkedIn的个人档案，你可能就会被颂扬。”许多合成图像是通过“裸体化”应用产生的。今年3月，运行报复色情热线的慈善机构向苹果公司报告了29个此类服务，后者随即将这些应用移除。

还有其他情况，合成图像正被直接用于威胁或羞辱他人。热线接到过年轻男孩伪造女亲属的虚假乱伦图像的案例；沉迷于色情的男子，制作了伴侣进行未获同意的性行为的合成图像；以及一些在健身房拍摄的照片，随后被制作成伪造视频，看起来像是他们在进行性行为。绝大多数受害者——但并非全部——是女性。热线接到的深度伪造案件中约72%涉及女性，年龄最大的受害者已七十多岁。

还有多个案例显示穆斯林女性遭受伪造图像的攻击，她们穿着暴露的衣物，或被剪去了头巾。无论意图如何，影响往往是极其严重的。“这些照片通常是如此真实， 你的同事、邻居、祖母不会知道区别，”沃辛顿表示。

报复色情热线能够帮助人们删除滥用图像。30岁的阿曼达·达什伍德在热线工作两年，她表示这一点通常是来电者的首要目标。“他们通常会说，‘哦，我的天，帮帮我，我需要在别人看到之前把这个删掉，’”她说。

她和热线团队的其他成员——八位女性，大多在30岁以下——有多种工具可供使用。如果受害者知道其内容的发布地点，团队将直接向平台发出移除请求。有些平台干脆无视这些请求。但热线与大多数主要平台（如Instagram、Snapchat、Pornhub和OnlyFans）保持合作关系，90%的情况下能够成功删除内容。

如果受害者不知道内容何处被发布，或者怀疑其已被更广泛地分享，他们会要求受害者发送自拍照，并通过面部识别技术（征得同意后）进行处理，或者使用反向图像搜索工具。虽然这些工具并不完美，但可以检测到在公开网络上分享的材料。该团队还可以建议防止内容再次在线发布的步骤。他们会引导人们使用一个名为StopNCII的服务——这是由Meta资助的SWGFL在线安全慈善机构所创建的，该机构也设有报复色情热线。

人们可以上传照片——无论真实还是合成——该技术会生成一个唯一的哈希，此哈希会与合作平台共享——包括Facebook、Instagram、TikTok、Snapchat、Pornhub和Reddit（但不包括X或Discord）。如果有人试图上传该图像，它会被自动阻止。截至12月，已经有一百万张图像被哈希，24,000次上传被预先阻止。

一些人也会选择向警方报告，但不同的执法机构反应截然不同。受害者企图报告合成图像滥用时，被告知警方无法处理编辑过的图像，或者起诉并不符合公众利益。

热线经理索菲·莫提默回忆起另一案例，警方表示“这不是你；这是一个看起来像你的人”，并拒绝调查。“我们知道案件很复杂，但这并不减轻对人们造成的实际伤害，”莫提默说。

11月，国家首席警官协会的助理警长萨姆·米拉在对亲密图像虐待的国会调查中表示，她“深切担忧”警官对相关立法的无知，以及案件处理的不一致。她提到：“就在昨天，一位受害者告诉我，她与450名深度伪造图像的受害者进行了对话，但只有两个人的警务经历是积极的。”

对于乔迪来说，增强公众以及警方对于深度伪造滥用的认识至关重要。在她得知自己的深度伪造作品后，她花了数小时翻阅这些帖子，试图拼凑事情的真相。最终，她意识到并不是陌生人分享了这些图片，而是她的一个好朋友亚历克斯·伍尔夫，他是一位剑桥毕业生和前BBC年度年轻作曲家。他用她被裁剪出来的照片发布了流言。“我知道我没有在Instagram上发布那张照片，只是发给了他。这时，我才明白过来。”

在乔迪和其他女性花了数小时筛选图像并向警方提交60页的证据后，伍尔夫被指控。最终，他被判刑20周，判决悬挂执行，需进行康复，并完成150小时的无偿劳动。法庭命令他向15名受害者每人赔偿100英镑，并删除所有设备上的图片。然而，该判决针对的是发布的留言的恶劣性质，而不是他对合成图像的邀请。

乔迪对警方的态度非常不满。“从一开始，感觉他们并没有认真对待这种滥用，”她说。她还称在论坛上要求删除合成图像的过程中，自己面临“一场艰苦的斗争”。但她最大的担忧是法律本身存在缺陷。如果伍尔夫没有发布那些图像，他也许就不会被定罪。而根据政府目前提出的法律草案——依照其公布的细节——他邀请他人制作乔迪的虚假图像将不会构成具体罪行。

司法部表示，协助他人犯罪本身即为违法，这将涵盖邀请行为。但乔迪表示：“它需要明确无误，以便检控服务做出起诉决定。因此，我们为什么要允许这个漏洞的存在？”许多人没有意识到的是，这些行为的施害者是“普通人，而非怪物或奇怪的人。他们是生活在我们之间的人——我们的同事、伴侣、朋友。”

乔迪希望人们意识到深度伪造滥用可能带来的“巨大影响”。三年过去了，她使用化名发声，因为如果使用真实姓名，将面临再次被目标的风险。即使最初的图像已经被移除，她表示自己仍然生活在“持续的恐惧”中，不知是否某些图像仍在网络某处流通。她的友谊、关系，以及对男性的看法都受到影响。“对我来说，这完全是来自我信任的人的最终背叛，”她说。

“许多人没有意识到的是，这些行为的施害者是‘正常’人，并不是那些怪物或奇怪的人，而是生活在我们中间的人——我们的同事、伴侣、朋友。”

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。