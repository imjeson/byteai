---

title: '国内首个自研MoE多模态大模型，揭秘腾讯混元多模态理解'
date: 2024-08-23
author: ByteAILab

---

AIxiv专栏是机器之心发布学术、技术内容的栏目。过去数年，机器之心AIxiv专栏接收报道了2000多篇内容，覆盖全球各大高校与企业的顶级实验室，有效促进了学术交流与传播。

---
如果您有优秀的工作想要分享，欢迎投稿或者联系报道。投稿邮箱：liyazhou@jiqizhixin.com；zhaoyunfeng@jiqizhixin.com

以 GPT 为代表的大型语言模型预示着数字认知空间中通用人工智能的曙光。这些模型通过处理和生成自然语言，展示了强大的理解和推理能力，已经在多个领域展现出广泛的应用前景。无论是在内容生成、自动化客服、生产力工具、AI 搜索、还是在教育和医疗等领域，大型语言模型都在不断推动技术的进步和应用的普及。

然而，要推动通用人工智能向探索物理世界迈进，第一步便是解决视觉理解问题，即多模态理解大模型。多模态理解让人工智能能够像人类一样，通过多种感官获取和处理信息，从而更全面地理解和互动世界。这一领域的突破将使人工智能在机器人、自动驾驶等方面取得更大的进展，真正实现从数字世界到物理世界的跨越。

去年 6 月 GPT-4V 发布，但相较于大型语言模型，多模态理解模型的发展显得较为缓慢，尤其是在中文领域。此外，不同于大语言模型的技术路线和选型相对确定，业界对于多模态模型的架构和训练方法的选型还没有完全形成共识。

近期，腾讯混元推出了基于 MoE 架构的多模态理解大模型。该模型在架构、训练方法和数据处理方面进行了创新和深度优化，显著提升了其性能，并能支持任意长宽比及最高 7K 分辨率图片的理解。与大部分多模态模型主要在开源基准测试中进行调优不同，腾讯混元多模态模型更加注重模型的通用性、实用性和可靠性，具备丰富的多模态场景理解能力。在近期发布的中文多模态大模型 SuperCLUE-V 基准评测中（2024 年 8 月），腾讯混元斩获国内排名第一，超越了多个主流闭源模型。

方法介绍：MoE 架构

腾讯混元语言大模型，在国内率先采用混合专家模型 (MoE) 架构，模型总体性能相比上一代提升 50%，部分中文能力已追平 GPT-4o，在 “时新” 问题的回答表现上，数学、推理等能力上均有较大提升。早在今年年初，腾讯混元就将该模型应用于腾讯元宝。

腾讯混元认为，能够解决海量通用任务的 MoE 架构，也是多模态理解场景的最佳选择。MoE 能够更好地兼容更多模态和任务，确保不同模态和任务之间是互相促进而非竞争的关系。

依托腾讯混元语言大模型的能力，腾讯混元推出了基于MoE架构的多模态理解大模型，在架构、训练方法和数据处理方面进行了创新和深度优化，性能得到显著提升。这也是国内首个基于MoE架构的多模态大模型。

简单可规模化

除了采用 MoE 架构外，腾讯混元多模态模型的设计还遵循简单、合理、可规模化的原则：

- 支持原生任意分辨率：与业界主流的固定分辨率或切子图方法相比，腾讯混元多模态模型能够处理原生任意分辨率的图片，实现了首个支持超过 7K 分辨率和任意长宽比（例如 16:1，见下文例子）图片理解的多模态模型。
- 采用简单的 MLP 适配器：相较于此前主流的 Q-former 适配器，MLP 适配器在信息传递过程中损失更小。

这种力求简单的设计，使得模型和数据更容易扩展和规模化。

SuperClue-V 榜单国内排名第一

2024 年 8 月，SuperCLUE 首次发布了多模态理解评测榜单 ——SuperClue-V。

SuperCLUE-V 基准包括基础能力和应用能力两个大方向，以开放式问题形式对多模态大模型进行评估，包含 8 个一级维度 30 个二级维度。

在此次评测中，混元多模态理解系统 hunyuan-vision 取得了 71.95 得分，仅次于 GPT-4o。在多模态应用方面，hunyuan-vision 领先于 Claude3.5-Sonnet 和 Gemini-1.5-Pro。

值得注意的是，业界此前的多模态评测多集中于英文能力，评测题目类型大多为选择题或判断题。而 SuperCLUE-V 评测更侧重于中文能力评测，关注用户的真实问题。此外，由于是首次发布，尚未出现过拟合现象。

腾讯混元图生文大模型在通用场景、图像 OCR 识别理解和中文元素理解推理等多个维度上显示了不错的性能，也体现了模型在未来应用上的潜力。

面向通用应用场景

混元多模态理解模型面向通用场景和海量应用进行了优化，积累了数千万相关问答语料，涵盖图片基础理解、内容创作、推理分析、知识问答、OCR 文档解析、学科答题等众多场景。以下是一些典型应用实例。

以下是更多典型示例：

将图片转换成文本表格：

![图片1](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWib3u1rBCuIwIakcIn4d3r9q6YRcNBQybanLS7SV9qC26lNrC9aDqdGkQcWxmjwoKj5KgB1TLE38ibQ/640?wx_fmt=png&from=appmsg)

解释一段代码：

![图片2](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWib3u1rBCuIwIakcIn4d3r9q9BbFzicr8mae8cBWhyqlBemlric6ySKicx2Ol8f2y6yXSFettbwzt4agQ/640?wx_fmt=png&from=appmsg)

分析账单：

![图片3](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWib3u1rBCuIwIakcIn4d3r9qRJAYdXoFOlyFG5JibLB4LVv7sWUr7q56N8lzoib08uTRo6a4ZtG9kA8A/640?wx_fmt=png&from=appmsg)

描述图片内容：

![图片4](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWib3u1rBCuIwIakcIn4d3r9qU0ibiaHgIvkicG1AghlVJzVRtXAVGZUUF0eHWGvj5jMlFkYlyYxh1GR6g/640?wx_fmt=png&from=appmsg)

做数学题：

![图片5](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWib3u1rBCuIwIakcIn4d3r9qMRvWonfegTEP03BZsSXxKqd3d54ueibLTcIvNban79d9SvuTq1MehicQ/640?wx_fmt=png&from=appmsg)

根据图片内容，进行分析：

![图片6](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWib3u1rBCuIwIakcIn4d3r9qH41mB9hFPiaemLgo8Yux7jLPrrZE03ntQRbTYticOyZTSBFL529RJjiaA/640?wx_fmt=png&from=appmsg)

帮你写文案：

![图片7](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWib3u1rBCuIwIakcIn4d3r9qCEuQPKAu8iaDvFw7g3TF25EfxBHk6icJt8wkkGRkVTh91TicXe9rYb7aw/640?wx_fmt=png&from=appmsg)

目前腾讯混元多模态理解大模型已在 AI 助手产品腾讯元宝上线，并通过腾讯云面向企业及个人开发者开放。

腾讯元宝地址：https://yuanbao.tencent.com/chat

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。