---
title: '不到60秒就能生成3D「手办」，Meta发力3D生成，ChatGPT时刻要来了吗？'
date: 2024-07-06
author: ByteAILab

---

3D 生成，一直在等待它的「ChatGPT时刻」。

一直以来，创作 3D 内容是设计和开发视频游戏、增强现实、虚拟现实以及影视特效中最重要的部分。

---


然而，3D 生成具有独特而艰巨的挑战，这是图像和视频等其他生成内容所不具备的。

首先，3D 内容在艺术质量、生成速度、3D 网格结构和拓扑质量、UV 贴图结构以及纹理清晰度和分辨率方面具有严格的标准；其次，与其他研究相比，可用的数据量少。虽然该领域有数十亿张图像和视频可供学习，但可用于训练的 3D 内容数量要少三到四个数量级。因此，现阶段的3D 生成还必须从非 3D 的图像和视频中学习，而且需要从部分 2D 观察中推断出 3D 信息；传统方法生成的3D 资源通常难以实现逼真的照明和材质属性，从而限制了它们在专业工作流程中的实用性；3D生成是一个非常耗费算力的过程，主要因为它涉及到复杂的计算和大量的数据处理，如实时渲染、细节处理。并且由于算力不够，可能会导致生成速度非常慢。

在生成式AI爆发的当下，很多研究者开始尝试针对以上问题提出解决方案。

刚刚，Meta发布了最新系统Meta 3D Gen (3DGen)，其用不到一分钟的时间，就能直接从文本生成3D资产。

论文地址：https://ai.meta.com/research/publications/meta-3d-gen/?continueFlag=24428397aaeb0cc6751570d48a532d36

3DGen支持基于物理的渲染 (PBR)，这是在实际应用中重新照明 3D 资产所必需的。此外，3DGen 还支持使用用户提供的额外文本输入对先前生成的（或艺术家创建的）3D 形状进行重新纹理化。

比如下面所展示的，借助3DGen，研究者渲染出了一只金属色的小狗：

未来感满满的机器人：

3DGen还能对生成的对象纹理进行进一步编辑和定制，同样的方法也可以应用于艺术家创建的3D网格纹理而不需要修改。如下所示，3DGen将艺术家创建的3D资产渲染成彩色的蝴蝶。

蝴蝶「变身」为用粉色和绿色纱线编织的蝴蝶玩具。

通过展示可以看出，即使是复杂的文本提示，3DGen也能很好地遵循指令，生成的3D形状和纹理质量也比较好。

以下是论文中的具体信息。

**Meta 3D Gen基本原理**

Meta 3D Gen 是一种两阶段方法，包括两个关键组件：用于创建 3D 网格的 Meta 3D AssetGen 和用于生成纹理的 Meta 3D TextureGen。

这些技术协同工作，可生成具有高分辨率纹理和PBR材质的 3D 资产。Meta表示，该流程的速度是现有解决方案的 3 到 10 倍。

第一阶段为3D 资产生成阶段。在这一阶段，根据用户提供的文本提示，Meta 3D AssetGen（简称 AssetGen）创建初始 3D 资产。此步骤生成具有纹理和 PBR 材质贴图的 3D 网格。...

接下来是第二阶段。给定第一阶段生成的 3D 资产和用于生成的初始文本提示，第二阶段将基于该资产和提示生成更高质量的纹理和 PBR 贴图。第二阶段用到了文本到纹理生成器 Meta 3D TextureGen（简称为 TextureGen）。...

此外，给定一个无纹理的 3D 网格和描述其所需外观的提示，第二阶段还可用于从头开始为该 3D 资产生成纹理（网格可以是先前生成的，也可以是艺术家创建的）。...

下图为第一阶段和第二阶段可视化对比。后者往往具有更高的视觉美感，看起来更逼真，细节频率更高。

我们不难发现，3DGen 以 AssetGen 和 TextureGen 为基础，将3D 对象的三个关键信息进行了很好的互补：视图空间（对象的图像）、体积空间（3D 形状和外观）和 UV 空间（纹理）。

此过程从 AssetGen 开始，通过使用一个多视角和多通道文本到图像生成器，生成关于物体的几个相对一致的视图。...

**实验对比**

[...]

**定性质量对比**

[...]

**3D生成来到「ChatGPT时刻」前夜**

3D生成赛道其实一直是资本市场的宠儿。A16Z接连对3D生成赛道出手，除了最近名声大噪的Luma Labs之外，Meta论文中提到的CSM，Google系的Yellow，还有曾经争议较大的Kaedim都是A16Z的被投明星企业。

[...]

扩展阅读：

[...]

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。