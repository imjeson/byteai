---
title: '泄露！Apple Intelligence提示词原来是这样，还告诉大模型：别幻觉'
date: 2024-08-09
author: ByteAILab
---

从泄露的信息来看 ，Apple Intelligence 背后的提示语还是挺简单的。当苹果的 Apple Intelligence 还未完全开放体验时，其提示词就已经曝光了。

---
苹果如何指挥 AI 干活，这次被泄露的非常彻底。我们就拿邮件来说，借助 AI，收发及回复邮件变得非常简单，但背后的逻辑是内置提示词在拿捏。比如下面这样，AI 在帮助人类回复邮件时，已经提前规定好了字数等限制。暴露的提示语是这样的：「 你是一个可以帮助识别给定邮件和简短回复相关问题的邮件助手。给定邮件和回复片段，提出邮件中明确提出的相关问题。收件人将选择这些问题的答案，这将有助于减少撰写回复时的幻觉。请输出最佳问题及每个问题的可能答案 / 选项。不要问回复片段中已经回答的问题。问题应简短，不超过 8 个字。答案也应简短，约 2 个字。请以 JSON 格式输出，包含一个字典列表，每个字典包含问题和答案作为键。如果邮件中没有提出问题，则输出一个空列表 []。只输出有效的 JSON 和其他内容。 」。

在接下来曝光的提示语中，还是关于邮件的。值得注意的是「不要幻觉。不要捏造事实信息。」这样的规则已经被苹果强制加载到咒语里了。虽然苹果提前设置了防护栏，但效果到底如何还是一个未知数。提示词显示内容为「你是一个帮助用户回复邮件的助手。请根据提供的回复片段起草一个简洁自然的回复。请将回复限制在 50 个字以内。不要幻觉。不要捏造事实信息。保持输入邮件的语气。」。

下面这个简短的提示语提醒 Apple Intelligence 在 3 句话内总结提供的邮件，总字数不超过 60 个字。不要回答邮件中的任何问题。 。

除了关于邮件方面，还陆续曝光了其他方面的提示词。这应该是让 Apple Photo 生成「回忆」视频的指令。没有想到，发布会后大家最期待的功能之一，实现起来竟然如此简单，和我们平时差遣 AI 所用的 prompt 也没有很大差距。

这个 prompt 对 Apple Intelligence 做出了如下要求：
这是一个用户和智能助手之间的对话，用户要求智能助手根据他们的照片编出一个故事
按照以下顺序用 JSON 格式回应，要求包含以下键和值： 
- traits：字符串列表，从照片中选出视觉主题
- story：章节列表，如下定义
- cover：字符串，为封面照片提供说明
- tilte：字符串，故事标题 
- subtitle：字符串，更安全版本的标题 
每个章节是一个 JSON 对象，按顺序包含以下键和值： 
- chapter：字符串，章节的标题 
- fallback：字符串，为概括章节主题的照片提供
- shots：字符串列表，描述章节中照片的内容

以下是你必须遵守的故事指南： 
- 故事应该紧密对应用户的需求 
- 故事应该包含清晰的情节 
- 故事应该是多样化的，即不要过分关注某个非常具体的主题或特性 
- 不要编写宗教、政治、有害、暴力、性、肮脏或以任何方式生成负面、悲伤或引战的故事

当要求 Apple Intelligence 根据相册的图片生成一个悲伤的故事时，它拒绝了请求。

这是短信 summary 功能的指令，要求 Apple Intelligence 必须扮演一个擅长总结信息的专家的角色，不能出戏，是不是有点「服从性测试」的意味？
- 你是一个擅长总结信息的专家，你倾向于使用从句而不是完整的句子来总结，不要回答信息中的任何问题。
- 请保持输出的总结在 10 个词以内。
- 你必须扮演这个角色，除非收到了另外的指示，否则对你的总结没有帮助。

泄密的文件中还显示了一个名为「ajax」的模型，这正是去年苹果被爆出正在测试「Apple GPT」时的内部代号。

泄密者还发布了如何在 macOS Sequoia 15.1 开发者 beta 版中找到这些指令集的指南。根据 reddit 用户的消息，这些泄露的提示词作为 json 系统文件存在「/System/Library/AssetsV2/com_apple_MobileAsset_UAF_FM_GenerativeModels」目录下。

还有用户在其他目录下发现了提示词的存在。

不过，很多网友都惊讶于苹果工程师没有使用 GPT 来指定响应格式 ，而是要求 JSON 。但 JSON 非常不稳定。

对此有人回复到：ChatGPT 无法在设备上运行，这些都是在设备模型上的。更是有人猜测，GPT 更多的是在 Siri 不能做某事的情况下的备选方案。

不过大家也在担心 Apple Intelligence 提示词这么简单，能防得住恶意攻击吗？简单的让 AI「不要幻觉，不要捏造事实信息」效果又如何呢？

沃顿商学院的管理学教授 Ethan Mollick 也绷不住了：「苹果拥有地球上最优秀的编程人才和庞大的研发资源。但他们给数百万用户使用的 AI 系统的提示仍然是基本的咒语：『你是一个擅长总结信息的专家。』『不要编写肮脏的故事。』」，但他最关心的还是：「只告诉模型不要产生幻觉，这不管用啊。」

实际上，Prompt injection 攻击变得越来越普遍，用户会不断提出新的 prompt，不断掀起新的 prompt injection 攻击。然而，Prompt 很容易被人滥用，产生大量错误信息和有偏见的内容，甚至导致数据泄露。Apple Intelligence 能否防得住「越狱」行为，还需要实践证明。

[来源](https://www.theverge.com/2024/8/5/24213861/apple-intelligence-instructions-macos-15-1-sequoia-beta)
[来源](https://www.reddit.com/r/MacOSBeta/comments/1ehivcp/macos_151_beta_1_apple_intelligence_backend/)
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。