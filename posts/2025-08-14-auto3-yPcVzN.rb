title: 'Inworld Runtime：首个面向消费者应用的AI运行时'
date: 2025-08-15
author: ByteAILab

---

今天，Inworld AI 发布了 Inworld Runtime，这是一款专为扩展消费者应用而设计的首个 AI 运行时。![图片](https://ai-techpark.com/wp-content/uploads/Inworld-Runtime.jpg){ width=60% }

---
它使开发者能够更快地从原型转向生产，并支持用户从 10 个增长到 1000 万个用户，所需的代码更改极少。通过自动化 AI 操作，Inworld Runtime 解放了工程资源，用于新产品开发，并提供了设计和部署无代码实验的工具。Inworld 目前的合作伙伴，包括主要媒体公司、AAA 级工作室和 AI 原生初创企业，已经将 Runtime 作为他们下一代实时、多百万用户 AI 特性和体验的 AI 栈基础。

为了加速与这些客户的合作，Inworld 建立了 Runtime 作为内部基础设施，以满足消费者 AI 的独特需求：在百万级并发用户规模下保持实时性能，专注于用户参与度的用户特定质量期望，以及每用户每天的成本控制在一分以下。当来自健康/健身、学习和社交应用的公司开始接触 Inworld 时，团队发现这些公司面临的挑战与 Runtime 已经解决的内部挑战完全一致，因此决定公开发布这一平台。

“Inworld Runtime 是因为我们自己需要它而建造的。现有工具无法满足我们合作伙伴所需的速度和规模，”Inworld AI 的首席执行官 Kylan Gibbs 说。“当我们意识到每个消费者 AI 公司都面临这些同样的障碍时，我们知道我们必须开放我们所构建的系统。我们目睹了行业的拐点，成千上万的开发者正在面临与我们相同的扩展难关，因此我们在过去一年中努力添加超出我们内部需求的功能，以创建加速整个消费者 AI 生态系统的通用后端。”

消费者 AI 成功的三个决定性因素
通过四年的消费者 AI 应用部署，Inworld 发现了三个决定成败的关键因素。必须在所有三个方面做到卓越，任何一方面的弱点都将阻止消费者 AI 特性或应用实现市场领先：

1. 从原型到生产的时间
虽然创建 AI 演示只需几小时，但达到生产就绪状态通常需要超过六个月的基础设施和质量提升工作。团队必须处理提供者的停机，实施后备方案，管理速率限制，配置和加速计算能力，优化成本，并确保质量的一致性。在与类别领导者合作的过程中，Inworld 观察到大多数消费者 AI 项目要么成功跃迁，要么在原型与可扩展现实之间的差距中停滞不前。

2. 新产品开发的资源分配
在产品发布后，大多数工程团队花费超过 60% 的时间在维护任务上：调试提供者变更、管理模型更新、处理规模问题和优化成本。这使得开发新特性的资源有限，导致产品停滞不前，而竞争对手则在不断进步。Inworld 亲身经历了这一点，即使是创新团队也会陷入维护循环，而无法构建用户所需的新功能。

3. 实验速度
消费者偏好不断发展，但传统的部署周期为 2-4 周，无法跟上这一节奏。团队需要测试数十种变体，衡量真实用户影响，并扩展成功者，而这必须在没有代码部署和应用商店批准摩擦的情况下完成。与行业内的合作伙伴合作使 Inworld 认识到，最快的学习者胜出，但现有基础设施使得快速迭代几乎不可能。

“我们在 19 天内从原型扩展到 100 万用户，成本降低超过 20 倍。” – Fai，Status CEO

Inworld Runtime 的技术设计
Inworld Runtime 通过多项创新提供这些能力，包括：

1. 自适应图
基于 C++ 的图执行系统，解决了大多数 AI 框架面临的跨平台扩展限制，支持 Node.js、Python 等 SDK。开发者可以使用预先优化的节点作为构建块（与顶级提供商的 LLM、TTS、STT、知识、记忆等 API 结合），处理低级整合工作，并自动优化组件之间的数据流。相同的图可以在极少的代码更改和管理端点的情况下无缝扩展，从 10 个测试用户到 1000 万个并发用户。这种友好的接口直接使得从原型到生产的飞跃在几天内完成，而不是几个月。

2. 自动化 MLOps
除了基本操作外，Runtime 还提供自包含基础设施自动化，整合了遥测捕获日志、跟踪和每次交互的指标。可操作的洞察，例如识别错误、用户模式和优化机会，通过 Inworld 的可观察性和实验管理平台 Portal 展现。Runtime 自动在提供者之间进行故障转移，智能管理模型的容量，并处理速率限制。它还支持定制的本地部署，为企业提供优化模型托管。随着应用的扩展，Inworld 提供必要的所有云基础设施，以训练、调整和托管打破成本-质量界限的自定义模型。

3. 实时实验
一键部署或扩展实验。配置与代码分离，使得可以毫无部署摩擦地即时进行 A/B 测试。Runtime 可以通过 SDK 定义变体，并通过 Portal 管理测试，自动运行数百个实验，测试不同的模型、提示、图配置和逻辑流程。更改在几秒钟内部署，并自动测量对用户指标的影响。

Inworld Runtime 的早期采用者证明的结果
Runtime 部署展示了一致的技术成就：

Inworld 最大的合作伙伴（主要知识产权所有者、媒体公司和 AAA 级工作室）已经将 Runtime 作为其 AI 栈的基础
Wishroll 在 19 天内从原型扩展到 100 万用户，成本降低超过 95%
Little Umbrella 能够在使用 Inworld 减少对现有标题的更新和维护工作量的同时发布新的 AI 游戏
Streamlabs 构建了一个多模态实时流媒体助手，包含以前六个月内无法实现的功能
Bible Chat 升级并扩展了他们的语音功能，同时将语音成本降低了 85%
Nanobit 为数百万用户提供个性化 AI 故事，确保了可持续的单位经济学

可用性和定价
开发者可以立即通过下载 Runtime SDK 来开始使用，网址为 inworld.ai/runtime，提供全面的文档和迁移指南。Runtime 与 Cursor、Claude Code、Google CLI、Windsurf 和 Zencoder 等代码助手原生兼容。开发者可以从自己的项目开始使用，也可以使用 Inworld 的模板和演示应用作为灵感。Runtime 可以灵活部署，既可以在客户端应用中运行，也可以在任何云提供者的服务器上或通过 Inworld 管理的模型托管进行定制的本地安装。投入生产后，可以使用 Portal 进行可观察性和快速实验。

Runtime 的定价完全基于使用情况，没有前期成本。开发者可以使用所有模型和功能进行实验，仅需为成功扩展的内容支付费用，确保消费应用经济的对齐，使得随着使用量的增长成本保持可持续性。开发者可通过 Anthropic、Google、Mistral 和 OpenAI 等提供的最新模型获得最大选择灵活性，以便轻松测试和选择最适合其用例的模型。Runtime 还通过高速提供商 Groq、Tenstorrent 和 Fireworks AI 提供了顶级开源模型，如 Deepseek、Llama 和 Qwen。与微软或谷歌有现有关系的开发者可以利用其云承诺通过 Azure Marketplace 和 Google Cloud Marketplace 访问 Runtime。

---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。