---
title: '突破数据墙！27岁华裔MIT辍学创业8年，年化收入逼近10亿'
date: 2024-09-27
author: ByteAILab

---

就在刚刚，创业成功的27岁亿万富翁Alexandr Wang宣布——Scale AI的年化收入，几乎达到了10亿美元！这个数字，足够震惊整个硅谷的。

相比之下，OpenAI预估的年收入也只是35-45亿美元而已。

---
再减去85亿美元的成本，OpenAI今年可能会血亏50亿。

这Scale AI是什么来头，能在营收上取得如此惊人的成绩？ 原来，它主攻的就是如今AI模型的一大软肋——对数据的巨大需求。

Scaling Law的存在意味着，随着模型变大，对数据的需求也呈现指数级增长，越来越多的人担心大模型会耗尽可用数据。 Scale AI的主营业务——做AI模型的「数据工厂」，恰好处于这个风口之上。 如果能攻克「数据墙」这个AI进步的巨大瓶颈，Alexandr Wang理所当然会赚得盆满钵满。

在AI浪潮中，赚得盆满钵满

生意能做这么大，源于Scale AI越做越成功的一项大业务。 在AI生态圈中，为大公司提供基础设施或服务支持的业务，市场需求巨大。 Scale AI做的就是后者——为这些公司提供人工数据标注员。 帮AI公司提高LLM的准确性。 Meta、谷歌等大公司，都是它的客户。 而且，今年Scale AI的生意越做越红火了。

跟去年同期相比，它今年上半年的销售额增长了近4倍，已经接近4亿美元。 可以肯定地说，Scale AI是从AI热潮中受益最多的私营企业之一。

投资者们当然也看到了这一点。 今年5月，Scale AI以138亿美元的估值，进行了新一轮融资。 投资者包括Accel、Founders Fund、Index Ventures、Thrive Capital和Greenoaks Capital等。 并且，除了亚马逊和Meta之外，Scale AI还吸引了各种各样的新投资者：思科、英特尔、AMD等风险投资部门参与其中，而且很多注资过的公司也回归了，包括英伟达、Coatue、Y Combinator等等。

就在近期，Wang手下的高管团队，再度进行了调整。

首席技术官Arun Murthy将离开公司，而去年离开风投公司Benchmark的前优步高管Jason Droege将加入公司担任首席战略官，直接向Wang汇报。

首席策略官Jason Droege解释自己为什么要加入Scale AI：这让我有机会参与到我一生中技术领域最根本的变革中 在Droege看来，Scale解决了人工智能中最困难的挑战之一：通过数据改进模型。 做到这一点需要卓越的人才、复杂的运营和对AI未来发展的强烈愿景。 虽然团队迄今已经取得了瞩目成就，但仍处于起步阶段。

2023年上半年开始，公司收入激增

这家成立8年的初创公司，一直负责合同工的招聘和培训，但尚未实现盈利。 然而就在今年上半年，它成功改善了运营的毛利率——每产生1美元收入，只需要花费约1.2美元，而在去年上半年，这一数字为1.5美元。

如今仅考虑业务成本（比如合同工的工资），Scale AI保留的收入只有一半。毛利率这一财务指标，略低于50%。 比起2022年上半年约57%的毛利率，这个数字有所下降。

这一水平，大大低于科技投资者对软件公司的期望。 但尽管如此，5月份的融资还是为Scale AI提供了雄厚的资金实力。截至上半年末，公司还有约9.8亿美元的现金。

从去年上半年开始，公司收入就开始激增。因为构建LLM的客户需要很多合同工，通过向聊天机器人提交问题、撰写答案，来训练AI模型。 在给投资者的PPT上，Scale AI自称是「一个人机混合系统，以低成本生产高质量数据」。

根据外媒消息，它还通过一家名为Outlier的子公司，雇佣了数十万个小时工，来进行数据微调。 显然，Scale AI选择聚焦LLM客户，是一种战略转型。

此前，它还有一项类似业务，主要是利用菲律宾和肯尼亚的低成本劳动力，为自动驾驶汽车公司标注数据。 但近年来，这项业务的增长已经放缓。 现在，即使雇佣薪酬更高、更专业的合同工，Scale AI的收入也依然能提高，因为它可以将这些更高的成本转移给客户。 当然，现在Scale AI也并非硅谷投资者眼中稳赚不赔的投资。 投资者担忧的问题，包括公司较低的毛利率，以及过度依赖少数几个大客户的问题。

天才少年辍学创办独角兽

Scale AI由Alexandr Wang和Lucy Guo于2016年创立，由著名创业孵化器Y Combinator投资。 客户包括Meta、微软、英伟达、OpenAI、丰田和哈佛医学院。

2019年，Scale AI成为独角兽。 2022年，Alexandr Wang成为全球最年轻的白手起家的亿万富翁。

Wang于1997年出生于新墨西哥州，父母都是在新墨西哥州洛斯阿拉莫斯国家实验室的物理学家。 高中阶段，他开始通过网络自学编程，开始参加世界级编程大赛，如美国计算机奥林匹克竞赛（USACO）。

17岁，他成为美国知名问答网站Quora的全职码农；18岁，考入麻省理工学院攻读机器学习；在MIT大一刚结束后的暑假，他就和Guo一起创办了Scale，并且拿到了Y Combinator的投资。

Wang跟爸妈说，「这就是我夏天随便玩玩的事。」

Scale AI刚起步时，有些人确实觉得这就是一个笑话，毕竟公司当时只有三名员工。 不过，在不断地融资和发展之下，Scale AI发展飞速，到2021年已经成长为价值73亿美元的独角兽企业，2023年初公司规模也扩展到了700人。

Wang透露，随着企业客户竞相训练生成式AI模型，Scale AI的这方面业务快速增长。 2023年，公司年度经常性收入增加了两倍，预计2024年底将达到14亿美元。

由于Scale AI的惊人成就，Alexandr Wang已经被硅谷公认为「下一个扎克伯格」。

AI模型的「数据工厂」

AI领域公认的三个基本支柱——数据、算法和算力。 算法领域，前有谷歌、微软的大型研究院，后有推出过Sora和GPT系列模型的OpenAI； 算力领域有供货全球的英伟达，但在Scale AI还未诞生的2016年，数据领域仍处于空白。

19岁的Alexandr Wang在看到这一点后，做出了辍学创业的决定，「我创办Scale的原因是为了解决人工智能中的数据问题」。

大部分数据都是非结构化的，AI很难直接学习这些数据；而且大型数据集的标注一项资源密集型工作，因此，「数据」被很多人认为是科技领域最辛苦、最卑微的部分。

但Scale AI却在短时间内就获得了巨大成功。他们可以为不同行业的企业客户量身定制数据服务。 在自动驾驶领域，Cruise和Waymo等公司通过摄像头和传感器收集了大量数据，Scale AI将机器学习与「人机回路」监督相结合，管理和标注这些数据。

他们曾经开发的「自治数据引擎」，甚至推动了L4级自动驾驶的发展。

Wang表示，Scale AI将自己定位为整个AI生态的基础设施供应商，构建「数据铸造厂」，而不仅仅是在子公司Remotasks中雇佣大量的合同工进行人工标注。 他强调，来自专家的、包含复杂推理的数据是未来人工智能的必备条件。 传统的数据来源，比如从Reddit等社区的评论中抓取数据存在局限性。 Scale AI构建了一些流程，模型先输出一些内容，例如撰写研究论文，在此基础上，人类专家可以改进这些内容，从而改进模型的输出。

「虽然人工智能生成的数据很重要，但想要获得有一定质量和准确性的数据，唯一方法是通过人类专家的验证。」 Alexandr Wang在Scale AI的官网上这样写道，「数据丰富不是默认情况，而是一种选择，它需要汇集工程、运营和AI方面最优秀的人才」。 Scale AI的愿景之一是「数据丰富」，从而将前沿LLM扩展到更大数量级，「为通向AGI铺平道路。在达到GPT-10的过程中，我们不应该受到数据的限制」。

业内盛赞的LLM排行榜更新

Scale AI对业界所做的贡献，不仅是数据标注这么简单。 今年5月，Scale AI重磅推出了全新LLM排行榜——SEAL，开始对前沿模型开展专业性评估。 对于这个榜单，Jim Fan大加赞赏。他认为SEAL是LMSys的非常好的补充和参照，提供公开模型的私密、安全、可信的第三方评估。

对此，Andrej Karpathy也深以为然。

随着OpenAI最强模型——o1的推出，SEAL排行榜也第一时间进行了评测。 除了在高级编程、数学和科学等领域表现出色之外，o1系列也为「prompt engineering」（提示工程）引入了新的变化。 在工具使用和指令跟随方面，o1-preview表现出色。而在编程能力方面，o1-mini夺得榜首，o1-preview紧随其后位居第二。

- 编程排行榜

在SEAL编程排行榜上，o1-mini以1271分的成绩领跑，紧随其后的是o1-preview，得分为1198。 评估数据集使用了1000个提示词，用于测试各种编程任务，涵盖从代码生成到优化和文档创建等多个方面。 过程中，每个模型的响应都会从正确性、性能和可读性三个维度进行评估，综合运用人工审核和代码执行测试的方法。

- 指令跟随排行榜

在对精确指令跟随能力的评估中，o1-preview以87.27 分的成绩领先，超越了知名Claude 3.5 Sonnet和Llama 3.1 405B Instruct。 评估数据集包含1054个跨领域的提示词，涉及文本生成、头脑风暴和教育支持等多个方面。

提示工程的变化

与我们熟悉的GPT、Gemini或Claude等模型相比，o1模型的提示词使用和可操控性明显不同。 根据OpenAI的建议，简单直接的指令有助于充分发挥o1的潜力。 与之前的模型不同，用户应避免要求模型进行思维链推理。他们还指出，提示词中的无关上下文对o1模型的干扰可能比之前的GPT系列更大，因此在检索增强生成（RAG）提示中加入一些示例很重要。

Cognition Labs发现，要求模型「think out loud」（大声思考）实际上会损害性能，而只要求给出最终答案反而会提高性能，因为o1模型无论如何都会产生内部的思维链。他们还指出，冗长或重复的指令会损害性能，而过于具体的指示似乎会影响模型的推理能力。

虽然o1在基准测试中取得了出色的结果，但让它完成你自己的具体任务似乎需要更多努力——它们往往会忽视明确（甚至是强调的）关于如何解决问题的指令。 由此可见，现实世界的提示和基准测试中使用的提示之间，实际上存在着不小的差距：后者旨在只包含明确的、自包含的、最小呈现的问题，没有关于如何解决
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。