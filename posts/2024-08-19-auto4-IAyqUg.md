---
title: '稚晖君一口气发布5款人形机器人！开发者还能“0元购”'
date: 2024-08-20
author: ByteAILab

---

刚刚，“鸽”了一年的稚晖君，终于带着具身智能新品来填坑了！没有什么比抽奖抽一台，更能体现对产品的自信了。

一水 衡宇 鱼羊 发自 凹非寺
量子位 | 公众号 QbitAI

一上来，稚晖君也没藏着掖着，就在直播现场搭建的“摄影棚”里，机器人当场秀了一波在语音指令下动手调饮料的操作：

现场主持人，也由此番发布的远征A2机器人亲自担当。

---


一套小连招下来，网友们be like：

B站科技区流量担当，诚不我欺（手动狗头）。

尽管发布会只有短短1小时不到，但稚晖君和他背后公司智元机器人憋了一年，此番属实带来不少干货，先给大家伙做个小总结：

- 发布远征A2系列人形机器人
- 全栈开源灵犀X1系列机器人，主打一个“人形机器人人人造”
- 自研关节模组实现量产化迭代升级，灵巧手自由度升级至19个
- 定义具身智能G1至G5演进路线
- …

总之，可以说是秀产品力的同时，也把硬核DIY的科技情怀给拉满了。

具体详情，咱们一项一项展开来唠~

## 面向量产的人形机器人

就像稚晖君自己所说，自去年8月中旬发布远征A1以来，他及他身后的智元机器人颇有些低调，在公众视野里可以说是“鸽”了一年。

但其实这一年中，智元机器人一直在“闷声干大事”。

智元机器人销售服务总经理姜青松对此补充说：

“我们每个月都在迭代，但因为不具备商用条件，所以没有宣传。”

而现在，面向商用，智元确实在这场发布会上，给出了阶段性的思考和答案。

首先，在产品方面，远征A2系列机器人相较于前代，主打的就是一个“面向量产改进”。

为此，智元此番发布了3款适用于不同场景的机器人：

- 远征A2，身高一米七，体重140斤，是能双足行走的交互服务机器人。大模型加持下，具备流畅的讲解能力和稳定的运动功能。
- 远征A2-W，轮式柔性智造机器人。一开场给稚晖君做饮料的就是它，具备动态任务编排、复杂作业执行，以及双臂协同作业等能力。
- 远征A2-Max，重载特种机器人，能够搬动40kg以上的重物。该款机器人目前处于产品研发阶段。

具体到技术细节上，智源机器人将机器人系统划分为动力域、感知域、通信域和控制域。

动力域方面，智元自研的PowerFlow关节模组实现量产化迭代升级。其中最强型号额定扭矩达到270Nm，峰值扭矩达到512Nm。

稚晖君表示，PowerFlow此番提升，主要是可靠性和稳定性达到量产级别。在现场，他也透露这款关节模组将开启对外售卖。

此外，机器人灵巧手的自由度也升级至19个，其中主动自由度达到12个，并引入了基于MEMS原理的触觉感知和视触觉感知技术。

使用工具拧螺丝：

拆快递：

干点穿针引线的精细活，都不在话下：

感知域方面，远征A2系列集成了RGBD相机、激光雷达、全景相机等传感器，引入自动驾驶Occupancy感知方案，通过SLAM算法进一步提升环境理解能力。

通信域方面，智元自研了专为具身智能打造的轻量化、高性能通信框架AimRT。

相比ROS等第三方中间件，在性能、稳定性、系统部署效率和灵活性均有提升的同时，兼容了ROS/ROS2已有生态。

AimRT还将于9月底开源。

控制域方面，结合Model-based和Learning-based两种算法，智元进一步提升了机器人的运动控制和适应能力。并预研了基于自然语言指令集驱动的、可以适配不同机器人本体的AgentOS，基于强化学习，实现机器人技能的精准编排和高效执行。

另外，智元还构建了面向开放生态的软件平台AIMA（AI Machine Architecture），覆盖机上、云端和客户端。该平台集成了机器人软件的核心技术，同时提供丰富的二次开发接口。

具身智能技术演进路线

值得关注的是，配合自家商用化进程，智元此番还提出了类似自动驾驶L1-L5的具身智能技术演进路线：

G1至G5（其中“G”指通用人工智能）。

其中，G1为传统自动化阶段，机器人基于大量人工编排执行任务，辅以简单视觉，基本不具备泛化能力。

G2阶段，有了大模型的加持，机器人开始实现一大类场景的快速迁移。

方法是，针对大量不同场景任务，提炼出可复用的原子能力，且以相对通用的方式实现这些能力。

过去一年，智元机器人在G2路线取得了阶段性突破，实现了通用的：位姿估计模型UniPose、抓取模型UniGrasp，力控插拔模型UniPlug等一系列zero-shot和few-shot的通用原子技能。

不过嘛，以上阶段都还采用了大量手工编排。

到了G3端到端阶段，机器人训练从算法驱动变成数据驱动。

此时，由手工设计各类原子能力变为依靠大量数据采集。这一阶段的目标是，形成一套通用技能训练框架。

比如发布会反复提到的“PPT能力”，即抓、放、递……

稚晖君特意提醒，当前实验表明，端到端是一条具备Scale up潜力的路线。

在G3基础上，G4主要实现通用操作大模型。

举个例子，比如对于开瓶子、开门把手这两个动作，G3阶段还需要单独采集数据，以训练不同的技能。

但对人类来说，其实动作的底层逻辑是相通的。

因此，G4引入了大量跨场景的真实、仿真数据，再加上时间模型等类似技术，让AI理解背后物理原理，从而执行更加复杂的任务。

至于最后的终极目标：AGI。对具身智能来说，主要还是能够走出实验室，在开放场景具备跨任务的泛化能力。

从G1到G5，一个显著趋势是：数据需求不断上涨。

姜青松透露，目前智元已经迈向G3阶段。在G3路线上，智元机器人还形成了一套具身数据方案AIDEA。

这是因为，“有多少人工就有多少智能，在具身智能领域依然成立”。

也就是说，高质量的人机操作数据非常关键。

具体来说，AIDEA包括数采本体、遥操设备和数据平台。

数采本体也就是轮式、足式等类型丰富、可靠稳定的机器人。

遥操设备支持全身映射、臂手协同和高精实时。

数据平台覆盖数据采集、数据标注、数据管理、模型训练、模型评测、模型部署再到数据回传的全链路，支持SaaS服务和私有化部署。

彩蛋是，基于AIDEA的百万条真机、千万条仿真数据，同样开源。今年四季度，感兴趣的小伙伴可以蹲起来了~

具身智能技术演进路线

值得关注的是，配合自家商用化进程，智元此番还提出了类似自动驾驶L1-L5的具身智能技术演进路线：

G1至G5（其中“G”指通用人工智能）。

其中，G1为传统自动化阶段，机器人基于大量人工编排执行任务，辅以简单视觉，基本不具备泛化能力。

G2阶段，有了大模型的加持，机器人开始实现一大类场景的快速迁移。

方法是，针对大量不同场景任务，提炼出可复用的原子能力，且以相对通用的方式实现这些能力。

过去一年，智元机器人在G2路线取得了阶段性突破，实现了通用的：位姿估计模型UniPose、抓取模型UniGrasp，力控插拔模型UniPlug等一系列zero-shot和few-shot的通用原子技能。

不过嘛，以上阶段都还采用了大量手工编排。

到了G3端到端阶段，机器人训练从算法驱动变成数据驱动。

此时，由手工设计各类原子能力变为依靠大量数据采集。这一阶段的目标是，形成一套通用技能训练框架。

比如发布会反复提到的“PPT能力”，即抓、放、递……

稚晖君特意提醒，当前实验表明，端到端是一条具备Scale up潜力的路线。

在G3基础上，G4主要实现通用操作大模型。

举个例子，比如对于开瓶子、开门把手这两个动作，G3阶段还需要单独采集数据，以训练不同的技能。

但对人类来说，其实动作的底层逻辑是相通的。

因此，G4引入了大量跨场景的真实、仿真数据，再加上时间模型等类似技术，让AI理解背后物理原理，从而执行更加复杂的任务。

至于最后的终极目标：AGI。对具身智能来说，主要还是能够走出实验室，在开放场景具备跨任务的泛化能力。

从G1到G5，一个显著趋势是：数据需求不断上涨。

G1至G5（其中“G”指通用人工智能）。

其中，G1为传统自动化阶段，机器人基于大量人工编排执行任务，辅以简单视觉，基本不具备泛化能力。

至于最后的终极目标：AGI。对具身智能来说，主要还是能够走出实验室，在开放场景具备跨任务的泛化能力。

从G1到G5，一个显著趋势是：数据需求不断上涨。

姜青松透露，目前智元已经迈向G3阶段。在G3路线上，智元机器人还形成了一套具身数据方案AIDEA。

这是因为，“有多少人工就有多少智能，在具身智能领域依然成立”。

具体来说，AIDEA包括数采本体、遥操设备和数据平台。

数采本体也就是轮式、足式等类型丰富、可靠稳定的机器人。

遥操设备支持全身映射、臂手协同和高精实时。

数据平台覆盖数据采集、数据标注、数据管理、模型训练、模型评测、模型部署再到数据回传的全链路，支持SaaS服务和私有化部署。

彩蛋是，基于AIDEA的百万条真机、千万条仿真数据，同样开源。今年四季度，感兴趣的小伙伴可以蹲起来了~

“人形机器人人人造”

以为介绍完远征系列，智元机器人一年一度亮活大会就结束了吗？
并不！
稚晖君一声令下，远征A2-W缓缓推上来了一个没它高的神秘黑箱。

有点眼熟，好像是直播最开始，稚晖君指挥A2-Max搬走的那玩意儿：

里面的东西破箱而出，是智元推出的另一款机器人。

灵犀X1。

诞生于智元X-Lab实验室（也可以简单理解为智元内部的稚晖君实验室），是智元机器人专门面向极致创新和敏捷探索而设立的。

今年6月立项，10个人组团投入其中，不到半个月前刚刚正式降生。

视频录像显示，灵犀X1身经百摔：

现在已经能
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。