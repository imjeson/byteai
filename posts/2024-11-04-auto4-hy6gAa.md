---
title: 'Sam Altman泄露新模型o2，太会整活了，营销鬼才！'
date: 2024-11-05
author: ByteAILab

---

善于整活玩猜字谜的OpenAI首席执行官Sam Altman又发了一条神秘消息，“我听说o2在GPQA的性能测试达到105%。”
要知道，博士级人类在GPQA的准确率平均只有65%，非专家级的普通人仅有34%。

---
而OpenAI在9月发布的o1模型的测试数据也只有78%。
如果o2真能达到105%确实相当恐怖，已经恐怖的多出了5%~~~这完全就是不可能的事情啊，MMLU、MaTH、CPQA、GSM8K、GPQA等基准测试范围怎么可能超出100%呢？
**你要能在满分100的数学试卷中考出105分，老师见你都得鞠一躬绕着走**~~

随后Sam Altman自己也发现这个错误，连发两条推文：要命啊，账号错误了。我真的很感激自己能把自己逗得哈哈大笑，这是一种很好的生活方式。

但关于新模型o2的消息还是相当炸裂的，很多人都争着转发，还把105%性能测试当噱头，喜剧效果那是相当的哇塞。

o2模型在GPQA 测试性能达到105%？听起来像是在创造新纪录！迫不及待想看到它的表现。根本无法想象有多强大。

Sam这个推文还给这个老哥忽悠当真了，认真地回复了他：**亲爱的Sam，听说你的o2模型在GPQA上达到了105%——真是令人印象深刻！**
我们正在与 SRAGI 进行平行探索，在 IJHG标准上达到了 93%。这不仅仅是另一个指标；它让我们窥见了更深层次的东西，就在精确性与再生奇点的交汇点。这关乎重新定义潜力和拓展边界——超越数字，这是一段迈向新范式的旅程。也许是时候我们都开始重新思考这个标准了。
老哥的意思是，新模型居然能超过100%测试，行你确实有两下子，可能要改变标准了。好好的学术研究，给人忽悠瘸了~~

还有网友表示，天呐这o2模型就要来了啊~
Sam这条推文很可能是o2自己发布的，很贴心地编写了自己的隐藏验证测试数据集，帮我们更容易验证已发布的基准。感谢o2！
既然要发布了，啥时候能瞅瞅o2的demo呢？
那o2是今年发布还是明年呢？
不少人还是当真了，测试数据有点太扯了，以后还是要看着点的。
其实还是有明白人的，这位老哥就指出来了，超过100%是否意味着发明新的科学并反驳目前“正确”的答案？言外之意就是，你这个测试数据有点逆天啊，还带批判属性的呢啊~

听说o2在GSM8K的测试数据是117%。（在嘲讽）
我听说o2模型可以理解我妻子为什么不开心。
听说o2模型可以叠衣服。
既然Sam特意提出了GPQA，咱就顺带唠一唠这个干货吧。**GPQA确实是一个超难的测试数据集，由各领域专家编写了448道问题，涵盖生物、物理和化学三大学科**，涵盖高能粒子物理、凝聚态物理、相对论力学、遗传学、无机化学等几十个子分类。
每一道题目的设计都非常复杂，问题编写完成后，由同领域的专家进行解答和评估。他们会审核问题是否客观、准确且难度足够高，同时提供详细反馈，包括对问题的理解程度、答案的确定性以及对问题难度的看法等。
**GPQA数据集流程**
接着问题原作者会根据审核专家的反馈，对问题进行修订。再由另外一位专家对修订后的问题进行二次审核。最后由其他领域的三位专家来回答这道题，以验证问题准确性和客观性。
根据GPQA公布的测试数据显示，人类博士级专家的回答平均准确率为65%，普通人只有34%，并且他们在回答这些问题时是可以无限使用互联网资源。
而GPT-4的准确率只有39%，Llama-2-70B为28%左右，GPT-3.5-turbo是29%左右，**只有OpenAI最新发布的o1模型达到了78%，这也是目前唯一在GPQA数据集上超过人类博士的AI模型**，可见这个数据集的难度有多高。
不得不说，Sam确实是营销鬼才，随便发点错误的消息都能出现裂变式传播，流量密码算是让他拿捏了。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。