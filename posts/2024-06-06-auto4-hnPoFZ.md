---
title: '国产大模型被抄袭事件告终 斯坦福团队致歉并撤下模型 面壁：知错能改，善莫大焉'
date: 2024-06-07
author: ByteAILab

---

斯坦福Llama3-V团队的终于向面壁智能团队正式道歉。

事情缘起于5月29日，斯坦福大学的一个研究团队发布了一个名为Llama3V的模型，号称只要500美元就能训练出一个 SOTA 多模态模型，且效果比肩 GPT-4V、Gemini Ultra 与 Claude Opus。

---


一时间备受关注，该AI团队背景豪华。3名作者拥有斯坦福大学、特斯拉、SpaceX的名校和企业背景。

但让人大跌眼镜的是，Llama3V与中国AI企业面壁智能在5月发布的8B多模态开源小模型MiniCPM-Llama3-V 2.59高度重合。

6月2日，有人在 Llama3-V的 Github 项目下提出质疑，但留言很快被删除。而后，事件引起面壁智能团队注意。

面壁团队通过测试，发现斯坦福大模型项目Llama3-V与MiniCPM一样，可以识别出“清华简”战国古文字，“不仅对得一模一样、连错得都一模一样”。

最后，斯坦福Llama3-V团队的两位作者Siddharth Sharma和 Aksh Garg在X上就抄袭行为向面壁智能团队正式道歉，并表示会将Llama3-V模型撤下。

---

### 事件各方表态

面壁智能CEO李大海针对斯坦福团队的Llama3V项目与面壁小钢炮的相似案例谈到，这项工作是团队同学耗时数个月，从卷帙浩繁的清华简中一个字一个字扫描下来，并逐一进行数据标注，融合进模型中的。更加tricky的是，两个模型在高斯扰动验证后，在正确和错误表现方面都高度相似。

李大海无奈的说道，技术创新不易，每一项工作都是团队夜以继日的奋斗结果，也是以有限算力对全世界技术进步与创新发展作出的真诚奉献。我们希望团队的好工作被更多人关注与认可，但不是以这种方式。

“我们对这件事深表遗憾！一方面感慨这也是一种受到国际团队认可的方式，另一方面也呼吁大家共建开放、合作、有信任的社区环境。一起加油合作，让世界因AGI的到来变得更好！”

对此，面壁智能联合创始人、首席科学家刘知远也作出回应。

刘知远表示，已经比较确信Llama3-V是对我们MiniCPM-Llama3-V 2.5套壳，比较有意思的证据是MiniCPM-Llama3-V 2.5研发时内置了一个彩蛋，就是对清华简的识别能力。这是我们从清华简逐字扫描并标注的数据集，并未公开，而Llama3-V展现出了一模一样的清华简识别能力，连做错的样例都一样。

“人工智能的飞速发展离不开全球算法、数据与模型的开源共享，让人们始终可以站在SOTA的肩上持续前进。我们这次开源的 MiniCPM-Llama3-V 2.5就用到了最新的Llama3作为语言模型基座。而开源共享的基石是对开源协议的遵守，对其他贡献者的信任，对前人成果的尊重和致敬。”

刘知远指出，Llama3-V团队无疑严重破坏了这一点。他们在受到质疑后已在Huggingface删库，该团队三人中的两位也只是斯坦福大学本科生，未来还有很长的路，如果知错能改，善莫大焉。

刘知远谈到，这次事件还让我感慨的是过去十几年科研经历的斗转星移。回想2006年我读博时，大家的主要目标还是能不能在国际顶级会议上发篇论文；到2014年我开始做老师时，就只有获得国际著名会议的最佳论文等重要成果，才有机会登上系里的新闻主页；2018年BERT出来时，我们马上看到了它的变革意义，做出了知识增强的预训练模型ERNIE发在ACL 2019上，当时以为已经站到国际前沿了；2020年OpenAI发布了1700+亿参数GPT-3，让我们清醒认识到与国际顶尖成果的差距，知耻而后勇&#8230;

---

### 何为面壁小钢炮

今年5月，面壁小钢炮 MiniCPM 系列，再次推出最强端侧多模态模型 MiniCPM-Llama3-V 2.5，且支持30+ 多种语言。

MiniCPM 是以「以小博大」著称的旗舰端侧模型，也不断推新端侧多模态能力天花板—— MiniCPM-Llama3-V 2.5实现了「以最小参数，撬动最强性能」的最佳平衡点。

从评测结果看，MiniCPM-Llama3-V 2.5以8B 端侧模型参数量级，贡献了惊艳的  OCR（光学字符识别）SOTA 成绩，以及端侧模型中的最佳多模态综合成绩与幻觉能力水平。

在综合评测权威平台 OpenCompass 上，MiniCPM-Llama3-V 2.5以小博大，综合性能超越多模态“巨无霸” GPT-4V 和 Gemini Pro。

OCR（光学字符识别）是多模态大模型最重要的能力之一，也是考察多模态识别与推理能力的硬核指标。新一代 MiniCPM-Llama3-V 2.5在 OCR 综合能力权威榜单 OCRBench 上，越级超越了 GPT-4o、GPT-4V、Claude 3V Opus、Gemini Pro 等标杆模型，实现了性能 SOTA。

在评估多模态大模型性能可靠性的重要指标——幻觉能力上，MiniCPM-Llama3-V 2.5在 Object HalBench 榜单上超越了 GPT-4V 等众多模型（注：目标幻觉率应为0）。

在旨在评估多模态模型的基本现实世界空间理解能力的 RealWorldQA 榜单上，MiniCPM-Llama3-V 2.5再次超越 GPT-4V 和 Gemini Pro，这对8B 模型而言难能可贵。

值得注意的是，该模型首次进行端侧系统加速，MiniCPM-Llama3-V 2.5已高效部署手机。

在图像编码方面，面壁首次整合 NPU 和 CPU 加速框架，并结合显存管理、编译优化技术，在 MiniCPM-Llama3-V 2.5图像编码方面实现了150倍加速提升。

在语言模型推理方面，目前开源社区的报告结果中，Llama 3语言模型在手机端侧的解码速度在0.5 token/s 上下，相比之下&#8230;

有别于常见的中英双语模型，MiniCPM-Llama3-V2.5可支持30+ 多种语言，包括德语、法语、西班牙语、意大利语、俄语等主流语言，基本覆盖一带一路国家。

总结起来就是，通过&#8230;

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。