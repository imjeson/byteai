---

title: '英国运动者对Meta计划使用AI进行风险评估表示担忧'
date: 2025-06-09
author: ByteAILab

---

互联网安全运动者呼吁英国的通信监管机构限制在关键风险评估中使用人工智能，原因是有报道称马克·扎克伯格的Meta计划自动化这项检查。

---
Ofcom表示正在“考虑所提出的担忧”，此前有报道称选旗下Facebook、Instagram和WhatsApp的公司可能会在不久的将来将高达90%的风险评估工作交由AI完成。

根据英国《在线安全法》，社交媒体平台需要评估其服务可能造成的伤害及其计划如何减轻这些潜在伤害，特别关注保护儿童用户和防止非法内容出现。风险评估过程被视为该法的重要组成部分。

Molly Rose基金会表示Meta的内容审核变更“令人极为担忧”，并指出根据Ofcom首席执行官梅兰妮·道斯（Melanie Dawes）发出的信函，Molly Rose基金会、儿童监督委员会（NSPCC）和互联网观察基金会（Internet Watch Foundation）等组织将AI驱动的风险评估前景形容为“一项退步和非常令人震惊的举措”。他们表示：“我们敦促您公开声明，风险评估通常不会被视为‘适当和充分’，这是该法所要求的标准，如果这些评估完全或主要是通过自动化产生的。”

该信函还敦促监管机构“挑战任何认为平台可以选择淡化其风险评估过程的假设”。Ofcom的发言人表示：“我们已经明确，服务应告诉我们是谁完成、审阅和批准了他们的风险评估。我们正在考虑信中提出的担忧，并将及时作出回应。”

Meta表示，该信函故意歪曲了公司在安全方面的做法，并表示其致力于高标准并遵守法规。“我们并不使用AI来做出风险决策，”Meta的一位发言人说。“相反，我们的专家构建了一种工具，帮助团队识别特定产品的法律和政策要求。我们使用由人类监督的技术来提高管理有害内容的能力，而我们的技术进步已经显著改善了安全结果。”

Molly Rose基金会在美国广播公司NPR上个月报道Meta算法更新和新安全功能将主要由AI系统批准，而不再由员工审查后组织了这封信。根据一位匿名的前Meta高管在NPR的说法，这一变化将使公司能够更快地推出Facebook、Instagram和WhatsApp的应用更新和功能，但将给用户带来“更高风险”，因为潜在问题在新产品发布到公众之前不太可能被防止。

NPR还报告称，Meta正在考虑对敏感领域进行审核的自动化，包括青少年风险和监测虚假信息的传播。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。