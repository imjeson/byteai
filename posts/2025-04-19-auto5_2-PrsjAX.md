---

title: 'Nature子刊，EPFL与上海交大用多模态Transformer精准预测全局最低吸附能，助力催化剂设计'
date: 2025-04-20
author: ByteAILab

---

在大规模催化剂筛选中，快速评估催化剂表面与吸附质之间的**全局最低吸附能**（Global Minimum Adsorption Energy, **GMAE**）是一项关键任务。然而，由于每种表面/吸附质组合往往对应多个吸附位点与复杂构型，传统基于密度泛函理论（DFT）的计算方法面临高昂的时间和资源成本。

---


为应对这一挑战，来自洛桑联邦理工学院（EPFL）的 **Philippe Schwaller** 教授团队与上海交通大学（SJTU）**贺玉莲**教授团队联合提出了一种**多模态 Transformer 框架 AdsMT**，该研究的**共同一作**为**陈俊武**（现 EPFL 博士生）和**黄旭**（现 UC Berkeley 博士生）。

在**不依赖具体吸附位点信息**的前提下，AdsMT 可高效预测 GMAE。该方法以催化剂表面的图结构和吸附质的特征向量为输入，通过引入**跨模态注意力机制（cross-attention）**，有效捕捉吸附质与表面原子之间的复杂交互，从而避免了对所有可能吸附构型的穷举计算。

该研究以「A multi-modal transformer for predicting global minimum adsorption energy」为题，于 2025 年 4 月 4 日刊登于《*Nature Communications*》

![A screenshot of a computer AI-generated content may be incorrect.](https://image.jiqizhixin.com/uploads/editor/fb553cee-3300-4d6e-ba97-d7c6dc9baa26/640.png)

**AdsMT 模型架构**

![Fig. 1](https://image.jiqizhixin.com/uploads/editor/8099181c-227f-4650-bb65-89da8fd9edcc/640.png)

AdsMT 框架由三个模块组成：**用于编码催化剂表面的图编码器**、**用于编码吸附质的向量编码器**，以及**用于融合表征并预测 GMAE 的跨模态编码器**。

其中，跨模态编码器结合了**跨注意力（cross-attention）**与自注意力（**self-attention**）两种机制，精细建模吸附质与表面原子之间的复杂交互。

在第一个跨注意力层中，**吸附质向量表征与表面图结构表征拼接形成查询矩阵（Q）**，而**原子嵌入（atomic embeddings）与原子深度嵌入（depth embeddings）则作为键（K）和值（V）矩阵输入**。其中，原子深度向量用于编码原子在表面结构中的相对层级位置（如顶层或底层原子），帮助模型理解吸附位点的空间分布。

随后在自注意力层中，吸附质、表面原子及其结构信息被统一堆叠输入，进一步通过自注意力机制（Q=K=V）整合为统一的多模态表征，用于最终的吸附能预测。

**GMAE 基准数据集**

![Fig. 3](https://image.jiqizhixin.com/uploads/editor/978cf03e-9cfe-4998-9893-9073a78f3eb3/640.png)

为系统评估模型在不同场景下的泛化能力，研究团队构建了三个具有代表性的用于预测全局最低吸附能（GMAE）的基准数据集，分别为 **OCD-GMAE**、**Alloy-GMAE** 和 **FG-GMAE**。每个样本对应一个**唯一的催化剂表面与吸附质组合**，为 AdsMT 及后续研究提供了稳定、可靠的评测基础。

**AdsMT 模型表现及迁移学习**

![Fig. 4](https://image.jiqizhixin.com/uploads/editor/18475a0c-153f-4860-82da-d52d439cf9ee/640.png)

AdsMT 融合了**定制化图编码器与迁移学习策略**，展现出优异的预测性能。研究团队专门设计了一种图神经网络 Transformer 编码器——**AdsGT**，用于高效提取表面原子间的结构信息。为系统评估其性能，团队将 AdsGT 与现有多种主流图编码器进行了对比，并在上述三个 GMAE 基准数据集上进行了统一评测。除了采用平均绝对误差（MAE）作为基本指标，研究还引入了一个更加严格的评价标准——**成功率（Success Rate, SR）**，即预测值与 DFT 真值误差小于 0.1 eV 的比例。

结果显示，AdsMT 结合 AdsGT编码器后的表现相较于结合其他图编码器而言更加优异，在**Alloy-GMAE 数据集**上，达到了 **0.143 eV 的 MAE** 和 **66.3% 的 SR**，在 **FG-GMAE 数据集**中，取得的**最低 MAE 为 0.095 eV，SR 达到 71.9%**。

为进一步提升模型在数据稀缺场景下的表现（如数据点小于一千且表面成分复杂，涉及 54 种元素的 **OCD-GMAE 数据集**），研究团队引入了**迁移学习策略**，先在包含局部最低吸附能（LMAE）的大型数据集上进行预训练。

为此，研究团队从 OC20 数据集中清洗构建了一个新数据集 **OC20-LMAE**，涵盖 36 万余组表面/吸附质组合与其对应的 LMAE 值。在此基础上进行迁移学习后，AdsMT 在 **OCD-GMAE** 上取得了显著提升，**MAE 降至 0.389 eV，SR 提高至 22.0%**。

**模型可解释性：最优吸附位点识别**

除了预测吸附能外，**识别最优吸附位点**在催化剂设计与反应机理研究中同样至关重要。对此，研究团队进一步探索了**跨注意力层中的注意力分数**，用于估计表面上最有可能发生吸附的位置。值得一提的是，**AdsMT 在训练时并未接收任何吸附位点或构型信息**，但其预测结果与 DFT 基准数据具有较高一致性，展现出出色的可解释性和实际应用潜力。

**不确定性量化评估**

在虚拟筛选实际应用中，**模型能否提供可靠的不确定性估计**尤为关键，有助于科研人员判断预测可信度，从而更高效地分配实验资源。为此，研究团队训练了多个相互独立的 AdsMT 模型副本，通过预测结果的方差来估计不确定性。结果表明，**AdsMT 的不确定性估计与预测 MAE 高度相关**，尤其在低不确定性区间具有极高的预测准确度。

进一步分析显示，**AdsMT 的不确定性估计具有良好的校准性和统计显著性**，有效避免了高估或低估风险的问题，为其在实际高通量催化剂筛选中的应用打下了基础。

**总结与展望**

研究团队提出了一个通用的多模态 Transformer 框架 AdsMT，可在**无需吸附位点信息**的情况下，直接预测表面-吸附质体系的最低吸附能（GMAE）。该模型融合了催化剂表面图与吸附质特征向量两种模态，在GMAE 基准数据集上取得了优异表现，并具备良好的泛化能力。AdsMT 对原子连接关系不变的几何扰动具有鲁棒性，并在预测效率上远超现有方法——比 DFT 快近**8 个数量级**，比 MLIP+启发式搜索快 **4 个数量级**。高效率及低成本使得 AdsMT 适用于**大规模催化剂的虚拟筛选**。

面对数据稀缺问题，研究显示迁移学习可有效提升性能。

未来可结合机器学习势函数（**MLIP**）获取粗略 GMAE 数据进行预训练，进一步引入**主动学习**策略，以扩展数据覆盖范围并增强模型可靠性。此外，AdsMT 的**跨注意力得分具备识别吸附位点的潜力**。

另外，可尝试将吸附构型等领域知识融入训练过程，或将原子重要性作为预测目标纳入损失函数，以增强模型的结构感知能力。

进一步地，AdsMT 可与 MLIP 和 DFT 联合应用于特定反应的催化剂筛选任务：先通过 AdsMT 快速锁定 GMAE 低且不确定性小的候选表面，随后使用 DFT 精细验证，从而在**大幅降低计算成本**的同时实现**可靠的虚拟筛选流程**。

论文链接：[https://www.nature.com/articles/s41467-025-58499-7](https://www.nature.com/articles/s41467-025-58499-7)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。