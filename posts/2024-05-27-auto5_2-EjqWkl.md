---

title: '英伟达赢麻了！马斯克xAI超级算力工厂曝光，10万块H100、数十亿美元'
date: 2024-05-28
author: ByteAILab

---

最近几年，随着大语言模型的飞速发展与迭代，科技巨头们都竞相投入巨额财力打造超级计算机（或大规模 GPU 集群）。他们认为，更强大的计算能力是实现更强大 AI 的关键。

---


早在 2022 年，Meta 即宣布与英伟达共同打造大型 AI 研究超级计算机「AI Research SuperCluster」（RSC），它由 760 个英伟达 DGX A100 系统组成，共有 6080 块 GPU，性能非常强大。

如今，马斯克旗下人工智能初创公司 xAI 传出了打造超级计算机的消息。

据外媒 The Information 报道，最近马斯克向投资者透露，xAI 计划建造超级算力工厂「Gigafactory of Compute」，为 AI 聊天机器人 Grok 的下一个版本提供算力支持。

<img src="https://image.jiqizhixin.com/uploads/editor/1787112f-60af-4490-ade6-bfa25a34683b/640.png"/>

据悉，xAI 计划将 10 万块 H100 专用 GPU 串联一台超级计算机，其规模至少是当前最大 AI 集群的四倍。如果 xAI 的计划能够顺利完成，这台超级计算机将耗费数十亿美元和大量电力。

不过，马斯克似乎很有信心，他的目标是在 2025 年秋季之前让这台超级计算机「跑」起来，并亲自负责按时交付。

当然，xAI 不想单打独斗， 其有望与甲骨文公司（Oracle）合作建造超级计算机。我们知道，xAI 是 Oracle 最大的 H100 服务器芯片租赁客户，已经使用了后者超过 1.5 万块 H100 芯片。

届时，xAI 超级算力工厂建成之后，10 万块 GPU 芯片集群将加速 Grok 聊天机器人的开发，减少语音限制。目前，Grok 的最新版本为 Grok 1.5，该版本实现了长上下文理解和高级推理能力，可以处理 128K token 的长上下文窗口。

<img src="https://image.jiqizhixin.com/uploads/editor/e451b30e-6b2d-43e0-8209-cdb9ee472308/640.png"/>

而据马斯克此前透露，xAI 正在训练的 Grok 2 已经耗费了约 2 万块 H100 GPU，未来进阶版本 Grok 3 可能需要高达 10 万块 H100 GPU。看来，马斯克已经在为 Grok 3 未雨绸缪了。

最后，对于超级算力工厂而言，最关键的找到一个电力充沛（可能需要 100MW）的位置。因此，AI 数据中心位置的选择非常重要。

至于建成的意义是什么？这个规模庞大的超级算力工厂将帮助 xAI 追赶 OpenAI、微软等资金更为雄厚的竞争对手。

此前同样据 The Information 报道，微软和 OpenAI 拟投入超 1000 亿美元打造一个数据中心项目，其中包括一台「星际之门」（Stargate）的 AI 超级计算机，配备了数百万个专用服务器芯片，旨在为 OpenAI 实现 AGI 提供动力。

<img src="https://image.jiqizhixin.com/uploads/editor/ef0ea015-d9ab-403e-a412-d1dc8a41e3e9/640.png"/>

其实，这也不是马斯克第一次投入超算项目。此前，特斯拉就被曝出到 2024 年底，投入远超 10 亿美元打造一台「Dojo 项目」的内部超级计算机，用于处理数据和视频，提高自动驾驶能力并最终实现完全自动驾驶。

此次， 马斯克又在大语言模型领域斥巨资建造超级计算机。有人表示，如果消息属实的话，这将成为游戏改变者。当然，英伟达是最大的赢家。

[参考链接](https://www.theinformation.com/articles/musk-plans-xai-supercomputer-dubbed-gigafactory-of-compute?rc=ks2jbm)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。