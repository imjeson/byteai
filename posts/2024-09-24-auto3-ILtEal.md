---
title: '83%的公司使用AI生成代码，尽管存在安全顾虑'
date: 2024-09-25
author: ByteAILab
---

新Venafi研究揭示AI和开源驱动的开发超越安全 - 许多安全领导者希望禁止AI代码
Venafi，机器身份管理领军者，今天发布了一份新的研究报告，名为《组织在超级开发环境中努力确保AI生成和开源代码的安全性》。![图片](https://ai-techpark.com/wp-content/uploads/2024/09/83-of-Firm-960x540.jpg){ width=60% }

---
该报告探讨了在超速开发环境中确保AI生成和开源代码安全性的风险和挑战。
对美国、英国、德国和法国800名安全决策者的调查显示，将近所有（92%）的安全领导者对其组织内使用AI生成代码表示担忧。其他关键调查结果包括：
安全与开发团队之间的紧张关系：83%的安全领导表示他们的开发人员目前使用AI生成代码，57%表示这已经成为常见做法。然而，72%感到他们别无选择，只能允许开发人员使用AI以保持竞争力，63%考虑禁止使用AI编码，因为存在安全风险。
无法以AI速度确保安全：66%的调查受访者报告称安全团队无法跟上由AI驱动的开发人员。因此，安全领导者感到失去了控制，企业面临风险，78%认为AI开发的代码将导致安全问题，59%因AI的安全隐患而失眠。
治理空白：三分之二（63%）的安全领导认为在其组织中无法治理AI的安全使用，因为他们无法看到AI的使用位置。尽管存在担忧，不到一半的公司（47%）已经实施政策以确保在开发环境中安全使用AI。
“安全团队在一个AI编写代码的新世界中处于两难境地。开发人员已经通过AI进行了超级加速，他们不会放弃超能力。而攻击者正在渗透我们的队伍 - 最近对开源项目的长期干扰和朝鲜人渗透IT的例子仅仅是冰山一角，”Venafi的首席创新官Kevin Bocek表示。“如今任何一个具有LLM的人都可以编写代码，开辟一个全新的战线。代码是最重要的，无论是您的开发人员在超级编码中使用AI，还是外国代理渗透或者某人在财务部门从LLM上训练的代码中获取了谁知道什么。因此，代码才是最重要的！我们必须对代码的身份进行认证，无论它来自何方。”
开源信任困境
在审视开发人员使用AI编写或生成代码的具体担忧时，安全领导者提到了三个最主要的担忧：
开发人员可能过度依赖AI，导致标准降低AI编写的代码将无法得到有效质量检查AI将使用未经良好维护的过时开源库
研究还强调不仅是AI使用开源可能会给安全团队带来挑战：
开源过载：安全领导者平均估计61%的应用程序使用开源。这种对开源的过度依赖可能存在潜在风险，因为86%的受访者认为开源代码鼓励开发人员追求速度而不是安全最佳实践。困扰的验证：90%的安全领导者信任开源库中的代码，其中43%表示完全信任 - 然而75%表示无法验证每行开源代码的安全性。因此，92%的安全领导者认为应该使用代码签名来确保可以信任开源代码。
“最近的CrowdStrike中断显示了代码从开发人员到全球性崩溃的速度带来的影响，”Bocek补充说。“现在的代码可以来自任何地方，包括AI和外国代理。代码来源将只会更多，而不是更少。基于其身份对代码、应用程序和工作负载进行认证，以确保它没有更改并且经过批准可供使用，是我们今天和明天的最佳选择。我们需要以CrowdStrike中断作为未来挑战的完美例子，而不是一次性事件。”
保持代码签名的信任链可以帮助组织防止未经授权的代码执行，同时扩展其操作以跟上开发人员使用AI和开源技术。Venafi的行业首创“阻止未经授权的代码解决方案”可帮助安全团队和管理员在所有环境中维护其代码签名信任链。
“在AI和开源如此强大又如此不可预测的世界中，代码签名成为企业的基础防线，”Bocek总结道。“但是，为了确保这种保护能够持续，代码签名过程必须像它的安全性一样强大。这不仅仅是阻止恶意代码 - 组织需要确保每一行代码来自一个可信任的来源，根据数字签名验证，并保证自签名以来没有被篡改。好消息是代码签名几乎无处不在 - 坏消息是它经常被安全部门无保护地留下来，而他们可以帮助确保其安全。”
要阅读完整报告，请访问 https://venafi.com/lp/organizations-struggle-to-secure-ai-generated-and-open-source-code/.
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。