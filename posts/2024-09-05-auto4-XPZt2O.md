---

title: '全球最大，马斯克4个月建成10万张H100超算集群！xAI算力超越OpenAI，奥特曼怕了'
date: 2024-09-06
author: ByteAILab

---

文章来源：[新智元](https://mp.weixin.qq.com/s/59R6AXHOz6bx2d_06xXhQw)

【导读】两天前，马斯克得意自曝：团队仅用122天，就建成了10万张H100的Colossus集群，未来还会扩展到15万张H100和5万张H200。此消息一出，奥特曼都被吓到了：xAI的算力已经超过OpenAI了，还给员工承诺了价值2亿期权，这是要上天？

![图片来源：由GPTNB生成](http://www.jesonc.com/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1725516767235/FomqzphUaMThB6od473gZYuMjGVh.png)

马斯克的xAI一路狂飙突进，把Sam Altman都整怕了！
就在9月3日，马斯克在推上得意自曝：
团队仅仅用了122天时间，就建成了有10万张H100的Colossus集群，是世界上最强大的AI训练系统。

---

而且，未来几个月规模还要翻一倍，扩展到15万张H100+5万张H200。

最后，马斯克感谢了英伟达和许多其他合作伙伴、供应商。据悉，是戴尔开发、组装了Colossus系统。

马斯克的xAI，已经让几大AI巨头感受到了强烈的威胁。

根据内幕消息，Sam Altman就曾表示，自己是怕了马斯克了！
如今的xAI，不光算力有超越OpenAI之势，还对员工十分大方。有说法指出，对于xAI的研究者，马老板曾承诺过价值2亿美元的期权。

![图片](http://www.jesonc.com/FpeIq4W6spGXEEU65oW85T1N_ye2)

### 马斯克，全力进军超算
相信大家都已经发现：马斯克的超算野心，是愈发藏不住了！
隔三岔五的，就会有劲爆消息曝出。

7月底，xAI启动了位于孟菲斯的超级AI集群的训练，该集群由十万个液冷H100 GPU组成。
十万个H100 GPU消耗的电力大约在70兆瓦，因此这个超算至少会消耗150兆瓦的电力。

8月底，特斯拉宣布了Cortex AI集群，包括5万个英伟达H100 GPU，和2万个特斯拉的Dojo AI晶圆级芯片。

![图片](http://www.jesonc.com/FohBIZm1KO0XUcgaIGuLl53OijGI)

如今看来，这些集群很可能都正式投入运行，甚至已经在训练AI模型了。
不过，马斯克真的有能力让它们全部在线吗？
首要问题是，要调试和优化这些集群的设置，需要一定时间。
其次，xAI还得确保它们获得足够的电力。
我们知道，虽然马斯克的公司一直在用14台独立发电机为其供电，但要为十万块H100 GPU供电，这些电力显然不够。
训练xAI的Grok 2，需要两万块H100；而马斯克预测，要训练Grok 3，可能会需要十万块H100。
所以，xAI的数据中心，建得怎么庞大都不过分。

![图片](http://www.jesonc.com/Furjv6XnwXJ9UCXGOrlVmbXixjjJ)

### 建设速度太快，推测是「部分上线」
122天，也就是4个月的时间，建成10万张H100组成的超算集群，这是个什么速度？
有业内人士表示，通常完成这样一个集群可能需要一年时间。
这个速度，这个规模，很马斯克。

![图片](http://www.jesonc.com/FjYQospBe5VQl4wYdH0xi4_KyAF-)

但也有人猜测，他可能有夸大其词的倾向，高估了在单一集群中实际运行的GPU数量。
囤足10万张芯片、放在一起共同运行，并不意味着就是单一集群。
论GPU数量，Meta在今年1月...

(以上内容省略，详情请查看原文链接)

---

Source:
- [原文链接](https://www.aixinzhijie.com/article/6846604)
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。