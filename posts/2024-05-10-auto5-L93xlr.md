---
title: '10年前VAE经典论文获奖，ICLR 2024首个时间检验奖公布'
date: 2024-05-11
author: ByteAILab

---

ICLR 2024 评选出的时间检验奖，在各自领域可谓是开山之作。

由深度学习巨头、图灵奖获得者 Yoshua Bengio 和 Yann LeCun 在 2013 年牵头举办的 ICLR 会议，在走过第一个十年后，终于迎来了首届时间检验奖。

---


为了评选出获奖论文，项目主席审查了 2013 年和 2014 年 ICLR 论文，并寻找具有长期影响力的论文。

今年，由 Diederik P. Kingma、Max Welling 合作撰写的论文获得了该奖项，获奖论文为《 Auto-Encoding Variational Bayes 》；论文《 Intriguing properties of neural networks 》获得了亚军。

ICLR 2024 时间检验奖

论文《 Auto-Encoding Variational Bayes 》作者共有两位，他们当时均来自于阿姆斯特丹大学。

论文地址：https://arxiv.org/pdf/1312.6114
论文标题：Auto-Encoding Variational Bayes
作者：Diederik P. Kingma 、 Max Welling

获奖理由：概率建模是对世界进行推理的最基本方式之一。这篇论文率先将深度学习与可扩展概率推理（通过所谓的重新参数化技巧摊销均值场变分推理）相结合，从而催生了变分自动编码器 (VAE)。这项工作的持久价值源于其优雅性。用于开发 VAE 的原理加深了我们对深度学习和概率建模之间相互作用的理解，并引发了许多后续有趣的概率模型和编码方法的开发。这篇论文对于深度学习和生成模型领域产生了重大影响。

作者介绍

Diederik P. Kingma 现在是谷歌的一名研究科学家。根据领英介绍，Kingma 曾经是 OpenAI 初创团队的一员，在 OpenAI 工作期间领导了一个算法团队，专注于基础研究。2018 年，Kingma 跳槽到谷歌，加入 Google Brain（现在合并为 Google DeepMind），专注于生成式模型研究，包括扩散模型和大型语言模型。

Kingma 主要研究方向是可扩展的机器学习方法，重点是生成模型。他是变分自编码器 (VAE，即本次获奖研究)、Adam 优化器、Glow 和变分扩散模型等研究的主要作者。根据 Google Scholar 显示，Kingma 的论文引用量达到 24 万多次。

论文另一位作者 Max Welling 现在为阿姆斯特丹大学机器学习教授。和一般机器学习研究者不同，Max Welling 并不是计算机专业科班出身，而是在世界顶尖公立研究型大学 —— 荷兰乌得勒支大学学了 11 年的物理，而且导师是荷兰理论物理学家、1999 年诺贝尔物理学奖得主 Gerard 't Hooft。在 Hooft 的指导下，Max Welling 于 1998 年拿到了量子物理学博士学位。

时间检验奖亚军论文

ICLR 2024 亚军论文颁给了《 Intriguing properties of neural networks 》。论文作者共有七位，他们当时分别来自谷歌、纽约大学、蒙特利尔大学。

在过去的十年中，他们中的大多数已经离开了原来的公司和机构。

Christian Szegedy 现在为 xAI 联合创始人；Wojciech Zaremba 为 OpenAI 联合创始人；Ilya Sutskever 是 OpenAI 联合创始人（不过自从 OpenAI 发生宫斗后，暂无消息 ）；Joan Bruna 现在为纽约大学副教授（Associate Professor）；Dumitru Erhan 为谷歌 DeepMind 研究总监；Ian Goodfellow 加入谷歌DeepMind；Rob Fergus 现在为谷歌 DeepMind 的研究科学家。

论文地址：https://arxiv.org/pdf/1312.6199
论文标题：Intriguing properties of neural networks
作者：Christian Szegedy、Wojciech Zaremba、Ilya Sutskever、Joan Bruna、Dumitru Erhan、Ian Goodfellow 、 Rob Fergus

获奖理由：随着深度神经网络在实际应用中越来越受欢迎，了解神经网络何时以及如何出现不良行为非常重要。本文强调了神经网络可能容易受到输入中几乎察觉不到的微小变化的影响。这一想法催生了对抗性攻击（试图欺骗神经网络）以及对抗性防御（训练神经网络不被欺骗）的研究。

这篇论文发表于 2014 年，可以说是对抗样本（Adversarial Examples）的开山之作。论文发现神经网络对数据的理解跟人类的理解方式并不相同，在此基础上，研究者又发现给输入数据添加扰动（也就是噪声），神经网络的输出会产生变化，他们将这种扰动后的图像称为对抗样本。

参考链接：https://blog.iclr.cc/2024/05/07/iclr-2024-test-of-time-award/

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。