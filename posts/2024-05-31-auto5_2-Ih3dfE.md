---
title: '神笔马良画出三维世界，基于线稿的3D生成编辑方法SketchDream来了'
date: 2024-06-01
author: ByteAILab

---

AIxiv专栏是机器之心发布学术、技术内容的栏目。过去数年，机器之心AIxiv专栏接收报道了2000多篇内容，覆盖全球各大高校与企业的顶级实验室，有效促进了学术交流与传播。

---
如果您有优秀的工作想要分享，欢迎投稿或者联系报道。投稿邮箱：liyazhou@jiqizhixin.com；zhaoyunfeng@jiqizhixin.com。本论文作者是中国科学院计算技术研究所高林老师及其博士生刘锋林，香港城市大学傅红波老师，卡迪夫大学来煜坤老师。该项研究工作受到国家自然科学基金委、北京市自然科学基金委、北京市科学技术委员会的资助，由信息高铁智算算力网平台提供算力支持。基于人工智能的数字内容生成，即 AIGC 在二维图像生成领域取得了很大的成功，但在三维生成方面仍存在挑战。智能化生成三维模型在 AR/VR、工业设计、建筑设计和游戏影视等方面都有应用价值，现有的智能化三维生成方法已经可以生成高质量的三维模型，但如何对生成结果进行精确控制，并对真实模型或生成的模型进行细节的修改，从而让用户自由定制高质量的三维模型仍然是一个待解决的问题。近期，一篇题为《SketchDream: Sketch-based Text-to-3D Generation and Editing》的论文提出了基于线稿和文本的三维内容生成和编辑方法 SketchDream [1]，论文发表在 SIGGRAPH 2024，并被收录于图形学顶级期刊 ACM Transactions on Graphics。这个 3D AIGC 工作助你成为神笔马良，通过画笔画出三维世界，已入选 SIGGRAPH 精选亮点工作宣传片。使用该系统，即使用户不会使用复杂的三维软件，也可以基于线稿自由创作三维内容，并对真实的模型进行修改和编辑。先来看看使用 SketchDream 创作的模型的效果：[链接](https://mp.weixin.qq.com/s/OwoUQpx9QlEf6LhfiwGN8Q)。图 1 基于 SketchDream 的三维生成效果 图 2 基于 SketchDream 的三维编辑效果。背景 最近，AI 绘画非常火爆，基于 Stable Diffusion [2] 和 ControlNet [3] 等方法，通过指定文本可以生成高真实感的二维图像。最新的视频生成方法 Sora [4]，已经可以基于文本生成高质量影视级的视频。但是，上述工作无法直接生成高质量的三维模型，更无法对现有的三维模型进行编辑和修改。针对上述问题，DreamFusion [5] 提出了 Score Distillation Sampling (SDS) 的方法，利用二维图像的 Diffusion model 生成模型优化神经辐射场，基于文本合成任意类别的高质量的三维模型。后续一系列工作 [6][7][8] 对该方法进行了改进，提升了生成的三维模型的质量，并使生成的过程更加稳定。但是，仅仅基于文本，难以实现对几何细节的控制，例如物体的形状和轮廓，不同的组件的形状和位置等。为了提高可控性，许多方法 [9][10] 使用额外的图像作为输入，生成高质量的模型，但用户依然需要提前获取合适的图像。除了三维内容生成，如何对已有的三维模型进行再创作，即对真实的三维模型进行修改和编辑也是非常重要的问题。Vox-e [11] 和 DreamEditor [12] 根据文本自适应的确定三维编辑区域，再实现基于文本的编辑效果。为了实现更精细的控制，SKED [13] 使用线稿编辑三维模型，但如何处理复杂编辑情景仍然较为困难。线稿作为一种用户友好的交互方法，被广泛用于三维建模。艺术家们通常会先绘制物体的线稿，再进一步使用专业软件进行建模。然而，直接使用线稿生成高质量的三维物体存在下述挑战：首先，线稿风格多样且过于稀疏，很难使用单视角的线稿约束三维物体的生成；其次，二维线稿只包含了单视角的信息，如何解决歧义性，生成侧面和背面区域较为困难。基于线稿的模型编辑则更具挑战性，如何分析并处理不同组件的关系，如何保证编辑区域的生成质量，如何保持非编辑区域不变，都是需要解决的问题。SketchDream 算法原理 基于线稿的多视角图像生成网络给定单视角的手绘线稿后，仅在线稿对应的视角添加约束，无法生成合理的三维模型。因此，需要将线稿的信息有效地传播到三维空间中的新视角，从而合成与线稿对应的高质量的模型。SketchDream 算法构建了基于线稿的多视角图像生成的扩散模型。具体而言，算法在多视角...

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。