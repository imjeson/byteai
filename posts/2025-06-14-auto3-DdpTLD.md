---

title: 'KAYTUS发布升级版MotusAI以加速大型语言模型部署'
date: 2025-06-15
author: ByteAILab

---

简化推理性能、工具兼容性、资源调度和系统稳定性，以快速推动大型AI模型的部署。![图片](https://ai-techpark.com/wp-content/uploads/KAYTUS-1.jpg){ width=60% }

---

KAYTUS，一家领先的端到端AI和液冷解决方案提供商，今天在2025年ISC高性能会议上宣布最新版本的MotusAI AI DevOps平台的发布。升级版MotusAI平台在大型模型推理性能方面提供了显著增强，并支持多种开源工具的广泛兼容性，涵盖大型模型的整个生命周期。该平台旨在实现统一和动态资源调度，大幅提高大型AI模型开发和部署的资源利用率和运营效率。MotusAI的最新版本将进一步加速AI adoption，推动教育、金融、能源、汽车和制造等关键领域的业务创新。
随着大型AI模型越来越多地嵌入现实世界应用，企业正在大规模部署它们，以在广泛的行业中创造实际价值。然而，许多组织在AI adoption中仍面临关键挑战，包括较长的部署周期、严格的稳定性要求、碎片化的开源工具管理和低计算资源利用率。为了解决这些痛点，KAYTUS推出了最新版本的MotusAI AI DevOps平台，旨在简化AI部署，增强系统稳定性，并优化大型模型操作的AI基础设施效率。
增强推理性能以确保服务质量
部署AI推理服务是一项复杂的任务，涉及服务部署、管理和持续的健康监控。这些任务需要在模型和服务治理、通过加速框架进行性能调优，以及长期服务稳定性等方面达到严格标准，通常需要大量的人力、时间和技术专长的投资。
升级版MotusAI提供强大的大型模型部署能力，使可见性和性能完美对齐。通过集成优化框架，如SGLang和vLLM，MotusAI确保能够快速、自信地部署高性能、分布式的推理服务。为支持大参数模型，MotusAI利用智能资源和网络亲和力调度加快上线时间，同时最大化硬件利用率。其内置监控能力覆盖整个栈，从硬件和平台到节点和服务，提供自动故障诊断和快速服务恢复。MotusAI还支持基于实时使用和资源监控的推理工作负载动态扩展，从而提供增强的服务稳定性。
全面的工具支持以促进AI adoption
随着AI模型技术的快速发展，支持开发工具的生态系统也变得愈发复杂。开发者需要一个简化的通用平台，以有效选择、部署和操作这些工具。
升级版MotusAI为广泛的领先开源工具提供了广泛支持，使企业用户能够按需配置和管理其模型开发环境。内置工具，如LabelStudio，加速了数据标注和跨多类别的同步，提高了数据处理效率，加快了模型开发周期。MotusAI还提供整个AI模型生命周期的集成工具链。这包括用于数据标注和治理的LabelStudio和OpenRefine，用于大型模型微调的LLaMA-Factory，用于大型模型应用开发的Dify和Confluence，以及用于文本到图像生成的Stable Diffusion。这些工具共同赋能用户快速采用大型模型，并在规模上提高开发生产力。
在同一节点上混合训练-推理调度以最大化资源效率
高效利用计算资源仍然是初创企业和中小型企业在AI adoption初期的关键优先事项。传统AI集群通常为训练和推理任务分别分配计算节点，限制了两种工作负载之间的资源调度的灵活性和效率。
升级版MotusAI通过支持在单个节点上混合调度训练和推理工作负载，克服了传统的局限性，使各种任务类型的无缝集成和动态编排成为可能。配备先进的GPU调度能力，MotusAI支持按需资源分配，赋予用户根据工作负载要求高效管理GPU资源的能力。MotusAI还具有多维GPU调度功能，包括细粒度分区和对多实例GPU (MIG) 的支持，满足模型开发、调试和推理等广泛应用场景的需求。
MotusAI的增强调度器显著优于基于社区的版本，在大规模POD部署中实现了5倍的任务吞吐量提升和5倍的延迟降低。它能够快速启动和准备数百个POD的环境，同时支持训练和推理的动态工作负载扩展和潮汐调度。这些能力提高了在广泛现实世界AI场景中的任务编排的无缝性。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。