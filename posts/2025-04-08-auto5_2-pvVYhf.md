---

title: 'Llama 4在测试集上训练？内部员工、官方下场澄清，LeCun转发'
date: 2025-04-09
author: ByteAILab

---

大家翘首以盼的 Llama 4，用起来为什么那么拉跨？

Llama 4 这么大的节奏，Meta 终于绷不住了。

本周二凌晨，Meta Gen AI 团队负责人发表了一份澄清说明（针对外界质疑「在测试集上训练」等问题），大佬 Yann LeCun 也进行了转发。

---


![图片](https://image.jiqizhixin.com/uploads/editor/ec3b7321-9c8f-48a1-84ac-4294b335777b/640.png)

> 很高兴能让大家用上 Llama 4，我们已经听说人们使用这些模型取得了很多出色的成果。尽管如此，我们也听到一些关于不同服务质量参差不齐的报告。由于我们在模型准备就绪后就推出了它们，因此我们预计所有公开部署都需要几天时间才能完成。我们将继续努力修复错误并吸引合作伙伴。
>
> 我们还听说有人声称 Llama 4 在测试集上进行训练，这根本不是事实，我们永远不会这样做。我们愿意理解为：人们看到的不稳定是由于需要稳定部署。相信 Llama 4 模型是一项重大进步，期待与社区的持续合作以释放它们的价值。

当前 Llama 4 性能不佳是被部署策略给拖累了吗？权威的大模型基准平台 LMArena 也站出来发布了一些 Llama 4 的对话结果，希望部分解答人们的疑惑。

![图片](https://image.jiqizhixin.com/uploads/editor/e00ebc01-7454-462c-bf22-da75f6cb1e0d/640.png)

链接：[LMArena实验对战](https://huggingface.co/spaces/lmarena-ai/Llama-4-Maverick-03-26-Experimental_battles)

可以看到，其中很多同问题的回答上，不论是跟哪家大模型比，Llama 4 的效果都是更好的。

但这究竟是模型真的好，还是 Meta 为了拯救口碑而进行的一系列公关活动？我们需要一起来梳理一下这一事件的发展脉络。

**Llama 4：买家秀 vs. 卖家秀**

Llama 4 是 Meta 在 4 月 6 日发布的模型，分为 Llama 4 Scout、Llama 4 Maverick 和 Llama 4 Behemoth 这几个版本。Meta 官方宣称新模型可以实现无与伦比的高智商和效率。

![图片](https://image.jiqizhixin.com/uploads/editor/32f92acd-12a9-42b2-a494-a5cf69463df2/640.png)

在大模型竞技场（Arena），Llama 4 Maverick 的总排名第二，成为第四个突破 1400 分的大模型。其中开放模型排名第一，超越了 DeepSeek；在困难提示词、编程、数学、创意写作等任务中排名均为第一；大幅超越了自家 Llama 3 405B，得分从 1268 提升到了 1417；风格控制排名第五。

![图片](https://image.jiqizhixin.com/uploads/editor/9bb66abe-5bc3-46bb-8298-bfd60136fcd8/640.png)

这样的成绩让开源社区以为又迎来一个新王，于是纷纷下载尝试。但没想到的是，这个模型并没有想象中好用。比如网友 @deedydas 发帖称，Llama 4 Scout（109B）和 Maverick（402B）在 Kscores 基准测试中表现不佳，不如 GPT-4o、Gemini Flash、Grok 3、DeepSeek V3 以及 Sonnet 3.5/7 等模型。而 Kscores 基准测试专注于编程任务，例如代码生成和代码补全。

另外还有网友指出，Llama 4 的 OCR、前端开发、抽象推理、创意写作等问题上的表现能力也令人失望。（参见《[Meta Llama 4 被疑考试「作弊」](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650963634&idx=1&sn=4935ed3758561c8ee8366adce6b3be1f&scene=21#wechat_redirect)》）

于是就有人质疑，模型能力这么拉跨，发布时晒的那些评分是怎么来的？

**内部员工爆料  Meta 工程师原贴对线**

在关于该模型表现反差的猜测中，「把测试集混入训练数据」是最受关注的一个方向。

在留学论坛「一亩三分地」上，一位职场人士发帖称，由于 Llama 4 模型始终未达预期，「公司领导层建议将各个 benchmark 的测试集混合在 post-training 过程中」，ta 因无法接受这种做法而辞职，并指出「Meta 的 VP of AI 也是因为这个原因辞职的」（指的是在上周宣布离职的 Meta AI 研究副总裁 Joelle Pineau）。

![图片](https://image.jiqizhixin.com/uploads/editor/d2f60c39-98bf-405b-8afa-53569cbc72c9/640.png)

由于发帖者没有实名认证信息，我们无法确认这一帖子的可靠性，相关信息也缺乏官方证实和具体证据。

不过，在该贴的评论区，有几位 Meta 员工反驳了楼主的说法，称「并没有这种情况」，「为了刷点而 overfit 测试集我们从来没有做过」。

![图片](https://image.jiqizhixin.com/uploads/editor/c6c4adba-ef22-4773-8bf0-8fe541bbadc8/640.png)

其中一位还贴出了自己的真名 ——「Licheng Yu」。领英资料显示，Licheng Yu 是 Facebook AI 的研究科学家主管，已经在 Meta 全职工作了五年多，其工作内容包括支持 Llama 4 的后训练 RL。

如前文所诉，Meta Gen AI 团队负责人也发推反驳了用测试数据训练模型的说法。

不过，有些测试者发现了一些有意思的现象。比如普林斯顿大学博士生黄凯旋指出，Llama 4 Scout 在 MATH-Perturb 上的得分「独树一帜」，Original 和 MATH-P-Simple 数据集上的表现差距非常大（两个数据集本身非常相似，后者只在前者的基础上进行了轻微扰动），这点很令人惊讶。

![图片](https://image.jiqizhixin.com/uploads/editor/722e117f-0451-417b-8247-885feda1c9f9/640.png)

这是没有做好数据增强的问题吗？或许也可以认为他们的模型为了标准测试做了「过度」优化？

虽然在数学方面，这个问题还没有答案。不过，在对话方面，Meta 的确指出他们针对对话做了优化。他们在公告中提到，大模型竞技场上的 Maverick 是「实验性聊天版本」，与此同时官方 Llama 网站上的图表也透露，该测试使用了「针对对话优化的 Llama 4 Maverick」。

![图片](https://image.jiqizhixin.com/uploads/editor/0d6fde36-84fd-41a4-a1b2-32f91f97ebc0/640.png)

针对这个版本问题，大模型竞技场官方账号也给出了回应，称 Meta 的做法是对平台政策的误读，应该更清楚地说明他们的模型是定制模型。此外，他们还将 Meta 在 HuggingFace 上发布的版本添加到了竞技场进行重新测试，结果有待公布。

**大模型竞技场公布对战数据**

最后，不论训练策略和 Deadline 的是与非，Llama 4 是否经得起考验，终究还是要看模型本身的实力。目前在大模型竞技场上，Llama 4 展示了一系列问题上的 good case。其中不仅有生成方案的：

![图片](https://image.jiqizhixin.com/uploads/editor/fc8f4b2f-979b-4c45-90d0-e12ad5efc03f/640.png)

也有生成网页代码的：

![图片](https://image.jiqizhixin.com/uploads/editor/4a76af1d-4d07-4773-af4f-7dc5c0ea2547/640.png)

看起来，Llama 4 也支持更多种类的语言。

![图片](https://image.jiqizhixin.com/uploads/editor/a07bca95-d85a-4df5-ad1f-12d578354dc4/640.png)

在推特的评论区里我们可以看到，人们对于这一系列展示仍然褒贬不一。

虽然 LM Arena 表示未来会将 HuggingFace 上的 Llama 4 版本引入进行比较，但已有人表示，现在我已经很难相信大模型竞技场了。

无论如何，在人们的大规模部署和调整之后，我们会很快了解 Llama 4 的真实情况。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。