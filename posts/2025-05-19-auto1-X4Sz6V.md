---
title: '科学家发现：人工智能在辩论中比人类更具说服力'
date: 2025-05-20
author: ByteAILab

---

人工智能可以在劝说别人方面与人类表现得一样好，甚至更好，而不仅仅是因为它不能大喊，研究发现。

---
专家表示，这些结果令人担忧，尤其是在选举诚信方面的潜在影响。“如果可以大规模部署具有说服力的人工智能，你可以想象有成群的机器人微针对未决票选民，微妙地用感觉真实的政治叙事来推动他们，”瑞士洛桑联邦理工学院的研究首席作者弗朗切斯科·萨尔维说。他补充说，这种影响很难追踪，更难以监管，并且几乎不可能在实时中揭穿。“如果恶意行为者尚未开始利用这些工具来传播错误信息和不公正的宣传，我会感到惊讶，”萨尔维表示。但他指出，具有说服力的人工智能也有潜在的好处，从减少阴谋信仰和政治极化到帮助人们养成更健康的生活方式。

萨尔维和他的同事在《自然人类行为》期刊上撰文报告了他们如何进行在线实验，将300名参与者与300名人类对手匹配，而另外300名参与者则与Chat GPT-4（一种被称为大型语言模型（LLM）的人工智能）匹配。每对被分配一个辩论命题。这些命题的争议程度各不相同，从“学生是否应该穿校服？”到“堕胎是否合法？”每个参与者随机分配一个辩论立场。

在600场辩论的结果中，当没有提供个人信息时，Chat GPT-4在说服他人方面与人类对手表现相似。然而，访问个人信息使人工智能（而非人类）更具说服力：在对手说服力不相等的情况下，AI在64%的时间里比人类更能改变参与者的观点。进一步调查发现，人工智能的说服力仅在未引发强烈意见的话题中明显。研究小组还发现，人类参与者在与人工智能配对时正确猜测对手身份的概率约为三分之四。他们还发现，AI使用的风格比人类参与者更具分析性和结构化，而并非每个人都会为自己认同的观点辩论。但研究小组警告说，这些因素并不能解释人工智能的说服力。

相反，这种效果似乎来自于人工智能根据个人的特点调整其论点。“这就像与一个不仅能提出好观点的人辩论：他们能够根据确切的反应推送你的观点，”萨尔维表示，并指出如果提供更多详细的个人信息，例如从社交媒体活动推测出的信息，这种效果可能会更显著。剑桥大学的社交心理学教授桑德·范德林登表示，该研究重新引发了对使用个性化LLM对公共舆论进行大众操控的潜在讨论。他指出，一些研究——包括他自己的研究——表明，LLM的说服力在于使用分析推理和证据，而有一项研究发现个人信息并未增加Chat-GPT的说服力。牛津大学的人工智能研究人员迈克尔·伍德里奇教授表示，虽然这些系统可能有积极的应用，例如用作健康聊天机器人，但还有更多令人不安的应用，包括恐怖组织对青少年的激进化，这类应用已经成为可能。“随着人工智能的发展，我们将看到越来越多的技术滥用可能性，”他补充道，“立法者和监管机构需要积极主动，以确保他们走在这些滥用行为前面，而不是在进行一场无休止的追赶游戏。”

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。