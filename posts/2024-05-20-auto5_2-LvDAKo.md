---

title: '首个GPU高级语言，大规模并行就像写Python，已获8500 Star'
date: 2024-05-21
author: ByteAILab

---

最多可支持 10000+ 个并发线程。

经过近 10 年的不懈努力，对计算机科学核心的深入研究，人们终于实现了一个梦想：在 GPU 上运行高级语言。

---


上周末，一种名为 Bend 的编程语言在开源社区引发了热烈的讨论，GitHub 的 Star 量已经超过了 8500。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicWmhmg0p2JGibzsWpwkM8G0Mq8icKdB8jicNoLz7Fk5XSV6D8vJ2XibicAfG0hufWCvx3HqPnibgWibztCQ/640?wx_fmt=png&from=appmsg)

GitHub：[https://github.com/HigherOrderCO/Bend](https://github.com/HigherOrderCO/Bend)

作为一种大规模并行的高级编程语言，它仍处于研究阶段，但提出的思路已经让人们感到非常惊讶。使用 Bend，你可以为多核 CPU/GPU 编写并行代码，而无需成为具有 10 年经验的 C/CUDA 专家，感觉就像 Python 一样！

![图片](https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicWmhmg0p2JGibzsWpwkM8G0npcGAYcjlvPfMXg939hsJ6utNfqiciasMib192O8U4sCn1Y12N7mX7OIw/640?wx_fmt=gif&from=appmsg)

是的，Bend 采用了 Python 语法。

与 CUDA、Metal 等低级替代方案不同，Bend 具有 Python、Haskell 等表达性语言的功能，包括快速对象分配、完全闭包支持的高阶函数、无限制的递归，甚至 continuation。Bend 运行在大规模并行硬件上，具有基于核心数量的近线性加速。Bend 由 HVM2 运行时提供支持。

该项目的主要贡献者 Victor Taelin 来自巴西，他在 X 平台上分享了 Bend 的主要特性和开发思路。

首先，Bend 不适用于现代机器学习算法，因为这些算法是高度正则化的（矩阵乘法），具有预先分配的内存，并且通常已经有编写好的 CUDA 内核。

Bend 的巨大优势体现在实际应用中，这是因为「真正的应用程序」通常没有预算来制作专用的 GPU 内核。试问，谁在 CUDA 中制作了网站？而且，即使有人这样做了，也是不可行的，因为：

1. 真正的应用程序需要从许多不同的库导入函数，无法为它们编写 CUDA 内核；
2. 真实的应用程序具有动态函数和闭包；
3. 真实的应用程序会动态且不可预测地分配大量内存。

Bend 完成了一些新的尝试，并且在某些情况下可以相当快，但现在想写大语言模型肯定是不行的。

作者对比了一下旧方法和新的方法，使用相同的算法树中的双调排序，涉及 JSON 分配和操作。Node.js 的速度是 3.5 秒（Apple M3 Max），Bend 的速度是 0.5 秒（NVIDIA RTX 4090）。

是的，目前 Bend 需要整块 GPU 才能在一个核心上击败 Node.js。但另一方面，这还是一个初生的新方法与大公司（Google）优化了 16 年的 JIT 编译器在进行比较。未来还有很多可能性。

**如何使用**

在 GitHub 上，作者简要介绍了 Bend 的使用流程。

首先，安装 Rust。如果你想使用 C 运行时，请安装 C 编译器（例如 GCC 或 Clang）；如果要使用 CUDA 运行时，请安装 CUDA 工具包（CUDA 和 nvcc）版本 12.x。Bend 目前仅支持 Nvidia GPU。

然后，安装 HVM2 和 Bend：

```
cargo +nightly install hvm
cargo +nightly install bend-lang
```

最后，编写一些 Bend 文件，并使用以下命令之一运行它：

```
bend run    <file.bend> # uses the Rust interpreter (sequential)
bend run-c  <file.bend> # uses the C interpreter (parallel)
bend run-cu <file.bend> # uses the CUDA interpreter (massively parallel)
```
你还可以使用 gen-c 和 gen-cu 将 Bend 编译为独立的 C/CUDA 文件，以获得最佳性能。但 gen-c、gen-cu 仍处于起步阶段，远没有像 GCC 和 GHC 这样的 SOTA 编译器那么成熟。

**Bend 中的并行编程**

这里举例说明可以在 Bend 中并行运行的程序。例如，表达式：

```
(((1 + 2) + 3) + 4)
```

不能并行运行，因为 + 4 取决于 + 3，而 + 3 又取决于 (1+2)。而表达式：

```
((1 + 2) + (3 + 4))
```

可以并行运行，因为 (1+2) 和 (3+4) 是独立的。Bend 并行运行的条件就是符合并行逻辑。

再来看一个更完整的代码示例：

```
# Sorting Network = just rotate trees!
def sort (d, s, tree):
  switch d:
    case 0:
      return tree
case _:
      (x,y) = tree
lft   = sort (d-1, 0, x)
      rgt   = sort (d-1, 1, y)
      return rots (d, s, lft, rgt)
# Rotates sub-trees (Blue/Green Box)
def rots (d, s, tree):
  switch d:
    case 0:
      return tree
case _:
      (x,y) = tree
return down (d, s, warp (d-1, s, x, y))

(...)

```

该文件实现了具有不可变树旋转的双调排序器。它不是很多人期望的在 GPU 上快速运行的算法。然而，由于它使用本质上并行的分治方法，因此 Bend 会以多线程方式运行它。一些速度基准：

- CPU，Apple M3 Max，1 个线程：12.15 秒
- CPU，Apple M3 Max，16 线程：0.96 秒
- GPU，NVIDIA RTX 4090，16k 线程：0.21 秒

不执行任何操作即可实现 57 倍的加速。没有线程产生，没有锁、互斥锁的显式管理。我们只是要求 Bend 在 RTX 上运行我们的程序，就这么简单。

Bend 不限于特定范例，例如张量或矩阵。任何的并发系统，从着色器到类 Erlang 的 actor 模型都可以在 Bend 上进行模拟。例如，要实时渲染图像，我们可以简单地在每个帧上分配一个不可变的树：

```
# given a shader, returns a square image
def render (depth, shader):
  bend d = 0, i = 0:
    when d < depth:
      color = (fork (d+1, i*2+0), fork (d+1, i*2+1))
    else:
      width = depth / 2
color = shader (i % width, i /width)
  return color
# given a position, returns a color
# for this demo, it just busy loops
def demo_shader (x, y):
  bend i = 0:
    when i < 5000:
      color = fork (i + 1)
    else:
      color = 0x000001
return color
# renders a 256x256 image using demo_shader
def main:
  return render (16, demo_shader)

```

它确实会起作用，即使涉及的算法在 Bend 上也能很好地并行。长距离通信通过全局 beta 缩减（根据交互演算）执行，并通过 HVM2 的原子链接器正确有效地同步。

最后，作者表示 Bend 现在仅仅是第一个版本，还没有在合适的编译器上投入太多精力。大家可以预期未来每个版本的原始性能都会大幅提高。而现在，我们已经可以使用解释器，从 Python 高级语言的角度一睹大规模并行编程的样子了。

**参考内容**:

- [https://news.ycombinator.com/item?id=40390287](https://news.ycombinator.com/item?id=40390287)
- [https://x.com/VictorTaelin?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor](https://x.com/VictorTaelin?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor)
- [https://x.com/DrJimFan/status/1791514371086250291](https://x.com/DrJimFan/status/1791514371086250291)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。