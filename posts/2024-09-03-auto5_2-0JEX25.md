---

title: '迈向「多面手」医疗大模型，上交大团队发布大规模指令微调数据、开源模型与全面基准测试'
date: 2024-09-04
author: ByteAILab

---

编辑 | ScienceAI

近日，上海交通大学、上海 AI Lab、中国移动等机构的联合研究团队，在 arXiv 预印平台发布文章《Towards Evaluating and Building Versatile Large Language Models for Medicine》，从数据、测评、模型多个角度全面分析讨论了临床医学大语言模型应用。

文中所涉及的所有数据和代码、模型均已开源。

---


GitHub: [https://github.com/MAGIC-AI4Med/MedS-Ins](https://github.com/MAGIC-AI4Med/MedS-Ins)

Paper Link: [https://arxiv.org/abs/2408.12547](https://arxiv.org/abs/2408.12547)

Leaderboard: [https://henrychur.github.io/MedS-Bench/](https://henrychur.github.io/MedS-Bench/)

**概览**

近年来，大型语言模型（LLM）取得了显著的进展，并在医疗领域取得了一定成果。这些模型在医学多项选择问答（MCQA）基准测试中展现出高效的能力，并且 UMLS 等专业考试中达到或超过专家水平。

然而，LLM 距离实际临床场景中的应用仍然有相当长的距离。其主要问题，集中在模型在处理基本医学知识方面的不足，如在解读 ICD 编码、预测临床程序以及解析电子健康记录（EHR）数据方面的误差。

这些问题指向了一个关键：当前的评估基准主要关注于医学考试选择题，而不能充分反映 LLM 在真实临床情景中的应用。

本研究提出了一项新的评估基准 MedS-Bench，该基准不仅包括多项选择题，还涵盖了临床报告摘要、治疗建议、诊断和命名实体识别等 11 项高级临床任务。

研究团队通过此基准对多个主流的医疗模型进行了评估，发现即便是使用了 few-shot prompting，最先进模型，例如，GPT-4，Claude 等，在处理这些复杂的临床任务时也面临困难。

为解决这一问题，受到 Super-NaturalInstructions 的启发，研究团队构建了首个全面的医学指令微调数据集 MedS-Ins，该数据集整合了来自考试、临床文本、学术论文、医学知识库及日常对话的 58 个生物医学文本数据集，包含超过 1350 万个样本，涵盖了 122 个临床任务。

在此基础上，研究团队对开源医学语言模型进行指令调整，探索了 in-context learning 环境下的模型效果。

该工作中开发的医学大语言模型——MMedIns-Llama 3，在多种临床任务中的表现超过了现有的领先闭源模型，如 GPT-4 和 Claude-3.5。MedS-Ins 的构建极大的促进了医学大语言模型在实际临床场景的中的能力，使其应用范围远超在线聊天或多项选择问答的限制。

相信这一进展不仅推动了医学语言模型的发展，也为未来临
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。