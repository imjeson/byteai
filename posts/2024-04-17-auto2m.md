---
title: 'Hugging Face推出Idefics2视觉语言模型'
date: 2024-04-17
author: Jeson
---

Hugging Face宣布推出Idefics2，这是一个多功能模型，能够根据图片和文本理解和生成文本回应。该模型在回答视觉问题、描述视觉内容、从图片创建故事、提取文档信息，甚至基于视觉输入执行算术运算方面设定了新的基准。
Idefics2以仅有80亿个参数和其开放许可证（Apache 2.0）所带来的多功能性，以及显著增强的光学字符识别（OCR）能力，大幅超越了其前身Idefics1。
该模型不仅在视觉问题回答基准测试中展现出卓越的表现，还能够与诸如LLava-Next-34B和MM1-30B-chat等远大于自身的同时代模型齐头并进：

Idefics2最具吸引力的特点之一是从一开始就与Hugging Face的Transformers集成，确保了对广泛的多模态应用进行简易微调。对于那些渴望深入了解的人，可以在Hugging Face Hub上找到可供实验的模型。
Idefics2的一大亮点是其全面的训练理念，融合了包括网络文档、图像-标题对和OCR数据在内的公开可用数据集。此外，还引入了一个创新的微调数据集，名为“大锅”，汇集了50个经过精心策划的数据集，用于多方面对话训练。
Idefics2展现了一种经过精心设计的图像处理方法，保持着原生分辨率和宽高比，这与计算机视觉中常规的调整大小规范有明显不同之处。其架构从先进的OCR能力中受益良多，能够熟练地转录图像和文档中的文本内容，并且在解读图表和图形方面表现出色。
将视觉特征简化集成到语言骨干部分标志着其前身架构的转变，通过采用学习型Perceiver池化和MLP模态投影，增强了Idefics2的整体效果。
这种视觉语言模型的进步为探索多模态交互开辟了新的途径，Idefics2准备成为社区的基础工具。其性能提升和技术创新突显出在创建复杂、上下文感知的人工智能系统中结合视觉和文本数据的潜力。
对于渴望利用Idefics2功能的爱好者和研究人员，Hugging Face提供了详细的微调教程。
