---
title: 'Hugging Face发布Idefics2视觉语言模型'
date: 2024-04-17
author: Jeson
---

Hugging Face宣布推出Idefics2，这是一种多功能模型，能够根据图像和文本理解和生成文本响应。![图片](https://www.artificialintelligence-news.com/wp-content/uploads/sites/9/2024/04/hugging-face-idefics2-model-ai-artificial-intelligence-development-visual-language-model-benchmark.jpg){ width=50% }

---
该模型在回答视觉问题、描述视觉内容、从图像创建故事、提取文档信息，甚至根据视觉输入执行算术运算方面树立了新的标杆。
Idefics2凭借仅有的80亿参数和其开放许可（Apache 2.0）所带来的多功能性，以及显著增强的光学字符识别（OCR）能力，超越了其前身Idefics1。
该模型不仅在视觉问答基准测试中表现出色，而且在与LLava-Next-34B和MM1-30B-chat等远大于其规模的当代模型竞争中表现出色。

Idefics2的吸引力主要体现在与Hugging Face的Transformers的整合上，从一开始就确保为广泛的多模态应用提供方便的微调。对于那些渴望尝试的人，可以在Hugging Face Hub上找到模型进行实验。
Idefics2的一个亮点是其全面的训练哲学，融合了包括网页文档、图像标题对和OCR数据在内的公开可用数据集。此外，它引入了一个被称为“神奇药锅”的创新微调数据集，将50个经过精心筛选的数据集汇集在一起，用于多方面对话训练。
Idefics2展示了一种对图像处理的精细化方法，保持原始分辨率和纵横比——这与计算机视觉中常规调整大小的方法有明显不同。其架构在高级OCR能力的帮助下极大地受益，熟练地转录图像和文档中的文本内容，并在解释图表和数据方面表现出色。
将视觉特征简化地整合到语言骨干中，标志着与其前身架构的转变，采用了学习的Perceiver池化和MLP模态投影，增强了Idefics2的整体效力。
这种在视觉语言模型中的进步开辟了探索多模态交互的新途径，Idefics2准备成为社区的基础工具。其性能增强和技术创新彰显了将视觉和文本数据相结合以创建复杂、具有情境感知能力的人工智能系统的潜力。
对于热衷者和研究人员希望利用Idefics2的能力，Hugging Face提供了详细的微调教程。
---
