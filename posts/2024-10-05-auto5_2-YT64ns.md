---
title: '号称击败Claude 3.5 Sonnet，媲美GPT-4o，开源多模态模型Molmo挑战Scaling law'
date: 2024-10-06
author: ByteAILab

---

Molmo，开源多模态模型正在发力！

虽然大家一直在期待谷歌、OpenAI 等等拥有无限资金储备和顶尖人才的大厂做出新的 Sota 模型。不过，一家默默耕耘的创业公司 Ai2 发布了一款多模态人工智能模型 Molmo。

---


在下面展示的视频中，我们可以看到 Molmo 就像钢铁侠的「贾维斯」一样万能。想卖自行车，咨询一下 Molmo 的建议，仅靠一张照片，Molmo 就能把自行车的颜色、品牌和二手售价搞清楚，并且帮你写出一句顺口的广告语。

它也可以从虚拟世界帮你解决现实世界的问题，说一句：「Molmo，帮我买杯星巴克的南瓜拿铁。」剩下的就不用动手了，打开外卖网页、点餐、付款，Molmo 一气呵成。你所要做的，就是坐在家中，静候咖啡送到你的手中。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWibf4n5SmibE1pklWrB1rbeqravHiahNFAA1Uliac4A96lOeEkdqxReKBWqGk8zDr6QK79Fx83GCzPHMw/640?wx_fmt=gif&from=appmsg)

机器之心也尝试了一下他们在线发布的 Demo 模型。相较于宣传视频，其功能还很有限，所以我们让其执行了图像描述任务，可以看到 Molmo 在细节描述和准确度上的表现确实很不错，它甚至能注意到猫背上的小玩具：「玩具看起来像一只绿色的老鼠，鼻子是粉红色的，尾巴是蓬松的，羽毛色彩缤纷。」

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibf4n5SmibE1pklWrB1rbeqrVe9sDCxXYm6h7SCGmM9juKpXEl77bkxibTVN1P8iaWRrHQ7RyKrjVibjA/640?wx_fmt=png&from=appmsg)

但遗憾的是，Molmo 的汉语输出能力非常有限，即使我们明确要求其输出汉语，它也未能办到：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibf4n5SmibE1pklWrB1rbeqrZGVoMbrqxfeEyFJwzDttfDW71P7Rfge2CcQzM3UpFHh3Zv6vbaFTPA/640?wx_fmt=png&from=appmsg)

除了 Demo，从数据来看，Molmo 的表现也足够惊艳。在人类测评和一系列测试集中，Molmo 的得分击败了 Claude 3.5 Sonnet、GPT4V 等一众顶尖模型，甚至可以媲美 GPT4o。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibf4n5SmibE1pklWrB1rbeqrCpAA58EOYBqibJXZuTIb5icG4ylHq6CLJXQsWXmXffruMrj2pRy9xX0w/640?wx_fmt=png&from=appmsg)

不过，Molmo 的体量更小，却能「以小搏大」，性能超越了比它的参数量大十倍的其他模型。据 Ai2 首席执行官 Ali Farhadi 称，Molmo 的体积小到可以在本地运行，它无需 API、无需订阅、更无需成本高昂的液冷 GPU 集群。

更重要的是 Molmo 完全免费且开源，所有的权重、代码、数据和评估流程都即将公布。

部分模型权重、推理代码和一个基于 Molmo-7B-D 模型的公开演示已经可以使用。

体验链接：[https://huggingface.co/collections/allenai/molmo-66f379e6fe3b8ef090a8ca19](https://huggingface.co/collections/allenai/molmo-66f379e6fe3b8ef090a8ca19)

Ai2 又是如何做到「四两拨千金」的呢？答案在 Ai2 公布的技术报告和论文中，这个秘诀就是：数据。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibf4n5SmibE1pklWrB1rbeqrM3JNoLxuThf2dRHzUTHh8iaFpp9EBiauHSN3351v3vtauWNcIR54G30Q/640?wx_fmt=png&from=appmsg)

论文链接：[https://molmo.allenai.org/paper.pdf](https://molmo.allenai.org/paper.pdf)

目前，最先进的多模态模型大多是闭源的，即使有一些开源的模型表现不错，但它们通常依赖于专有模型生成的合成数据。因此，如何从零开始构建高性能 VLM，对于开源社区来说，种种基础知识都很难获得。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibf4n5SmibE1pklWrB1rbeqrz2pfr1EQGPGUbsv5tIELuJWL4rANRbe9ctJgyEVRhib5uWlJmhmAUmg/640?wx_fmt=png&from=appmsg)

如上图所示，Ai2 的研究团队统计了目前 VLM 的开源程度，除了直接看模型的权重、数据和代码是否公开，他们还考虑了模型是否依赖于其他闭源模型。如果一个模型在训练中用了其他专有模型生成的数据，那它就被标记为「蒸馏」，这意味着它无法完全独立再现。

针对「闭源」的瓶颈，Ai2 使用语音描述收集了一个高细节度的图像描述数据集，这个数据集完全由人工标注，并可以公开访问。

该团队认为提升模型性能的诀窍是使用更少但质量更好的数据。面对数十亿张图像，...

（部分内容省略，具体请参考原文链接）

参考链接：
- [https://x.com/reach_vb/status/1838938439267258840](https://x.com/reach_vb/status/1838938439267258840)
- [https://techcrunch.com/2024/09/25/ai2s-molmo-shows-open-source-can-meet-and-beat-closed-multimodal-models/](https://techcrunch.com/2024/09/25/ai2s-molmo-shows-open-source-can-meet-and-beat-closed-multimodal-models/)
- [https://molmo.allenai.org/blog](https://molmo.allenai.org/blog)
- [https://molmo.allenai.org/paper.pdf](https://molmo.allenai.org/paper.pdf)

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。