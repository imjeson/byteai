---
title: 'Galileo发布新的幻觉指数'
date: 2024-07-30
author: ByteAILab

---

今年的指数新增了11个模型到框架中，代表了过去8个月内开源和闭源LLM的快速增长。![图片](https://ai-techpark.com/wp-content/uploads/2024/07/Galileo-Rele-960x540.jpg){ width=60% }

---
随着品牌竞相创建更大、更快、更准确的模型，幻觉仍然是部署可投入生产的Gen AI产品的主要障碍。

指数通过Galileo的专有评估指标“上下文依从性”测试开源和闭源模型，旨在检查输出的不准确性，并帮助企业做出关于平衡价格和性能的明智决策。模型在输入范围从1,000到100,000个标记的情况下进行测试，以了解在短（少于5k标记）、中（5k到25k标记）和长上下文（40k到100k标记）长度下的性能。

最佳整体表现模型：Anthropic的Claude 3.5 Sonnet。这个闭源模型在短、中和长上下文场景中超越了竞争模型。Anthropic的Claude 3.5 Sonnet和Claude 3 Opus在各类别中保持接近完美的得分，击败了去年的获胜者GPT-4o和GPT-3.5，尤其是在较短的上下文场景中。

成本最佳表现模型：Google的Gemini 1.5 Flash。由于在所有任务中表现出色，谷歌模型在成本方面排名最佳。

最佳开源模型：阿里巴巴的Qwen2-72B-Instruct。这个开源模型在短和中上下文中表现最佳。

“在今天快速发展的AI领域中，开发人员和企业面临着一个关键挑战：如何在平衡成本、准确性和可靠性的前提下利用生成式AI的力量。当前的基准往往基于学术用例，而不是真实应用。我们的新指数旨在通过测试需要LLM检索数据的真实世界用例来解决这个问题，这在企业AI实施中是一个常见实践。”Galileo的首席执行官兼联合创始人Vikram Chatterji说。"由于在原始训练数据方面表现出色，闭源模型如Claude-3.5 Sonnet和Gemini 1.5 Flash仍然是表现最佳的模型，但开源模型，如Qwen1.5-32B-Chat和Llama-3-70b-chat，正在迅速缩小差距，改善了对幻觉表现和低成本的障碍。”

- 开源正在缩小差距：闭源模型如Claude-3.5 Sonnet和Gemini 1.5 Flash由于专有训练数据而保持着领先地位，但开源模型，如Qwen1.5-32B-Chat和Llama-3-70b-chat，正在迅速缩小差距，改善了对幻觉表现和低成本的障碍。
- 长上下文长度整体改善：当前的RAG LLM，如Claude 3.5 Sonnet、Claude-3-opus和Gemini 1.5pro001在扩展上下文长度方面表现尤为出色，而不失质量或准确性，反映出在模型训练和架构方面正在取得进展。
- 较大的模型并非总是更好：在某些情况下，较小的模型表现优于较大的模型。例如，Gemini-1.5-flash-001胜过了较大的模型，这表明在模型设计的效率有时会超过规模。
- 从国家到全球的关注：像Mistral-large和Alibaba的qwen2-72b-instruct等国外LLM正在成为该领域的新兴玩家，并继续增长至，代表了全球推动创建有效语言模型的努力。
- 仍有提升的空间：谷歌的开源Gemma-7b表现最差，但他们的闭源Gemini 1.5 Flash模型始终位列前茅。

查看Galileo的幻觉指数结果的详细分析。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。