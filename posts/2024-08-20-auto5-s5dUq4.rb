```
---

title: '国内首个UI大模型出炉！Motiff妙多大模型打造设计师最佳助手、优化UI设计工作流'
date: 2024-08-21
author: ByteAILab

---

人工智能的发展速度可能超乎你的想象。自GPT-4将多模态技术引入公众视野以来，多模态大模型进入快速发展阶段，逐渐从单纯的模型研发转向垂直领域的探索和应用，与各行各业深度融合。

---
在界面交互领域，谷歌、苹果等国际科技巨头纷纷投入UI多模态大模型研发，这被视为手机AI革命的必经之路。

在此背景下，国内首个UI大模型横空出世。8月17日，在IXDC2024国际体验设计大会上，AI时代设计工具Motiff妙多推出了其自主研发的UI多模态大模型——Motiff妙多大模型。这是全球首个由UI设计工具企业研发的大模型，标志着中国UI设计力量在全球舞台上的崛起。

（IXDC大会现场，Motiff妙多副总裁介绍国内首个UI大模型——Motiff妙多大模型）

Motiff妙多大模型具备出色的UI理解能力和执行开放式指令的能力。在五个行业公认的UI能力基准测试集中，Motiff妙多大模型的各项指标均超过了GPT-4o和苹果的Ferret UI，同时在Screen2Words（界面描述与推断）和Widget Captioning（部件描述）两大指标上也超越了谷歌的ScreenAI，其中Widget Captioning指标高达161.77，刷新SoTA。与Ferret UI、ScreenAI等现有解决方案相比，Motiff妙多大模型能灵活地根据上下文理解界面元素，达到“设计专家”水平，最接近人类对UI界面的理解和表述结果。

（权威UI指标横评中，Motiff妙多大模型所有指标均超过GPT-4o和Ferret UI）

**最懂UI的大模型、表述高度接近人类，未来界面交互革命的基石**

在IXDC大会上，Motiff妙多副总裁张昊然详细介绍了Motiff妙多大模型，它具备理解用户界面和交互导览两大能力，有望引领界面交互革命。“人类的创造从认知和理解开始，AI 时代的 UI 创作也将从大模型充分理解用户界面开始。”张昊然说。

Motiff妙多大模型在理解用户界面方面表现卓越，堪比“设计专家”。它不仅能识别界面中所有的图片、图标、文字和40多种细粒度UI组件，还能精确标注界面上不同元素的区域坐标。此外，它还能够回答与用户界面相关的各种问题，并根据界面信息进行功能推断、详细描述界面内容。

相较于GPT-4o、Ferret UI和ScreenAI等大模型，Motiff妙多大模型还在界面分析能力上具有显著优势。例如，在APP Store应用界面中，Motiff妙多大模型能以UI设计视角将页面分为顶部导航栏、应用信息模块等多个模块，并详细分析每个模块的功能和布局，这有助于提供设计建议、自动生成UI设计原型等。Motiff妙多在界面分析能力上处于行业领先水平，是最懂UI设计的多模态大模型。

（Motiff妙多大模型能回答各种各样有关UI界面的问题）

Motiff妙多大模型在理解和表述能力上也最接近人类。此前的解决方案（如 Ferret UI 和 ScreenAI）难以根据上下文理解图标的含义，Motiff妙多大模型通过人工标注等方式收集了大量高质量的 UI 领域数据，能理解并指出同一图标在不同界面中的...

（继续内容请查看原文）
```
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。