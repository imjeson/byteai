---

title: 'Helm.ai宣布推出VidGen-1'
date: 2024-06-22
author: ByteAILab

---

Helm.ai，一家领先的高级ADAS、4级自动驾驶和机器人自动化AI软件提供商，今天宣布推出VidGen-1，这是一种生成式AI模型，可为自动驾驶开发和验证生成高度逼真的驾驶场景视频序列。![图片](https://ai-techpark.com/wp-content/uploads/2024/06/Helm.ai-announced-960x540.jpg){ width=60% }

---
这一创新型AI技术跟随Helm.ai宣布推出GenSim-1用于生成标记图像，并且对于预测任务和生成仿真具有重要意义。

经过在数千小时的多样化行车素材上训练，Helm.ai的生成式AI视频模型利用创新的深度神经网络（DNN）架构，结合高效的无监督训练技术Deep Teaching，生成逼真的驾驶场景视频序列。这些视频的分辨率为384 x 640，可变帧速率高达30帧每秒，长达几分钟，可以随机生成，无需输入提示，也可以通过单张图片或输入视频进行提示。

VidGen-1能够生成不同地理位置的行车场景视频，适用于多种摄像机类型和车辆视角。该模型不仅产生高度逼真的外观和时间上连贯的物体运动，还学习并再现类似人类的驾驶行为，生成自车辆及周围代理根据交通规则行动的动作。该模型模拟国际多个城市的各种场景，包括城市和郊区环境、各种车辆、行人、自行车骑手、十字路口、转弯、各种天气条件（如雨、雾）、照明效果（如眩光、夜间驾驶），甚至准确反映湿润路面、反光建筑墙壁以及自车辆引擎盖上的倒影。

视频数据是自动驾驶中信息丰富的感知模式，并且来自成本效益最高的传感器——摄像机。然而，视频数据的高维度使得AI视频生成成为一项具有挑战性的任务。在准确建模移动场景的动态，即视频逼真度的同时实现高水准的图像质量，在视频生成应用中是众所周知的困难。

Helm.ai的首席执行官兼联合创始人弗拉迪斯拉夫·沃龙斯基（Vladislav Voroninski）表示：“我们在生成式AI视频方面取得了技术突破，开发出VidGen-1，为自动驾驶领域设立了新的标杆。结合我们多年来开发的Deep Teaching技术和内部关于生成式DNN架构的额外创新，将产生高效且可伸缩的方法生成逼真的AI生成视频。我们的技术是通用的，可以在无需任何更改的情况下同样有效地应用于自动驾驶、机器人技术以及任何其他视频生成领域。”

相比传统的非AI模拟，VidGen-1为汽车制造商提供了显著的可伸缩性优势，通过快速生成资产并赋予仿真中的代理复杂的现实生活行为。Helm.ai的方法不仅缩短了开发时间和成本，而且有效地弥合了“仿真到真实”的差距，提供了一个高度逼真且高效的解决方案，极大地扩展了基于仿真的训练和验证的适用性。

沃龙斯基补充道：“预测视频中的下一帧类似于预测句子中的下一个单词，但高维度得多。生成驾驶场景的逼真视频序列代表了自动驾驶预测的最高形式，因为这需要准确地建模真实世界的外观，并且包括意图预测和路径规划作为堆栈最高级别的隐含子任务。这种能力对于自动驾驶至关重要，因为从根本上讲，驾驶就是关于预测下一步会发生什么。”

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。