---

title: '股价暴涨7%！我们深挖了两份低调公布的资料后，发现了苹果AI的秘密'
date: 2024-06-19
author: ByteAILab

---

<div class="article-content__container">
<div class="bbt-html">
<div class="ne-render-content">
<p>文章来源： 腾讯科技</p>
<p>文 / 郝博阳 郭晓静 吴彬</p>
<p class="ne-empty-p"></p>
<div class="ne-atomic">
<div class="ne-img-wrapper" data-align="c"><img src="https://appserversrc.8btc.cn/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1718679963415/FvdvdDkxdblEGYOGc5wdDd73-02l.png" style="width: 100%"><div class="ne-img-desc">图片来源：由GPTNB生成</div></div>
</div>
<p><br><br>苹果在大模型时代落后了吗？几乎所有人都希望在苹果WWDC24上找到这个答案。然而，在最重要的主题演讲环节之后，争议也纷至沓来：发布会前半部分是被戏谑为“追赶安卓”的小功能集合，后半部分最重磅的AI，从表面上看和安卓手机目前已经对外发布的AI能力大差不差，被很多人认为“没有惊喜”。

---
段子开始在网上传播：“WWDC24最大的惊喜是苹果给iPad带来了一个新的计算器”。</p>
<p>虽然真正意义上的AI硬件还没有出现，但是大模型可能成为未来端侧设备中等同于操作系统的“核心”，已经成为行业中的某种共识。这样重要的大模型能力，苹果到底有没有？苹果在AI时代，难道真的要靠OpenAI这样的第三方大模型公司了吗？</p>
<p>主题演讲的当天，苹果的股价下跌了1.9%，这似乎符合外界对于这场发布会的”平淡“评价。然而，戏剧性的事情出现了，苹果股价在主题演讲的第二天，暴涨7%创出历史新高。资本市场是市场合力的体现，对于苹果3.18万亿的巨大市值体量来讲，资金背后情绪的巨大反差，值得引起关注。</p>
<p>顺着之前的争议焦点，我们将关注点集中到了两份资料：一份资料是苹果在官网低调发布的大模型技术文档，其中有很多值得深挖的细节。另外一份是腾讯科技在现场的同事，发回的一份笔记，笔记记录了主题演讲之后举办的一个不起眼的闭门对谈内容，对话的两个人是“苹果公司的软件工程高级副总裁雷格-费德里吉（Craig Federighi）和苹果公司机器学习和人工智能战略高级副总裁约翰-吉安南德雷亚（John Giannandrea），他们二位都直接向CEO库克汇报。对话的内容包括为何与OpenAI合作以及如何保护隐私等。</p>
<p>本文围绕这两份资料，试图抽丝剥茧地探究一下，苹果的“大模型竞争力”究竟怎样。</p>
<p><strong>重点有两个：</strong></p>
<p><strong>● </strong>苹果自研大模型的能力很强；</p>
<p><strong>● </strong>OpenAI并没有为Apple Intelligence提供支持，两者完全独立。Apple Intelligence完全由Apple自研模型提供支持。</p>
<div class="ne-atomic">
<div class="ne-img-wrapper" data-align="c"><img alt="" src="https://appserversrc.8btc.cn/FtwLaXJEoPa9r0bAvtOs1WWY6hmS" style="width:677px"></div>
</div>
<h3><br><strong>深挖苹果发布的模型技术文档：</strong><br><strong>两个新确定的信息，</strong><br><strong>可能才是这次发布最重要的点</strong></h3>
<p>首先是信息逐渐清晰：有两个在发布会上并没说明的信息，在发布会后逐渐清晰化。</p>
<p>1.苹果低调发布了自研模型：不仅有端侧的小模型，还有云端大模型</p>
<p>在Keynote上，苹果一直在讲拥有了AI能力的端侧设备，能带给用户多么神奇的应用体验。但是这些模型到底是谁家的？哪些是苹果自研的，哪些是和OpenAI合作的？虽然承诺了隐私安全，但是究竟具体如何保障？马斯克连发推怒怼苹果如果集成了OpenAI，将在公司禁用苹果。但是苹果整场主题演讲下来，我们都没找到明确答案。</p>
<p>直到发布会后，它发布了一篇技术博客，并在State of Union上公布了它会在苹果设备上用的模型细节：端和云模型，都是苹果自己开发的。</p>
<p><strong>自研大模型赶上GPT4</strong></p>
<p>具体来看，苹果设备上的端侧模型是一个30亿参数（3B）的小模型，云上模型具体参数苹果没有公布。这两个模型的性能都相当能打。</p>
<p>3B级小模型和主流几个7B级模型能力上苹果都能基本胜出（胜出+平手概率&gt;50%)。而其云端模型则直接打到了GPT-4 Turbo级（胜出+平手概率58.3%）。</p>
<p>这一发布可能才是整个苹果这波更新里最大的核弹：苹果自研出了GPT4级大模型，而且一出场就已经成熟到可以直接接入苹果的软硬件体系内了。</p>
<p>这意味着之前对苹果模型能力的质疑完全不成立。苹果现在不用依靠外部模型公司就能构建出自己内部闭环的AI系统。这是除了谷歌之外的其他手机厂商当下完全无法做到的。</p>
<p>这就是苹果把OpenAI只列为之一，而且是作为外部调用的模型之一的底气。</p>
<p>端侧小模型强优化</p>
<p>另外说说端侧模型，在发布会上苹果强调大多数Apple Intelligents的操作都会在端侧模型上完成。但在发布会后所有人几乎都在质疑，一个3B大小的模型是不是能真的完成发布会上展示的那些功能。</p>
<p>首先，3B大小的端侧模型落地其实已经很不容易了。</p>
<p>看看苹果的竞品们的表现吧：谷歌在去年12月首次把其端侧模型Gemnini Nano部署到旗舰手机Pixel 8 Pro上，它的参数大小不过是1.8B，而且能力非常局限。三星S24在端侧也用的是Gemnini Nano。要知道Pixel 8 Pro具有12G内存，直到今年5月谷歌刚刚才能让8G内存的Pixel 8 和 8a也跑上这个1.8B的模型，还要下个月才能真正升级部署。而其他手机厂商部署的端侧模型基本上都是在1B级别的参数规模。</p>
<p>而苹果做到了让自己8G内存的iPhone 15 Pro跑起来一个3B参数的模型。这工程能力就甩出竞争对手一个身位。</p>
<p>在这之前，苹果已经为此做足了准备，在去年12月引起轰动的论文《LLM in a flash: Efficient Large Language Model Inference with Limited Memory》里，苹果就提出了解决小内存运行大模型的方法，使用窗口化（Windowing）以及行列捆绑（Row-Column Bundling）两项关键技术，来最小化数据传输和最大化闪存吞吐量。</p>
<p>在这次的技术文档中，苹果还提到了他们在模型框架中用上了分组注意力查询（grouped-query-attention）和LoRA适应器框架。这两项技术一个避免重复映射，一个可以压缩推理过程，都可以有效降低内存占用和推理成本。</p>
<p>另外，为了保证AI模型的运作不至于大幅降低手机功耗，苹果还配上了功耗分析工具 Talaria，及时优化功耗。</p>
<div class="ne-atomic">
<div class="ne-img-wrapper" data-align="c"><img src="https://appserversrc.8btc.cn/Fj4cc8bVij0hLn4sRblD-Iu8rqJS" style="width: 677px"></div>
</div>
<p>在这一系列操作之下，3B模型的端侧部署才成为了可能。</p>
<p>其次，在这篇技术博客里，苹果也展示了他们如何去保障小模型的交付能力：不全能，但对具体任务做了加强。</p>
<p>具体来讲，苹果在基础模型上加了很多微调的适配器。适配器是叠加在通用基础模型上的小型模型权重集合。它们可以动态加载和交换，使基础模型能够根据当前任务实时进行针对性特殊化处理。苹果智能包含一系列适配器，针对应急判断，总结，邮件回复等诸多发布会上的功能都进行了精细调优。</p>
<div class="ne-atomic">
<div class="ne-img-wrapper" data-align="c"><img src="https://appserversrc.8btc.cn/FuESPheCy_58WsvmWxseo_hg32AX" style="width: 677px"></div>
</div>
<p>因此，至少端侧模型可以较好的完成基本的摘要、写邮件等最常见的工作。</p>
<div class="ne-atomic">
<div class="ne-img-wrapper" data-align="c"><img src="https://appserversrc.8btc.cn/Fi47YVwyAG5zRKfniozcOb3oGtJk" style="width: 677px"></div>
</div>
<p>综合来看，苹果在这次发布会上所展示出来的综合模型能力基本可以说是远超预期。从大模型到小模型都一跃进入了第一梯队。</p>
<p><strong>只有新旗舰才能用上的AI，可能引发新的换机潮</strong></p>
<p>另一个消息也很重要：虽然iOS18系统升级可以适用于iPhoneX以上的所有机型，但苹果的AI功能只能适用在iPhone 15 Pro及以上机型，其它终端需要M1芯片以上的能力。这意味为了能用上AI，用户可能必须要进行一波换机潮。</p>
<div class="ne-atomic">
<div class="ne-img-wrapper" data-align="c"><img src="https://appserversrc.8btc.cn/FkrGyFtB5RjZgdjuxJ40yjfPtEPt" style="width: 677px"></div>
</div>
<p>这其实也不是苹果有意卡老用户。端侧大模型的运行瓶颈一方面是算力，一方面是内存。对苹果来说，算力问题可能反倒不是那么棘手。本次Apple Intelligent下放的产品从M1开始。M1芯片负责AI推理的NPU能力其实还比不上A16，但也足够处理苹果端侧模型的推理需求了。那iPhone14 Pro乃至iPhone 15为什么不行？还是因为内存不够。</p>
<p>因为在模型进行推理过程中需要占用很大的运行内存（DRAM），较小的内存会严重拖慢推理速度甚至无法完成推理。因此iPhone 15 Pro及以上的苹果手机才有的8G内存，可能就是当下经过一系列优化的3B端侧模型所需的最小内存数。</p>
<p>但这件事本身也有着优化的空间。昨天上交大发布的PowerInfer2手机推理框架就提出了进一步减小内存占用的方法。GeminiNano下放到Pixel 8也说明了谷歌也在做一样的努力。</p>
<p>但内存需求小了，还有7B，14B的模型排队等着上端。长远来看，机还是不得不换。毕竟只有更大的端侧模型才能带来更多让用户买单的体验魔法。</p>
<div class="ne-atomic">
<div class="ne-img-wrapper" data-align="c"><img src="https://appserversrc.8btc.cn/FktJURnvyg2geuop25lbrADjGtSr" style="width: 677px"></div>
</div>
<h3><strong>圆桌对话透露了和OpenAI的关系</strong></h3>
<p>既然苹果自研的大模型能力如此强大，为何还要和OpenAI合作？苹果公司的软件工程高级副总裁克雷格-费德里吉（Craig Federighi）和约翰-吉安南德雷亚（John Giannandrea）在Keynote之后的闭门对话环节揭示了这个细节，腾讯科技在WWDC现场的同事发回了这场对话的内容记录。“现有的拥有丰富公共信息的大语言模型，如ChatGPT，也有其用途。这些非常大的前沿模型有一些用户很喜
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。