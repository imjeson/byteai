---

title: 'Cato Networks推出Cato CASB的生成式AI安全控制'
date: 2025-04-21
author: ByteAILab

---

Cato CASB增强了一个影子AI仪表板，提供对生成式AI应用的全面可视化，并配备强大的政策引擎用于治理生成式AI的使用。![图片](https://ai-techpark.com/wp-content/uploads/Cato-Networks.jpg){ width=60% }

---
今天，Cato Networks，作为SASE的领导者，推出了Cato CASB（云访问安全代理）的生成式AI（GenAI）安全控制。Cato CASB作为Cato SASE云平台中的原生功能，现在增强了针对生成式AI应用的新能力，包括影子AI仪表板和政策引擎。借助影子AI仪表板，企业可以检测、分析并深入了解生成式AI的使用情况。通过政策引擎，企业可以控制用户在生成式AI应用中的活动。Cato结合这两方面，使安全和IT团队能够在创新与风险管理之间取得平衡。

生成式AI迅速成为员工提升生产力和自动化任务的首选工具。然而，随着生成式AI采用的激增，出现了日益严重的影子AI问题，即员工在没有IT监督的情况下使用生成式AI应用程序。根据Gartner®的预测，“到2027年，超过40%的与AI相关的数据泄露将是由于跨境生成式AI（GenAI）不当使用造成的。”¹

影子AI的不断增长趋势使企业面临安全、合规和运营风险。敏感的公司数据可能在不知情的情况下共享给生成式AI应用，可能违反监管要求，并且错误信息或偏见输出可能影响商业决策。

有了Cato CASB的新生成式AI安全控制，安全和IT团队可以：

- 发现影子AI：区分授权使用和未授权使用，通过识别所有生成式AI应用并对其进行分类。Cato提供了950多个生成式AI应用的目录。
- 控制生成式AI应用访问：通过在细粒度水平上定义和执行访问政策，确保生成式AI的负责任使用。控制可以访问哪些生成式AI应用，以及在其中可以执行哪些操作（上传、下载等）。
- 保护敏感数据：实时限制或防止将敏感数据上传到大型语言模型（LLM），避免数据安全和保密违反。
- 维护治理和合规性：通过全面可视化所有用户活动，以符合企业政策和监管标准的方式推动生成式AI的采用。

“企业需要智能的方式来治理生成式AI，”Cato Networks产品管理副总裁Ofir Agasi表示。“通过对Cato CASB的增强，我们在Cato SASE云平台内利用AI发现、分类和保护生成式AI应用的使用方式。我们为安全和IT团队提供了管理风险和负责任地实现创新的工具。”

“Cato Networks让我们在不担心曝光敏感数据或知识产权的情况下放心使用生成式AI，”CloudFactory安全运营负责人Shayne Green表示。“借助Cato CASB的新生成式AI安全控制，我们可以以受控风险的方式采用生成式AI工具。”

可用性
Cato CASB的生成式AI安全控制面向全球客户正式推出。

资源

了解有关Cato CASB中新生成式AI安全控制的更多信息，请访问博客。
了解Cato的AI安全方法和Cato的AI/ML能力。
Cato CASB的生成式AI安全控制是Cato最新的AI创新，于SASEfy 2025期间宣布，SASEfy是Cato的全球虚拟活动。今年的活动聚焦于SASE和AI。 如果您错过了SASEfy 2025，注册以点播观看录制内容。

Gartner免责声明
¹ Gartner新闻稿，“Gartner预测到2027年，40%的AI数据泄露将源于跨境生成式AI的不当使用，”2025年2月17日。
GARTNER是Gartner, Inc.及其子公司的注册商标和服务标志，在美国和国际上使用并获得许可。保留所有权利。
PR Newswire PR Newswire赋能传播者识别和参与关键影响者，制作和分发有意义的故事，并衡量他们努力的财务影响。Cision是全球领先的公关和市场传播专业人士的媒体软件和服务提供商。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。