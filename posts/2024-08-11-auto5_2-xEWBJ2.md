---

title: '给视频模型安上快慢两只眼睛，苹果免训练新方法秒了一切SOTA'
date: 2024-08-12
author: ByteAILab

---

自从 Sora 发布以来，AI 视频生成领域变得更加「热闹」了起来。过去几个月，我们见证了即梦、Runway Gen-3、Luma AI、快手可灵轮番炸场。

---

和以往一眼就能识破是 AI 生成的模型不太一样，这批视频大模型可能是我们所见过的「最好的一届」。
然而，视频大语言模型（LLM）惊艳表现的背后离不开庞大且经过精细标注的视频数据集，这需要花费相当高的成本。近期研究领域也涌现了一批无需额外训练的创新方法：采用训练好的图像大语言模型，直接用于视频任务的处理，这样就绕开了「昂贵」的训练过程。
此外，现有大多视频 LLM 存在两个主要缺点：（1）它们只能处理有限帧数的视频输入，这使得模型难以捕捉视频中细微的空间和时间内容；（2）它们缺少时间建模设计，而是简单地将视频特征输入到 LLM...

[点击阅读更多](https://arxiv.org/pdf/2407.15841)

实验结果显示，SF-LLaVA 在所有基准测试中均以显著的优势超越了现有免训练方法。与精心微调的 SFT 模型相比，SF-LLaVA 能达到相同性能，甚至更好。

论文链接：https://arxiv.org/pdf/2407.15841

模型架构

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibv1kAx14e5hrRfl4zwdto52x289qYn4pmjYH4QKVfhqVFiaDCqibjwmP2WJ4ftN258TbnWe8NXseqA/640?wx_fmt=png&from=appmsg)

慢速路径：低帧率提取特征，同时尽可能多地保留空间细节（例如每 8 帧保留 24×24 个 token）
快速路径：高帧率运行，但用较大的空间池化步长降低视频的分辨率，以模拟更大的时间上下文，更专注于理解动作的连贯性
这相当于模型拥有两只「眼睛」：一只慢慢看，注意看细节；另一只快速看，注意看动作。这样就解决了大多现有的视频 LLM 的痛点，既能捕捉到详细的空间...

[点击阅读更多](https://arxiv.org/pdf/...)

---

更多细节，请参考原论文。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。