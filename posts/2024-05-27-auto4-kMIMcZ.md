---

title: '速递｜马斯克 xAI 计划打造 AI 版的超级工厂，规模将是如今最大 GPU 集群四倍，明年秋季前投入运行'
date: 2024-05-28
author: ByteAILab

---

文章来源：[有新Newin](https://mp.weixin.qq.com/s/CTKagKMseoJoOvwdal12Ww)

根据 The Information 最新报道，马斯克 5 月份在向投资者做演示时表示，他希望超级计算机能在 2025 年秋季之前投入运行，并将亲自负责按时交付；预计完成后，连接在一起的芯片组将至少是当今最大 GPU 集群的4 倍，例如 Meta Platforms 为训练其 AI 模型而构建的 GPU 集群。 马斯克曾公开表示，xAI 将需要多达 10 万个 GPU 来训练和运行其下一版本的 Grok。

---
为了让聊天机器人更智能，马斯克最近告诉投资者，xAI 计划将所有这些芯片串联成一台超级计算机，或者说是计算超级工厂（Gigafactory of Compute）。

xAI 可能会与 Oracle 合作开发这台超级计算机。xAI 一直在与 Oracle 高管讨论在未来几年内可能花费 100 亿美元租用云服务器的问题。目前，xAI 已经从 Oracle 租用了大约 1.6 万台 H100 芯片服务器，也是 Oracle 此类芯片最大客户。 预计这台超级计算机需要花费数十亿美元并获得足够的电力，以赶上资金更雄厚的竞争对手，这些竞争对手也计划在明年推出类似规模的 AI 芯片集群，并在未来推出更大的芯片集群。 集群是指单个数据中心内通过电缆连接的众多服务器芯片，以便它们能够以更高效的方式同时进行复杂计算。领先的 AI 公司和云提供商认为，拥有更大、计算能力更强的集群将带来更强大的 AI。 

xAI 的办公室位于旧金山湾区，但决定 AI 数据中心位置的最重要因素是电力供应。据悉，拥有 10 万个 GPU 的数据中心可能需要 100 兆瓦的专用电力。 这将比传统云计算中心所需的电力要多很多，与云提供商目前运行和建设的容纳多个集群的 AI 中心的能源需求相当，这些数据中心越来越多地建在偏远或非传统的地方，那里的电力更便宜，也更充足。

此前，也传出微软和 OpenAI 正在威斯康星州建设一个独立于价值1000亿美元的超级计算机的大型数据中心，竞争成本约为100亿美元，而亚马逊网络服务正在亚利桑那州建设一些 AI 数据中心。 根据马斯克的时间表，xAI 仍落后于对手。到今年年底或明年年初，OpenAI 及其主要支持者微软可能已经拥有了马斯克设想的规模的集群。OpenAI 和微软还讨论了开发一台价值1000 亿美元的超级计算机，规模将是马斯克设想的几倍，包含数百万个 Nvidia GPU。

Nvidia CFO Colette Kress 已将 xAI 列入六家客户名单中，这些客户将与 OpenAI、亚马逊、谷歌等公司一起率先使用 Nvidia 的下一代旗舰芯片 Blackwell。 目前，xAI 正在 2 万个 GPU 上训练 Grok 2.0，最新版本可以处理文档、图表和现实世界中的物体，未来该模型也将扩展到音频和视频。此外，马斯克 4 月份与投资者的电话会议上表示，特斯拉还拥有 3.5 万台 Nvidia H100 来训练其自动驾驶，并计划在今年年底前将数量增加一倍以上。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。