---

title: '首个无限上下文大模型颠覆12亿美元RAG市场'
date: 2025-08-09
author: ByteAILab

---

硅谷初创公司iFrame™ AI，悄然与一家领先的云服务供应商达成了近2000万美元的协议，推出全球首个具有无限上下文窗口的大型注意模型——这一突破即将颠覆专业服务行业，并削弱OpenAI等公司的收入，这些公司依赖于高成本、冗余的数据检索服务。![图片](https://ai-techpark.com/wp-content/uploads/First.jpg){ width=60% }

---


就像DeepSeek去年震撼AI生态系统一样，iFrame的Asperanto和Sefirot-10模型彻底消除了检索管道和微调的需求，兑现了前谷歌首席执行官埃里克·施密特的最新预测，即无限上下文模型正在成为现实，旨在重塑我们对智能体AI应用的理解。

近十年来，人工智能行业一直被困在变压器的注意力矩阵中——这一引擎驱动着OpenAI、Google和Anthropic等每个主要AI，使得即使是最先进的模型也陷入了数字遗忘的状态。

经过三年的隐秘研发，iFrame™即将推出全球首个大型注意模型（LAM），其架构不仅仅扩展了上下文窗口——而是使得这一概念变得过时。通过完全移除注意力矩阵，iFrame™创建了一种可以在一次处理期间原生推理数TB数据的模型：无需RAG，无需微调，无需花招。与其训练一个数十亿美元的大型语言模型以提取和微调用于可用推理的数据，不如使用iFrame™，您只需将数TB的数据上传到一个注意力块，便可在数秒内升级AI知识。

“无论好坏，我帮助AI摆脱了矩阵——字面意义上，”iFrame的创始人、单体框架的创造者弗拉德·帕宁在最近的采访中表示。他的突破并不是从现有AI研究上不断迭代，而是从对宇宙拓扑数学的深度研究中发掘出来，灵感来源于那位著名隐士格里戈里·佩雷尔曼，他在2002年解决了庞加莱猜想。

“每个人都在试图从被接受的叙事中优化矩阵，”帕宁解释道，“而我却鲁莽地寻找那扇在矩阵计算并行性教义中明确排除存在的门的钥匙。”

这一切对整个AI硬件和软件生态系统构成了根本挑战。像AWS、Azure和Google这样的GPU巨头，可能会在一夜之间将其数据中心的利用率提高四倍。iFrame的架构从底层设计，旨在运行在去中心化网络上，充分利用可用硬件上的每一块内存。它绕过了使NVIDIA成为AI之王的GPU VRAM瓶颈，并开启了一个全球分布设备上的大型AI模型运行的新道路。

GlobeNewswire是全球最大的新闻发布网络之一，专注于向媒体、投资社区、个人投资者和公众传播企业新闻稿、财务披露和多媒体内容。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。