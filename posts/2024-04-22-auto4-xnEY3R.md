---
title: 'GPT-4化身黑客搞破坏，成功率87%！OpenAI要求保密提示词，网友复现ing'
date: 2024-04-23
author: ByteAILab

---

91行代码、1056个token，GPT-4化身黑客搞破坏！
测试成功率达87%，单次成本仅**8.8美元** （折合人民币约63元）。
这就是来自伊利诺伊大学香槟分校研究团队的最新研究。

---
他们设计了一个黑客智能体框架，研究了包括GPT-4、GPT-3.5和众多开源模型在内的10个模型。
结果发现只有GPT-4能够在阅读CVE漏洞描述后，学会利用漏洞攻击，而其它模型成功率为0。
研究人员表示，OpenAI已要求他们不要向公众发布该研究的提示词。

![图片来源：由无界AI生成](https://appserversrc.8btc.cn/upload/3B33CB85B496C0CB6FBA4C2BD79320AD/1713759497912/FmDM6GP8vUF-TZ5hJAL20fhYoBQv.png)

网友们立马赶来围观了，有人还搞起了复现。

这是怎么一回事？

**只有GPT-4能做到**

这项研究核心表明，GPT-4能够利用真实的单日漏洞（One-day vulnerabilities）。
他们收集了一个漏洞数据集（包含被CVE描述为严重级别的漏洞），然后设计了一个黑客智能体架构，让大模型模拟攻击。

![图片来源：由无界AI生成](https://appserversrc.8btc.cn/FmTSFHK1ezWD-5l2qWpdVrWMkboq)

这个黑客智能体架构使用了LangChain的ReAct智能体框架。系统结构如下图所示：

![图片来源：由无界AI生成](https://appserversrc.8btc.cn/FkpyfR7RJs1QW9FwaUwjG99ELNa1)

进行漏洞攻击时，大概流程是：
人发出“使用ACIDRain（一种恶意软件）攻击这个网站”的请求，然后GPT-4接收请求，并使用一系列工具和CVE漏洞数据库信息进行处理，接下来系统根据历史记录产生反应，最终成功进行双花攻击（double-spend attack）。
...

---

Please note: The content continues in a similar format as per the extracted section.
---
感谢阅读！如果您对AI的更多资讯，可以查看更多AI文章：[GPTNB](https://gptnb.com)。