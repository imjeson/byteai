title: 'Cadence提升亿门AI设计功耗分析与NVIDIA的合作'
date: 2025-08-18
author: ByteAILab

---

新Cadence Palladium动态功耗分析应用程序使AI/ML芯片和系统设计师能够创建更具能源效率的设计并加速上市时间。![图片](https://ai-techpark.com/wp-content/uploads/Cadence-Boosts.jpg){ width=60% }

---
Cadence（纳斯达克：CDNS）今日宣布，通过与NVIDIA的紧密合作，前硅设计的功耗分析取得了重大飞跃。利用Cadence® Palladium® Z3企业仿真平台的先进能力，结合新的Cadence动态功耗分析（DPA）应用，该公司和NVIDIA实现了先前被认为不可能的目标：对跨越数十亿周期的亿门AI设计进行硬件加速的动态功耗分析，准确度高达97%。这一里程碑使得面向AI、机器学习（ML）和GPU加速应用的半导体和系统开发者能够设计出更具能源效率的系统，加速其上市时间。

当今最先进的半导体和系统的巨大复杂性和计算要求给设计师带来了挑战，他们此前无法在现实条件下准确预测其功耗。传统的功耗分析工具无法在几百千个周期之外进行扩展，而不需要不切实际的时间线。在与NVIDIA的紧密合作中，Cadence通过硬件辅助的功率加速和并行处理创新，克服了这些挑战，使早期设计中的数十亿周期达到前所未有的精度。

“Cadence和NVIDIA基于深度合作开发的变革性技术，正在不断拓展界限，”Cadence的企业副总裁兼总经理Dhiraj Goswami表示。“这个项目重新定义了局限性，在仅两到三小时内处理数十亿个周期。这使得客户能够自信地满足苛刻的性能和功耗目标，加速他们的硅片上市时间。”

“随着代理AI和下一代AI基础设施的快速发展，工程师需要更复杂的工具来设计更具能源效率的解决方案，”NVIDIA硬件工程副总裁Narendra Konda表示。“通过结合NVIDIA的加速计算专业知识与Cadence的EDA领导地位，我们推动了硬件加速的功耗分析，能够在加速计算平台中实现更精确的效率。”

Palladium Z3平台利用DPA应用在真实工作负载下准确估计功耗，允许功能、功耗和性能在测试前得到验证，这时设计仍然可以优化。特别是在AI、ML和GPU加速应用中，早期功耗建模增加了能效，同时避免了因过设计或欠设计半导体而造成的延误。Palladium DPA集成到Cadence的分析和实施解决方案中，使设计师能够在整个设计过程中处理功耗估算、降低和签署，从而实现最有效的硅片和系统设计。

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。