---

title: '60刀亿砸向无人机，800个AI项目并行。美国启动「曼哈顿计划2.0」，AI进入奥本海默时刻？'
date: 2024-07-17
author: ByteAILab

---

来源：新智元

【导读】曼哈顿计划2.0来了？截止目前，美国军方已经拥有800多个活跃的AI项目，仅在24年就为AI申请了18亿美元的资金。

---
在未来五年内，美国还将拨款60亿美元，用于无人协作战斗机的研发。现在，AI似乎已经进入了奥本海默时刻。

人工智能，已经进入奥本海默时刻。
现在，AI武器不断被用于军事用途，相关行业正在蓬勃发展。
价值数十亿美元的AI军备竞赛，已经吸引了硅谷巨头和世界各地的国家。
世界各地日益加剧的冲突，既是AI战争的加速器，也是试验场。各国军队都对AI有着极大的兴趣，而且，这一领域目前还缺乏监管。

而美国军方，已经拥有了800多个活跃的AI项目，仅在2024年，就已经在预算中为AI申请了价值18亿美元的资金。
在世界各地军队和政府中扎根的AI，很可能在根本上改变社会，改变技术，改变战争。

无人机广告成真
在近距离的城市战斗中，一队士兵正在遭受火箭弹的攻击。
其中一人通过无线电拨打电话，不久后，配备炸药的一队小型自主无人机飞来。
这些自杀式无人机飞进建筑物中开始扫描敌人，找到目标后，就会根据命令引爆。
以上这个画面，来自武器公司Elbit的广告，来宣传AI无人机能怎样「最大限度地提高杀伤力和战斗节奏」。
现在，Elbit开发的技术，已经越来越多地进入现实世界。
新美国安全智库中心执行副总裁兼研究主任Paul Scharre表示：「随着时间的推移，我们可能会看到人类将更多判断力让给机器。」
「如果我们在15或20年后回过头来看，会意识到我们已经越过了一个非常重要的门槛。」

2023年，一架集成AI的无人机在探测爆炸装置

美国斥资10亿美元，用于「复制者计划」
虽然AI发展是近几年才迎来投资的激增，但战争中自主武器系统的发展，最早可以追溯到几十年前。
当然，这些进展很少出现在公众讨论中，而是少数学者、军事战略家研究的课题。
但是现在，公众对AI的关注度不断提高。武器是否真正「自主」，也成为热议的话题。
在专家和研究人员看来，我们可以把「自主」理解为一个范围，而非简单的二元概念。
但他们普遍认为，如今机器能够比以往任何时候在没有人类输入的情况下，做出更多的决策。

而且，大量的资金也在疯狂涌入公司和政府机构，它们承诺：AI可以让战争变得更智能、更便宜，也更快。
五角大楼计划，到2025年斥资10亿美元用于其「复制者计划」。这项计划的目标是开发大量无人驾驶作战无人机，利用AI来寻找威胁。
在未来五年内，美国空军计划拨款约60亿美元用于无人协作战斗机的研发，从而建立一支由1000架可自主飞行的AI战斗机组成的机队。
近年来，美国国防部还筹集了数亿美元，来资助名为Project Maven的秘密人工智能计划，这项计划重点在自动目标识别和监视等技术。

英国士兵在演习时使用AI

科技公司纷纷签订巨额合同
同时，军事上对AI和自主性日益增强的需求，帮科技公司和军火商们纷纷赢得了巨额订单。
Anduril是一家开发自主攻击无人机、无人战斗机和水下航行器的公司，正在筹集全新一轮风投，预计估值125亿美元。
Anduril的创办者Palmer Luckey是一名31岁的亿万富翁，他今年已经和五角大楼签订了一份合同，用于建立无人驾驶战机项目。
硅谷亿万富翁Peter Thiel，也创立了一家技术和监控公司Palantir。它已经参加了美国陆军「第一辆人工智能定义的汽车」等AI项目。

5月，五角大楼宣布授予Palantir一份价值4.8亿美元的合同，用于帮助识别敌方目标的AI技术。
目前，Palantir的技术已经在几次军事行动中使用。

Palantir参与了美国陆军的「第一辆AI定义的车辆」
Anduril和Palantir，分别以《指环王》中的圣剑和魔法石命名，而这两家公司，只是国际AI战争淘金热的一小部分。

Helsing凭借AI防御软件筹集了近5亿美元的资金，并在本月估值达到了54亿美元。
同时，Elbit Systems在3月的一份财务文件中披露，公司已于2023年签订了7.6亿美元的弹药合同。并且，在过去一年里，收入达到了60亿美元。

Helsing凭借其人工智能防御软件筹集了近5亿美元资金，本月估值达54亿美元
与过去几年相比，大型科技公司也更愿意接受国防工业及其对AI的使用了。
在2018年，谷歌员工曾抗议该公司参与军方的Project Maven，认为这违反了伦理和道德责任。当时迫于压力，谷歌断绝了和该项目的合作。
然而此后，谷歌又和某国政府达成了一项价值12亿美元的协议，为其提供云计算服务和AI功能。
今年，因为一些员工抗议军事合同，谷歌解雇了数十名员工。而CEO劈柴直言不讳地告诉员工：「这是一门生意」。

2022年，亚马逊同样发生了类似的员工抗议，同样地，公司并没有改变政策。

双重黑箱
研究人员警告说，随着大量资金流入国防技术领域，许多公司和技术的运营透明度和问责度极低。
一旦产品意外失效，结果就是致命的，但这些军火商通常对此并不负责。
而且，美国国家安全机构的保密倾向也意味着，公司和政府没有义务公开这些系统如何运作的细节。
当政府采用了秘密、专有的AI技术，将其置于国家安全的隐秘世界中时，就会形成弗吉尼亚大学法学教授Ashley Deeks所称的「双重黑箱」。
这种情况下，公众很难知道这些系统是否正确或符合道德地运作。而且，通常来说会留有很大的错误空间。
美国安全智库中心的Scharre表示：「我在商业领域见过很多关于AI的炒作，『AI』这个词在到处被滥用。一旦你深入了解，就会发现它可能并不像广告宣传的那样复杂。」

活动人士在德国柏林的勃兰登堡门前举行抗议，要求「阻止杀手机器人」

人在回路
虽然公司和国家军队不愿透露他们系统的具体运作细节，但他们确实参与了很多辩论，关于AI系统的道德责任和监管。
比如，外交官和军火商普遍认为，决策过程中应该始终有「人类参与」，而不是完全交由机器控制。
然而，对于如何实施人类监督，各方却鲜有共识。
「每个人都能认同这个概念，但同时每个人又对它在实际中的意义有不同看法，」里士满大学的法律教授兼自主战争专家、DARPA的首位访问学者Rebecca Crootof说。
「在实际的指导技术设计决策方面，这个概念并不是那么有用。」
抗议者聚集在英国莱斯特的Elbit System工厂门外
此外，人类心理和问责制的复杂性，给「人在回路」的高层讨论带来了更多麻烦。
研究人员经常引用的一个例子就是自动驾驶汽车，在必要时，人类必须重新控制车辆，来实现「人类参与」。
但是，如果自动驾驶汽车犯了错，或者使得人类做出错误决策，把责任归咎于驾驶员公平吗？
再具体一点，如果自动驾驶汽车在撞车的前几秒钟，将控制权交给了人类，这种情况下谁该负责？
美国安全智库中心的Scharre指出了一件有趣的事：我们有时会让人类坐在驾驶舱上，这样出事时我们就可以找到人担责了，这就是所谓的「道德缓冲区」。

如何监管，众说纷纭
在今年四月底于维也纳举行的一次会议上，来自143个国家的国际组织和外交官齐聚一堂，讨论在战争中使用人工智能和自主武器的监管问题。
多年来，联合国安理会都未就此达成任何全面性条约。
相比全面禁掉自主武器，奥地利外长Alexander Schallenberg的呼吁要温和得多——「至少我们该做出最深远、最重要的决定——谁生谁死仍然掌握在人类手中，而不是机器手中」。

关于「禁止特定类型的自主武器系统」，国际红十字会和停止杀手机器人组织已经呼吁了十来年了。
阻止杀手机器人组织的经理Catherine Connolly表示：「我们看到大量资金投入自主武器和AI瞄准系统等技术，这让人非常担忧。」
如今，情况愈发紧迫。
军备控制倡导者们也承认，留给争取监管的时间不多了。
某组织危机、冲突和军备部门的副主任Mary Wareham表示，「我们曾经呼吁对全自主武器系统进行预防性禁止，而现在，我们已经不再使用『预防性』这个词，因为我们离自主武器已经非常近了。」
而对于增强监管的呼声，遭到了美国等国家以及军火商的反对。
Anduril的创始人Luckey模糊地承诺在公司的技术中保持「人类参与」，但公开反对对自主武器的监管和禁令。
Palantir的CEO Alex Karp则多次提到，我们已经到达了奥本海默时刻。

一架集成AI的无人机正在排雷
专家表示，这种缺乏监管的问题不仅仅是自主武器独有的现象，而是国际法律体系普遍面临的难题。
但很多人担心，一旦这些技术被开发出来并整合到军队中，它们就会长期存在，并且更加难以监管。
「武器一旦被用于军事中，就更难放弃，因为他们已经依赖它。」美国安全智库中心的Scharre说。「这已经不仅仅是金融投资了。」
如果自主武器和AI的发展像其他军事技术一样，它们的使用也很可能会逐渐渗透到国内执法和边境巡逻机构中，从而进一步巩固这种技术。
「很多时候，战争中使用的技术最终会回到国内。」 Connolly说。

参考资料：
https://www.theguardian.com/technology/article/2024/jul/14/ais-oppenheimer-moment-autonomous-weapons-enter-the-battlefield
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。