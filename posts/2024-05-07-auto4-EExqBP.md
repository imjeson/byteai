---
title: 'OpenAI神秘模型，再次被Sam Altman提及'
date: 2024-05-08
author: ByteAILab

---

5月6日，OpenAI首席执行官Sam Altman在社交平台分享了一条推文“我是一个优秀的GPT-2聊天机器人”。而在4月30日，Altman就提起过该模型非常喜欢GPT-2。

---
按道理说一个只有15亿参数在2019年发布的开源模型，被反复提及两次就很不寻常。更意外的是GPT-2曾短暂上榜LMSYS的聊天机器人竞技场性能媲美GPT-4、Claude Opus等模型。很多人猜测，难道这是OpenAI即将发布的GPT-4.5、GPT-5？但在5月2日的一场公开演讲中，Altman否认了这个说法。

[GPT-2开源地址](https://github.com/openai/gpt-2)

[论文地址](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

从GPT-2展示出的性能来看有一点是可以肯定的，OpenAI掌握了一种新的训练、微调模型方法，可将小参数模型的性能训练的和大参数模型一样优秀，就像微软刚发布的Phi-3系列模型。所以，**这可能是一款针对手机、平板等移动设备的高性能、低消耗模型**。因为，微软、谷歌、Meta等科技巨头都发布了针对移动端的大模型，唯独OpenAI迟迟没有发布。**加上苹果正在与OpenAI、谷歌洽谈希望在iOS 18中使用GPT系列模型来增强用户体验和产品性能。**非常善于营销的Altman用这种“新锅抄旧菜”的方法进行病毒式宣传来赢得苹果的信任。一方面，可以极大展示自己模型的性能与技术实力；另一方面给谷歌造成压力，虽然其Gemini系列是针对移动端的，但在市场应用方面并没有太多的反响。

开发移动端的大模型都有一个非常相似的技术特点，就是参数都非常小。例如，微软刚发布的Phi-3系列模型，最小的只有13亿参数；谷歌的Gemini系列模型最小的只有18亿。这是因为，**参数越大模型的神经元就越多对硬件的要求也就越高**。如果想部署在移动端的大模型需要考虑电池、存储空间、算力、延迟、推理效率等因素，才能在有限的硬件空间内发挥出最大的性能。例如，直接使用一个1000亿参数的模型，可能还没问几下电池先耗尽了。此外，在移动设备对推理的效率要求也很高。目前手机端的延迟大概是web、PC端的数倍，如果想更好地使用语音助手、实时翻译、文本问答这些功能，也是使用小参数模型的主要原因之一。

所以，OpenAI使用在2019年开源的15亿参数GPT-2模型来实验最合适不过了，并且架构也是基于Transformer，基本上是GPT-3、GPT-4的先辈模型。当然，如果未来OpenAI真的发布面向移动端的小参数模型，名字肯定不会再叫GPT-2，大概会起GPT-4 mini/little一类的吧。【本文素材来源OpenAI，如有侵权请联系删除】

END

---
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。