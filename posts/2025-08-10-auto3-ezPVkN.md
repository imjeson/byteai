---
title: '首个无限上下文大型语言模型扰动12亿美元的RAG市场'
date: 2025-08-11
author: ByteAILab
---

硅谷初创公司iFrame™ AI悄然与一家领先的云服务提供商达成了近2000万美元的协议，推出世界首个具有无限上下文窗口的大型注意力模型——这一突破有望扰动专业服务行业，并在高成本、冗余数据检索服务中冲击类似OpenAI公司的收入。![图片](https://ai-techpark.com/wp-content/uploads/First.jpg){ width=60% }

---


正如DeepSeek在去年震撼AI生态系统一样，iFrame的Asperanto和Sefirot-10模型完全消除了检索管道和微调的需求，兑现了前谷歌首席执行官埃里克·施密特（Eric Schmidt）最近的预测：无限上下文模型即将面世，旨在重塑我们对代理式AI应用的理解。

在过去近十年中，人工智能行业一直被困在变换器的注意力矩阵中——这一引擎驱动了OpenAI、谷歌和Anthropic等所有主要AI产品，迫使即便是最先进的模型也陷入了数字健忘症。

经过三年的隐身模式，iFrame™推出了世界首个大型注意力模型（LAM），这一架构不仅扩展了上下文窗口——而且将这一概念彻底变得过时。通过完全去除注意力矩阵，iFrame™创造了一个可以在一次处理过程中原生推理数TB数据的模型：无需RAG，无需微调，无需花招。使用iFrame™，您只需将数TB数据上传到一个注意力块，即可在几秒钟内升级AI知识。

“好或坏，我帮助AI逃离了矩阵——字面意义上，”iFrame的创始人、单调框架的创作者弗拉德·帕宁（Vlad Panin）在最近的采访中说道。他的突破并非来自于对现有AI研究的迭代，而是源于对宇宙拓扑数学的深入研究，灵感来自享有盛誉的隐士格里戈里·佩雷尔曼（Grigori Perelman），他于2002年解决了庞加莱猜想。

“每个人都在尝试从接受的叙事中优化矩阵，”帕宁解释道。“我却鲁莽地去寻找一把钥匙，去打开一个显然被矩阵计算并行主义的教义所排斥的门。”

这对整个AI硬件和软件生态系统提出了根本性挑战。像AWS、Azure和谷歌这样的GPU巨头可能会在一夜之间将其数据中心利用率提高四倍。iFrame的架构从一开始就设计为在去中心化网络上运行，利用所有可用硬件的每一丝内存。它绕过了使NVIDIA成为AI之王的GPU VRAM瓶颈，为一个可以在全球分布式设备网络上运行的大型AI模型的世界打开了道路。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。