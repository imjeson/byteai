---
title: '首个多模态连续学习综述，港中文、清华、UIC联合发布'
date: 2024-11-14
author: ByteAILab

---

AIxiv专栏是机器之心发布学术、技术内容的栏目。过去数年，机器之心AIxiv专栏接收报道了2000多篇内容，覆盖全球各大高校与企业的顶级实验室，有效促进了学术交流与传播。

---
如果您有优秀的工作想要分享，欢迎投稿或者联系报道。投稿邮箱：liyazhou@jiqizhixin.com；zhaoyunfeng@jiqizhixin.com

本文作者来自于港中文、清华和UIC。主要作者包括：余甸之，港中文博士生；张欣妮，港中文博士生；陈焱凯，港中文博士；刘瑷玮，清华大学博士生；张逸飞，港中文博士；Philip S. Yu，UIC教授；Irwin King，港中文教授。

论文标题：Recent Advances of Multimodal Continual Learning: A Comprehensive Survey
论文链接：https://arxiv.org/abs/2410.05352
GitHub地址：https://github.com/LucyDYu/Awesome-Multimodal-Continual-Learning

多模态连续学习的最新进展

连续学习（CL）旨在增强机器学习模型的能力，使其能够不断从新数据中学习，而无需进行所有旧数据的重新训练。连续学习的主要挑战是灾难性遗忘：当任务按顺序训练时，新的任务训练会严重干扰之前学习的任务的性能，因为不受约束的微调会使参数远离旧任务的最优状态。尽管连续学习取得了重大进展，但大多数工作都集中在单一数据模态上，如视觉，语言，图，或音频等。这种单模态的关注忽略了现实世界环境的多模态本质，因为现实世界环境本身就很复杂，由不同的数据模态而不是单一模态组成。

随着多模态数据的快速增长，发展能够从多模态来源中连续学习的 AI 系统势在必行，因此出现了多模态连续学习（MMCL）。这些 MMCL...

[剩余内容省略]

---
请将Body部分的内容转化为不带html标签（注：图片链接展示需要保留）的Makedown的内容。再整体按照如下Makedown格式标准输出。

---

title: '首个多模态连续学习综述，港中文、清华、UIC联合发布'
date: 2024-11-14
author: ByteAILab

---

[转换后的内容]
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。