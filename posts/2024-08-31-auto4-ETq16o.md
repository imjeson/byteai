---
title: '曙光存储的“引力弹弓”，让AI向产业宇宙加速狂奔'
date: 2024-09-01
author: ByteAILab

---

《流浪地球》中，科学家利用木星的“引力弹弓”效应，为地球加速，成功脱离危机，是整部电影最激动人心的高潮段落。加速，不仅在科幻电影中揪人心弦，对AI行业也十分重要。

---
比如说，千亿级大模型必须写容错点checkpoint，一旦数据存储发生灾难性故障，导致AI训练中断，对于一些着急上线的企业来说，时间就是生命线，可能造成难以弥补的损失。所以说，确保AI快速稳定地进行，是产业智能化的必要条件。为AI加速，存储也可以起到“引力弹弓”效应。试想一下，当你正在滑滑板，有一个速度很快的人从你旁边经过，拉了你一把，就如同弹弓弓弦一样，给了你一个加速前进的力。存力之于AI，就起到了类似的作用。存力和算力互相协同，通过存力来缩短数据读写时间，减少算力的空转等待时间，可以有效提升AI大模型的训练效率。不过，想充分释放存力的“引力弹弓”效应，传统存储的性能、可靠性等，就有些力不从心了。锻造一张最适合AI的“引力弹弓”，曙光存储出手了。此前，曙光推出的智存产品搭载五级加速方案，已经在政务、科研、金融、医疗等行业场景，相继落地。就在近期，又宣布与智元机器人合作，成为具身智能领域的存力伙伴。在曙光存储的存力底座上，越来越多的AI模型/能力，正加速奔向产业宇宙。我们就跟随这张“引力弹弓”的发射方向，来一场奔赴星辰大海的AI之旅吧。“引力弹弓”效应，利用了宇宙中天体的引力，当航天器进入引力影响范围时，被拉了一把，行程就会开始加速。对AI来说，存储也自带加速“引力”吗？答案是肯定的。至少从四个方面，存储可以“拉”AI一把：首先是性能。计算越复杂，对存储性能和带宽的要求越高，存储必须足够快，才能匹配上GPU或AI芯片，否则就会导致算力空载、空转或等待。在模型训练中断时从checkpoint快速写回，也可以提高AI计算效率。其次是质量。“garbage in，garbage out（垃圾进，垃圾出）”，存储承载的数据质量，直接影响到大模型训练的效果，随着大模型需要“咀嚼”的数据规模、类型越来越多，AI存储必须具备对海量规模、异构等数据的高效吞吐和处理能力。第三是安全。存储系统的管理审计、权限管理等，从数据I/O通路上保证用户数据的安全可靠，不会有篡改、不可追溯等问题，也是AI用户十分看重的。第四是优化。存储可以结合用户业务，进行一些个性化的微调与适配，比如了解到业务数据中的大文件多还是小文件多，随机访问多还是顺序访问多，在此基础上进行参数调整，可以针对性优化，提升业务体验。因此，存储在AI基础设施中的优先级不断提高。去年大模型爆火初期，AI行业用户一开始只关注存储产品的容量，后续则慢慢意识到存储的性能、开放兼容性、AI应用适配性等更多维度指标的重要性。从能用到智用，存储之于AI的“引力”正越来越大，起到了越来越重要的加速作用。AI存储对行业用户的吸引力，越来越大，但动辄万亿参数、万卡集群的AI大模型，对存储的要求也指数级上升。市面上是否有超强AI存力的产品，像木星推动地球一样，发挥出强大天体才具备的“引力弹弓效应”呢？曙光决定来打造一个。曙光ParaStor分布式全闪存储，作为最懂AI的存储产品，核心特点就是一个字：快。可以将AI整体表现提升20倍以上，让数据无需等待，AI也就快人一步。具体是怎么做到的？曙光存储运营总监石静向我们解密。这张最适合AI的“引力弹弓”，有两大核心：一是最强的数据底座，二是最佳的AI应用加速套件。可以这样理解，数据底座就像是天体本身的引力足够大、足够强。曙光存储的ParaStor分布式全闪存储，在整个硬件层面进行提升，可以发挥出极致性能。带宽倍数提升，单个节点可以做到最高150GB/s带宽，一秒钟提供150G的数据吞吐。IOPS十倍提升，一秒钟可以处理320万个I/O请求，实现高效吞吐。而应用套件，就像是在原有引力基础上再造一个加速引擎，推动AI走得更快。ParaStor分布式全闪存储采用了业内独家的“五级加速方案”，尽可能地缩短整个I/O流程，让数据更加靠近计算，分别实现了本地内存、Burst Buffer加速层、网络层（RDMA-Based）、存储节点高速层（ NVMe SSD-Based ）、应用层（存储直达GPU）的五层加速。最强数据底座+五级加速的最佳AI应用加速套件，成为一张强有力的“引力弹弓”，让AI表现提升20倍，可以去往更广阔的产业天地。利用“引力弹弓效应”，人造航空器“旅行者1号” 飞出了太阳系，进入了太阳系外更广阔的宇宙空间。曙光存储可以让AI走得更快，那么能推动AI走得更远吗？目前来看，答案是确定的。作为分布式存储市场领导者象限中排名第一的厂商，曙光也在AI赛道上起到了引领作用。曙光存储走向行业的足迹，连起来，就是AI迈向产业的“轨迹”。为AI筑底座。曙光存储与中国移动合作，为其新型智算中心提供存储底座，助力万卡甚至超万卡集群的建设，算力网络AI注智赋能，有望为各行各业提供澎湃的智能算力。泉州智慧城市大脑，借助新一代曙光存储的异构融合能力，实现海量异构数据资源的融合，打造更坚实的“数字底座”。为AI谋效率。在与某AI大模型厂商的合作中，曙光存储的ParaStor分布式全闪存储，单节点150GB/s带宽和320万IOPS，整体训练效率提升50%以上，有了高效率的支撑大模型厂商更快推出产品来满足市场需求。为AI降成本。目前，曙光存储实现了国内外双栈技术生态全兼容（CPU/GPU/OS/DB/Cloud），可以应对AI算力多元异构的技术挑战，支持国内外不同厂商、不同架构、不同版本的算卡，以及多样的大模型，帮助行业客户在智能化过程中，实现成本均衡。更合理的成本，也可以加速AI的产业化进程。为AI谋新篇。在具身智能等新兴领域，曙光存储深入了解行业痛点，针对具身智能机器人低时延、高性能、丝滑体验等刚需，凭借快训练、快归档和合理成本等优势，为智元机器人打造坚实存储底座，让智元机器人可以实时、高效、丝滑地运行，及时处理故障，保持在最佳状态，加速商用进程，开启具身智能的新纪元。不难看到，一张强大存储的“引力弹弓”，正推动AI走得又快又稳又远，走向广袤的产业宇宙。可能有人会问，为什么最适配AI的存储，会率先诞生在中国、在曙光？首先，曙光与国内AI的距离最近。可以针对性地满足国內AI厂商的定制化开发需求，这是海外厂商很难具备的。此外，曙光自主研发实力很强。有国产化要求、担心海外供应链风险、追求完全自研的厂商，曙光存储有极强的吸引力。而AI新技术，也要求存储厂商需要更多地跟介质厂商、网络厂商交互，共同探索全新的方案。以及在存储系统中纳入AI的能力，在算法上面有更多的积淀。因此，对存储厂商的综合能力、生态合作等，也都提出了新的要求。从这个角度讲，曙光存储在AI领域的“引力弹弓”效应，也将进一步推动国产存储厂商的跟进与升级。当越来越多的国产先进存储，为AI提供加速引力，一定会将AI推向更广阔的产业地带。那时，我们将看到一个更加辽阔璀璨的智能中国。
---
感谢阅读！如果您对AI的更多资讯感兴趣，可以查看更多AI文章：[GPTNB](https://gptnb.com)。